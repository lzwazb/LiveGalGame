#!/usr/bin/env python3
"""
FunASR Worker with Streaming Recognition

Âü∫‰∫é FunASR/paraformer-zh-streaming ÁöÑÊµÅÂºèËØ≠Èü≥ËØÜÂà´ÂºïÊìé
ÊîØÊåÅÂÆûÊó∂Èü≥È¢ëÊµÅËØÜÂà´„ÄÅ‰∏≠ÊñáÊ†áÁÇπÁ¨¶Âè∑Ê∑ªÂä†ÂíåÊó∂Èó¥Êà≥È¢ÑÊµã„ÄÇ

Ê†∏ÂøÉÁâπÊÄßÔºö
1. ÊªëÂä®Á™óÂè£ÊµÅÂºèËØÜÂà´
2. ÁºìÂ≠òÊú∫Âà∂Áª¥ÊåÅ‰∏ä‰∏ãÊñá
3. ‰∏≠ÊñáÊ†áÁÇπÁ¨¶Âè∑‰ºòÂåñ
4. Ê∑∑ÂêàÂàÜÂè•Á≠ñÁï•

IPC ÂçèËÆÆÔºö
- ËæìÂÖ•Ôºöstreaming_chunk, batch_file, reset_session, force_commit
- ËæìÂá∫Ôºö
  - partial: ÂÆûÊó∂Â≠óÂπïÔºàÂ¢ûÈáèÊñáÊú¨Ôºâ
  - sentence_complete: ÂÆåÊï¥Âè•Â≠êÔºàËß¶ÂèëÂ≠òÂ∫ìÔºâ
"""

import base64
import json
import math
import os
import sys
import time
import traceback
from dataclasses import dataclass, field
from typing import Dict, List, Tuple

import numpy as np
from funasr import AutoModel

# ==============================================================================
# OS Á∫ßÂà´ÁöÑÊñá‰ª∂ÊèèËø∞Á¨¶ÈáçÂÆöÂêë
# ==============================================================================
ipc_fd = os.dup(sys.stdout.fileno())
ipc_channel = os.fdopen(ipc_fd, "w", buffering=1, encoding="utf-8")
os.dup2(sys.stderr.fileno(), sys.stdout.fileno())
sys.stdout = sys.stderr


def send_ipc_message(data):
    """ÂèëÈÄÅ JSON Ê∂àÊÅØÂà∞ Node.js"""
    try:
        json_str = json.dumps(data, ensure_ascii=False)
        ipc_channel.write(json_str + "\n")
        ipc_channel.flush()
    except Exception as exc:
        sys.stderr.write(f"[IPC Error] Failed to send: {exc}\n")
        sys.stderr.flush()


# ==============================================================================
# ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ
# ==============================================================================
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ.setdefault("TQDM_DISABLE", "1")

HF_HOME = os.environ.get("HF_HOME")
DEFAULT_CACHE_DIR = os.path.join(HF_HOME, "hub") if HF_HOME else os.path.expanduser("~/.cache/huggingface/hub")
CACHE_DIR = os.environ.get("ASR_CACHE_DIR") or DEFAULT_CACHE_DIR
os.makedirs(CACHE_DIR, exist_ok=True)

# ==============================================================================
# FunASR ÈÖçÁΩÆ
# ==============================================================================
SAMPLE_RATE = int(os.environ.get("ASR_SAMPLE_RATE", "16000"))

# ÊªëÂä®Á™óÂè£ÈÖçÁΩÆ
CHUNK_SIZE = os.environ.get("FUNASR_CHUNK_SIZE", "0,10,5")  # ctx,left,right
CHUNK_SIZE_LIST = [int(x) for x in CHUNK_SIZE.split(",")]
ENCODER_LOOK_BACK = int(os.environ.get("FUNASR_ENCODER_LOOK_BACK", "4"))
DECODER_LOOK_BACK = int(os.environ.get("FUNASR_DECODER_LOOK_BACK", "1"))

# ËØÜÂà´Á™óÂè£ÈÖçÁΩÆ
MIN_NEW_AUDIO_SECONDS = float(os.environ.get("ASR_MIN_NEW_AUDIO", "0.5"))
MAX_BUFFER_SECONDS = float(os.environ.get("ASR_BUFFER_SECONDS", "30"))
LOOKBACK_SECONDS = float(os.environ.get("ASR_LOOKBACK_SECONDS", "1.0"))
MIN_DECODE_SAMPLES = int(0.4 * 16000)  # ÊúÄÂ∞èËß£Á†ÅÈááÊ†∑Êï∞

MIN_NEW_AUDIO_SAMPLES = int(MIN_NEW_AUDIO_SECONDS * SAMPLE_RATE)
MAX_BUFFER_SAMPLES = int(MAX_BUFFER_SECONDS * SAMPLE_RATE)

# ÂàÜÂè•ÈÖçÁΩÆ
SENTENCE_END_PUNCTUATION = set("„ÄÇÔºÅÔºü!?.Ôºõ;")
CLAUSE_PUNCTUATION = set("Ôºå,„ÄÅÔºö:")
MIN_SENTENCE_CHARS = int(os.environ.get("MIN_SENTENCE_CHARS", "4"))
# „Äê‰ºòÂåñ„ÄëÊèêÈ´òËá™Âä®Êèê‰∫§Èó®ÊßõÔºåÂáèÂ∞ëÂè•Â≠êÊà™Êñ≠
MIN_AUTO_COMMIT_CHARS = int(os.environ.get("MIN_AUTO_COMMIT_CHARS", "30"))  # ‰ªé18ÊèêÈ´òÂà∞30
MAX_SENTENCE_SECONDS = float(os.environ.get("MAX_SENTENCE_SECONDS", "20"))  # ‰ªé15ÊèêÈ´òÂà∞20
# „Äê‰ºòÂåñ„ÄëÊèêÈ´òÂÅúÈ°øÊ£ÄÊµãÈòàÂÄºÔºåÂáèÂ∞ëËØØÂà§
SEGMENT_GAP_THRESHOLD = float(os.environ.get("SEGMENT_GAP_THRESHOLD", "1.2"))  # ‰ªé0.5ÊèêÈ´òÂà∞1.2

# „Äê‰ºòÂåñ„ÄëÊ†áÁÇπÊ∑ªÂä†Á≠ñÁï•ÈÖçÁΩÆ - Èôç‰ΩéÂª∂ËøüÔºåÊèêÂçáÂìçÂ∫îÈÄüÂ∫¶
PUNC_DEBOUNCE_INTERVAL = float(os.environ.get("PUNC_DEBOUNCE_INTERVAL", "0.3"))  # ‰ªé0.8ÈôçËá≥0.3Áßí
MIN_CHARS_FOR_PUNC = int(os.environ.get("MIN_CHARS_FOR_PUNC", "3"))  # ‰ªé6ÈôçËá≥3‰∏™Â≠óÁ¨¶
PUNC_CONTEXT_SENTENCES = int(os.environ.get("PUNC_CONTEXT_SENTENCES", "2"))  # ‰øùÁïôÂ§öÂ∞ë‰∏™Â∑≤ÂÆåÊàêÂè•Â≠ê‰Ωú‰∏∫‰∏ä‰∏ãÊñá


@dataclass
class SentenceBuffer:
    """ÂΩìÂâçÊ≠£Âú®ÊûÑÂª∫ÁöÑÂè•Â≠ê"""
    text: str = ""
    start_time: float = 0.0
    last_update_time: float = 0.0


# „ÄêÊ†∏ÂøÉ‰øÆÂ§ç„ÄëFunASR ÊµÅÂºèÊ®°ÂûãÈúÄË¶ÅÂõ∫ÂÆöÂ§ßÂ∞èÁöÑ chunk
# chunk_size = [0, 10, 5] ÊÑèÂë≥ÁùÄ stride = 10 * 60ms = 600ms = 9600 samples
FUNASR_STRIDE_SAMPLES = int(CHUNK_SIZE_LIST[1] * 0.06 * SAMPLE_RATE)


@dataclass
class SessionState:
    """
    FunASR ‰ºöËØùÁä∂ÊÄÅÔºåÁÆ°ÁêÜÈü≥È¢ëÁºìÂÜ≤ÂíåÂàÜÂè•

    „ÄêÊ†∏ÂøÉ‰øÆÂ§ç„ÄëÊ∑ªÂä†Èü≥È¢ëÁ¥ØÁßØÂô®ÔºåÁ°Æ‰øùÊåâÂõ∫ÂÆöÂ§ßÂ∞èÈÄÅÂÖ•Ê®°Âûã
    """
    # „ÄêÊñ∞Â¢û„ÄëÈü≥È¢ëÁ¥ØÁßØÁºìÂÜ≤Âå∫
    audio_buffer: np.ndarray = field(default_factory=lambda: np.array([], dtype=np.float32))
    processed_samples: int = 0
    current_sentence: SentenceBuffer = field(default_factory=SentenceBuffer)
    last_partial_text: str = ""
    funasr_cache: Dict = field(default_factory=dict)
    completed_sentences: List[str] = field(default_factory=list)
    # „Äê‰ºòÂåñ„ÄëÂ¢ûÈáèÊ†áÁÇπÂåñÁä∂ÊÄÅ
    last_punc_time: float = 0.0
    raw_text_buffer: str = ""  # ÂéüÂßãÊú™Âä†Ê†áÁÇπÁöÑÊñáÊú¨ÁºìÂÜ≤
    stable_punctuated_text: str = ""  # Â∑≤Á®≥ÂÆöÁöÑÊ†áÁÇπÂåñÊñáÊú¨ÔºàÊúÄÂêé‰∏Ä‰∏™Âè•Êú´Ê†áÁÇπ‰πãÂâçÔºâ
    unstable_raw_text: str = ""  # ‰∏çÁ®≥ÂÆöÁöÑÂéüÂßãÊñáÊú¨ÔºàÊúÄÂêé‰∏Ä‰∏™Âè•Êú´Ê†áÁÇπ‰πãÂêéÔºâ

    def append_audio(self, samples: np.ndarray):
        """Á¥ØÁßØÈü≥È¢ëÊï∞ÊçÆ"""
        if self.audio_buffer.size == 0:
            self.audio_buffer = samples.astype(np.float32)
        else:
            self.audio_buffer = np.concatenate([self.audio_buffer, samples.astype(np.float32)])

    def get_next_chunk(self) -> Tuple[np.ndarray, bool]:
        """
        Ëé∑Âèñ‰∏ã‰∏Ä‰∏™Âõ∫ÂÆöÂ§ßÂ∞èÁöÑ chunk
        ËøîÂõû: (chunk, has_more)
        """
        if self.audio_buffer.size >= FUNASR_STRIDE_SAMPLES:
            chunk = self.audio_buffer[:FUNASR_STRIDE_SAMPLES]
            self.audio_buffer = self.audio_buffer[FUNASR_STRIDE_SAMPLES:]
            return chunk, self.audio_buffer.size >= FUNASR_STRIDE_SAMPLES
        return None, False

    def get_remaining_audio(self) -> np.ndarray:
        """Ëé∑ÂèñÂâ©‰ΩôÁöÑÈü≥È¢ëÔºàÁî®‰∫é is_finalÔºâ"""
        remaining = self.audio_buffer
        self.audio_buffer = np.array([], dtype=np.float32)
        return remaining

    def update_processed_samples(self, samples: int):
        """ËÆ∞ÂΩïÂ∑≤Â§ÑÁêÜÁöÑÈááÊ†∑ÁÇπÊï∞Èáè"""
        self.processed_samples += samples

    def reset(self):
        """ÂÆåÂÖ®ÈáçÁΩÆ‰ºöËØùÁä∂ÊÄÅ"""
        self.audio_buffer = np.array([], dtype=np.float32)
        self.processed_samples = 0
        self.current_sentence = SentenceBuffer()
        self.last_partial_text = ""
        self.completed_sentences.clear()
        self.funasr_cache = {}
        self.last_punc_time = 0.0
        self.raw_text_buffer = ""
        self.stable_punctuated_text = ""
        self.unstable_raw_text = ""


def decode_audio_chunk(audio_b64: str) -> np.ndarray:
    """Ëß£Á†ÅÈü≥È¢ëÂùó"""
    audio_bytes = base64.b64decode(audio_b64)
    audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
    return audio_int16.astype(np.float32) / 32768.0


def extract_incremental_text(previous: str, current: str) -> str:
    """ÊèêÂèñÂ¢ûÈáèÊñáÊú¨"""
    if not current:
        return ""
    if not previous:
        return current
    if current == previous or current in previous:
        return ""
    if previous in current:
        return current[len(previous):]

    # Â∞ùËØïÊâæÂà∞ÊúÄÈïøÁöÑÈáçÂè†ÈÉ®ÂàÜ
    max_overlap = min(len(previous), len(current))
    for overlap in range(max_overlap, 0, -1):
        if previous[-overlap:] == current[:overlap]:
            return current[overlap:]
    return current


def find_last_sentence_end(text: str) -> int:
    """ÊâæÂà∞ÊñáÊú¨‰∏≠ÊúÄÂêé‰∏Ä‰∏™Âè•Êú´Ê†áÁÇπÁöÑ‰ΩçÁΩÆ
    
    ËøîÂõûÔºöÊúÄÂêé‰∏Ä‰∏™Âè•Êú´Ê†áÁÇπ‰πãÂêéÁöÑ‰ΩçÁΩÆÁ¥¢ÂºïÔºåÂ¶ÇÊûúÊ≤°ÊúâÊâæÂà∞ËøîÂõû 0
    """
    last_pos = -1
    for i, char in enumerate(text):
        if char in SENTENCE_END_PUNCTUATION:
            last_pos = i
    return last_pos + 1 if last_pos >= 0 else 0


def split_stable_unstable(text: str) -> Tuple[str, str]:
    """Â∞ÜÊñáÊú¨ÂàÜÂâ≤‰∏∫Á®≥ÂÆöÈÉ®ÂàÜÔºàÊúÄÂêéÂè•Êú´Ê†áÁÇπ‰πãÂâçÔºâÂíå‰∏çÁ®≥ÂÆöÈÉ®ÂàÜÔºà‰πãÂêéÔºâ
    
    ËøîÂõûÔºö(stable_part, unstable_part)
    """
    last_end_pos = find_last_sentence_end(text)
    return text[:last_end_pos], text[last_end_pos:]


def find_sentence_boundaries(text: str) -> List[Tuple[int, str]]:
    """ÊâæÂà∞ÊñáÊú¨‰∏≠ÁöÑÂè•Â≠êËæπÁïå"""
    boundaries = []
    for i, char in enumerate(text):
        if char in SENTENCE_END_PUNCTUATION:
            boundaries.append((i + 1, 'end'))
        elif char in CLAUSE_PUNCTUATION:
            boundaries.append((i + 1, 'clause'))
    return boundaries


def split_by_sentence_end(text: str) -> Tuple[List[str], str]:
    """ÊåâÂè•Êú´Ê†áÁÇπÂàÜÂâ≤ÊñáÊú¨"""
    import re
    sentences = []
    remaining = text

    # ‰ΩøÁî®Ê≠£ÂàôÂåπÈÖçÂè•Êú´Ê†áÁÇπ
    pattern = r'([^„ÄÇÔºÅÔºü!?.Ôºõ;]*[„ÄÇÔºÅÔºü!?.Ôºõ;])'
    matches = list(re.finditer(pattern, text))

    if not matches:
        return [], text

    last_end = 0
    for match in matches:
        sentence = match.group(1).strip()
        if sentence and len(sentence) >= MIN_SENTENCE_CHARS:
            sentences.append(sentence)
        last_end = match.end()

    remaining = text[last_end:].strip()
    return sentences, remaining


def load_funasr_models() -> Tuple[AutoModel, AutoModel, AutoModel]:
    """Âä†ËΩΩ FunASR Ê®°Âûã
    
    ‰ΩøÁî® ModelScope (ÈªòËÆ§ hub="ms") ‰∏ãËΩΩÊ®°ÂûãÔºåÂõΩÂÜÖËÆøÈóÆÊõ¥Á®≥ÂÆö„ÄÇ
    Ê®°ÂûãÂêçÁß∞Êò†Â∞ÑÂèÇËßÅ funasr/download/name_maps_from_hub.py:
      - paraformer-zh-streaming -> iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online
      - ct-punc -> iic/punc_ct-transformer_cn-en-common-vocab471067-large
      - fa-zh -> iic/speech_timestamp_prediction-v1-16k-offline
    
    „ÄêÈáçË¶Å„Äë‰ΩøÁî® model_revision="v2.0.4" ‰∏éÊµãËØï Demo ‰øùÊåÅ‰∏ÄËá¥
    """
    sys.stderr.write(f"[FunASR Worker] Loading models from cache: {CACHE_DIR}\n")
    sys.stderr.write(f"[FunASR Worker] Chunk stride: {FUNASR_STRIDE_SAMPLES} samples ({FUNASR_STRIDE_SAMPLES/SAMPLE_RATE*1000:.0f}ms)\n")
    sys.stderr.flush()

    try:
        # ÊµÅÂºèËØÜÂà´Ê®°Âûã - ‰ΩøÁî® FunASR ÂÆòÊñπÊ≥®ÂÜåÂêçÁß∞ÔºåÂÜÖÈÉ®‰ºöÊò†Â∞ÑÂà∞ ModelScope ‰ªìÂ∫ì
        # „ÄêÈáçË¶Å„ÄëÊåáÂÆö model_revision="v2.0.4" ‰∏é Demo ‰øùÊåÅ‰∏ÄËá¥
        sys.stderr.write("[FunASR Worker] Loading streaming ASR model: paraformer-zh-streaming (v2.0.4)\n")
        stream_model = AutoModel(
            model="paraformer-zh-streaming",
            model_revision="v2.0.4",
        )
        sys.stderr.write("[FunASR Worker] Streaming model loaded\n")

        # Ê†áÁÇπÁ¨¶Âè∑Ê®°Âûã
        sys.stderr.write("[FunASR Worker] Loading punctuation model: ct-punc (v2.0.4)\n")
        punc_model = AutoModel(
            model="ct-punc",
            model_revision="v2.0.4",
        )
        sys.stderr.write("[FunASR Worker] Punctuation model loaded\n")

        # Êó∂Èó¥Êà≥È¢ÑÊµãÊ®°ÂûãÔºàÂèØÈÄâÔºâ
        try:
            sys.stderr.write("[FunASR Worker] Loading timestamp model: fa-zh (v2.0.4)\n")
            ts_model = AutoModel(
                model="fa-zh",
                model_revision="v2.0.4",
            )
            sys.stderr.write("[FunASR Worker] Timestamp model loaded\n")
        except Exception as e:
            sys.stderr.write(f"[FunASR Worker] Timestamp model load failed (optional): {e}\n")
            ts_model = None

        sys.stderr.flush()
        return stream_model, punc_model, ts_model

    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Model loading failed: {e}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        raise


def funasr_streaming_recognition(
    audio_array: np.ndarray,
    model: AutoModel,
    cache: Dict,
    is_final: bool = False
) -> str:
    """
    FunASR ÊµÅÂºèËØÜÂà´

    ËøîÂõûÔºöÂ¢ûÈáèÊñáÊú¨
    """
    try:
        # FunASR ÊµÅÂºèËØÜÂà´Ë∞ÉÁî®
        results = model.generate(
            input=audio_array,
            cache=cache,
            is_final=is_final,
            chunk_size=CHUNK_SIZE_LIST,
            encoder_chunk_look_back=ENCODER_LOOK_BACK,
            decoder_chunk_look_back=DECODER_LOOK_BACK,
        )

        # ÊèêÂèñÊñáÊú¨
        chunk_text = ""
        if isinstance(results, list) and results:
            for item in results:
                if isinstance(item, dict) and "text" in item:
                    chunk_text += item["text"]
        elif isinstance(results, dict) and "text" in results:
            chunk_text = results["text"]

        return chunk_text.strip()

    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Streaming recognition failed: {e}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        return ""


def apply_punctuation(text: str, model: AutoModel) -> str:
    """Â∫îÁî®Ê†áÁÇπÁ¨¶Âè∑"""
    if not text or not text.strip():
        return text

    try:
        response = model.generate(input=text.strip())
        if response and isinstance(response, list) and len(response) > 0:
            if isinstance(response[0], dict):
                punctuated_text = response[0].get("text", "") or response[0].get("value", "")
                return punctuated_text.strip() if punctuated_text else text
            else:
                return str(response[0]).strip()
        elif isinstance(response, dict):
            punctuated_text = response.get("text", "") or response.get("value", "")
            return punctuated_text.strip() if punctuated_text else text
        return text
    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Punctuation failed: {e}\n")
        return text


def apply_incremental_punctuation(
    stable_text: str,
    new_raw_text: str,
    punc_model: AutoModel,
    context_sentences: int = 1
) -> str:
    """
    Â¢ûÈáèÊ†áÁÇπÂåñÔºöÂè™ÂØπÊñ∞ÊñáÊú¨Ê∑ªÂä†Ê†áÁÇπÔºå‰øùÁïô‰∏ä‰∏ãÊñáÊèêÂçáÂáÜÁ°ÆÊÄß
    
    Args:
        stable_text: Â∑≤ÁªèÊ†áÁÇπÂåñ‰∏îÁ®≥ÂÆöÁöÑÊñáÊú¨
        new_raw_text: Êñ∞Â¢ûÁöÑÊú™Ê†áÁÇπÂåñÊñáÊú¨
        punc_model: Ê†áÁÇπÊ®°Âûã
        context_sentences: ‰øùÁïôÂ§öÂ∞ë‰∏™Â∑≤ÂÆåÊàêÂè•Â≠ê‰Ωú‰∏∫‰∏ä‰∏ãÊñá
    
    Returns:
        Ê†áÁÇπÂåñÂêéÁöÑÊñ∞ÊñáÊú¨Ôºà‰∏çÂåÖÂê´‰∏ä‰∏ãÊñáÔºâ
    """
    if not new_raw_text or not new_raw_text.strip():
        return ""
    
    # ‰ªé stable_text ‰∏≠ÊèêÂèñ‰∏ä‰∏ãÊñáÔºàÊúÄÂêé N ‰∏™Âè•Â≠êÔºâ
    context = ""
    if stable_text and context_sentences > 0:
        # ÊâæÂà∞ÊâÄÊúâÂè•Êú´Ê†áÁÇπ‰ΩçÁΩÆ
        sentence_ends = []
        for i, char in enumerate(stable_text):
            if char in SENTENCE_END_PUNCTUATION:
                sentence_ends.append(i + 1)
        
        # ÂèñÊúÄÂêé N ‰∏™Âè•Â≠ê
        if sentence_ends:
            start_pos = sentence_ends[-context_sentences] if len(sentence_ends) >= context_sentences else 0
            context = stable_text[start_pos:]
    
    # ÁªÑÂêà‰∏ä‰∏ãÊñá + Êñ∞ÊñáÊú¨ËøõË°åÊ†áÁÇπÂåñ
    text_to_punctuate = f"{context}{new_raw_text}"
    punctuated_full = apply_punctuation(text_to_punctuate, punc_model)
    
    # ÊèêÂèñÊñ∞ÊñáÊú¨ÂØπÂ∫îÁöÑÊ†áÁÇπÂåñÁªìÊûú
    if context:
        # ÁßªÈô§‰∏ä‰∏ãÊñáÈÉ®ÂàÜÔºåÂè™ËøîÂõûÊñ∞ÊñáÊú¨ÁöÑÊ†áÁÇπÂåñÁªìÊûú
        # Áî±‰∫éÊ†áÁÇπÂèØËÉΩÊîπÂèòÈïøÂ∫¶ÔºåÊàë‰ª¨ÈúÄË¶ÅÊô∫ËÉΩÂåπÈÖç
        context_len = len(context)
        # ÁÆÄÂåñÂ§ÑÁêÜÔºöÂÅáËÆæ‰∏ä‰∏ãÊñáÈÉ®ÂàÜÂü∫Êú¨‰∏çÂèòÔºåÁõ¥Êé•Êà™Âèñ
        if len(punctuated_full) > context_len:
            return punctuated_full[context_len:]
        else:
            # Â¶ÇÊûúÊ†áÁÇπÂåñÂêéÂèçËÄåÂèòÁü≠‰∫ÜÔºåËØ¥ÊòéÂèØËÉΩÊúâÈóÆÈ¢òÔºåËøîÂõûÂéüÂßãÊñ∞ÊñáÊú¨
            return new_raw_text
    else:
        return punctuated_full


def process_single_chunk(
    stream_model: AutoModel,
    punc_model: AutoModel,
    chunk: np.ndarray,
    state: SessionState,
    request_id: str,
    session_id: str,
    is_final: bool,
) -> str:
    """
    Â§ÑÁêÜÂçï‰∏™Âõ∫ÂÆöÂ§ßÂ∞èÁöÑ chunk
    ËøîÂõûÔºöËØÜÂà´ÊñáÊú¨ÔºàRAWÔºåÊó†Ê†áÁÇπÔºâ
    """
    try:
        raw_text = funasr_streaming_recognition(
            chunk,
            stream_model,
            state.funasr_cache,
            is_final=is_final,
        )
        return raw_text
    except Exception as exc:
        sys.stderr.write(f"[FunASR Worker] Chunk recognition failed: {exc}\n")
        sys.stderr.flush()
        return ""


def handle_streaming_chunk(
    stream_model: AutoModel,
    punc_model: AutoModel,
    data: Dict,
    sessions_cache: Dict[str, SessionState],
):
    """
    „ÄêÊ†∏ÂøÉ‰øÆÂ§ç„ÄëÊåâÁÖßÂõ∫ÂÆö stride Â§ßÂ∞èÂ§ÑÁêÜÊµÅÂºèÈü≥È¢ë
    
    ÂÖ≥ÈîÆÊîπËøõÔºö
    1. Á¥ØÁßØÈü≥È¢ëÊï∞ÊçÆÂà∞ÁºìÂÜ≤Âå∫
    2. ÊåâÁÖß FUNASR_STRIDE_SAMPLES (9600 samples = 600ms) ÂàáÂàÜ
    3. ÊØè‰∏™ chunk ‰æùÊ¨°ÈÄÅÂÖ•Ê®°ÂûãÔºåÁª¥Êä§ cache ËøûÁª≠ÊÄß
    """
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)
    audio_data_b64 = data.get("audio_data")
    is_final = bool(data.get("is_final", False))

    if not audio_data_b64:
        send_ipc_message({"request_id": request_id, "error": "No audio_data provided"})
        return

    state = sessions_cache.setdefault(session_id, SessionState())
    samples = decode_audio_chunk(audio_data_b64)
    if samples.size == 0:
        return

    # „ÄêÊ†∏ÂøÉ„ÄëÁ¥ØÁßØÈü≥È¢ëÂà∞ÁºìÂÜ≤Âå∫
    state.append_audio(samples)
    
    timestamp_ms = int(time.time() * 1000)
    sys.stderr.write(
        f"[FunASR Worker] Audio received: session={session_id}, new_samples={len(samples)}, "
        f"buffer_size={state.audio_buffer.size}, stride={FUNASR_STRIDE_SAMPLES}\n"
    )
    sys.stderr.flush()

    # „ÄêÊ†∏ÂøÉ„ÄëÊåâÂõ∫ÂÆöÂ§ßÂ∞èÂàáÂàÜÂπ∂‰æùÊ¨°Â§ÑÁêÜ
    accumulated_text = ""
    chunks_processed = 0
    
    while True:
        chunk, has_more = state.get_next_chunk()
        if chunk is None:
            break
        
        chunks_processed += 1
        chunk_text = process_single_chunk(
            stream_model, punc_model, chunk, state,
            request_id, session_id, is_final=False
        )
        if chunk_text:
            accumulated_text += chunk_text
            sys.stderr.write(f"[FunASR Worker] Chunk #{chunks_processed} text: \"{chunk_text[:30]}...\"\n")
            sys.stderr.flush()
        
        state.update_processed_samples(len(chunk))

    # Â¶ÇÊûúÊòØÊúÄÁªàÂùóÔºåÂ§ÑÁêÜÂâ©‰ΩôÈü≥È¢ë
    if is_final:
        remaining = state.get_remaining_audio()
        if remaining.size > 0:
            chunks_processed += 1
            final_text = process_single_chunk(
                stream_model, punc_model, remaining, state,
                request_id, session_id, is_final=True
            )
            if final_text:
                accumulated_text += final_text
                sys.stderr.write(f"[FunASR Worker] Final chunk text: \"{final_text[:30]}...\"\n")
                sys.stderr.flush()
            state.update_processed_samples(len(remaining))

    if chunks_processed > 0:
        sys.stderr.write(
            f"[FunASR Worker] Processed {chunks_processed} chunks, "
            f"accumulated_text=\"{accumulated_text[:50]}...\"\n"
        )
        sys.stderr.flush()

    if not accumulated_text:
        return

    # =========================================================================
    # ÂàÜÂè•Â§ÑÁêÜÈÄªËæë
    # =========================================================================
    chunk_start_time_ms = (state.processed_samples - len(samples)) / SAMPLE_RATE * 1000
    chunk_end_time_ms = state.processed_samples / SAMPLE_RATE * 1000
    audio_duration = len(samples) / SAMPLE_RATE

    # Êõ¥Êñ∞ÂéüÂßãÊñáÊú¨ÁºìÂÜ≤Âå∫ÔºàÊó†Ê†áÁÇπÔºâ
    state.raw_text_buffer += accumulated_text
    # „ÄêÂÖ≥ÈîÆ‰øÆÂ§ç„ÄëÂêåÊ≠•Êõ¥Êñ∞‰∏çÁ®≥ÂÆöÂå∫ÂüüÁöÑÂéüÂßãÊñáÊú¨
    state.unstable_raw_text += accumulated_text
    
    sentence_start_time_sec = state.current_sentence.start_time
    if not sentence_start_time_sec:
        sentence_start_time_sec = chunk_start_time_ms / 1000
        state.current_sentence.start_time = sentence_start_time_sec

    # „Äê‰ºòÂåñ1„ÄëÁ´ãÂç≥Êõ¥Êñ∞ÊòæÁ§∫ÊñáÊú¨ÔºàÂéüÂßãÊñáÊú¨ÔºâÔºå‰∏çÁ≠âÂæÖÊ†áÁÇπÂåñ
    # ËÆ©UIËÉΩÂ§üÂÆûÊó∂ÊòæÁ§∫‰ªª‰ΩïËØÜÂà´Âà∞ÁöÑÂÜÖÂÆπ
    state.current_sentence.text = f"{state.stable_punctuated_text}{state.unstable_raw_text}"
    
    # „Äê‰ºòÂåñ2„ÄëÂÖàÂèëÈÄÅpartialÊ∂àÊÅØÊòæÁ§∫ÂéüÂßãÊñáÊú¨
    current_buffer = state.current_sentence.text
    if current_buffer:
        incremental = extract_incremental_text(state.last_partial_text, current_buffer).strip()
        if incremental:
            send_ipc_message({
                "request_id": request_id,
                "session_id": session_id,
                "type": "partial",
                "text": incremental,
                "full_text": current_buffer,
                "timestamp": timestamp_ms,
                "is_final": is_final,
                "status": "success",
                "language": "zh",
            })
            sys.stderr.write(f"[FunASR Worker] üìù PARTIAL (raw): \"{incremental[:30]}...\"\n")
            sys.stderr.flush()
            state.last_partial_text = current_buffer

    # „Äê‰ºòÂåñ3„ÄëÂºÇÊ≠•Ê†áÁÇπÂåñ - Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÊ∑ªÂä†Ê†áÁÇπÔºàÈò≤ÊäñÔºâ
    current_time = time.time()
    should_punctuate = (
        len(state.unstable_raw_text) >= MIN_CHARS_FOR_PUNC and
        (current_time - state.last_punc_time) >= PUNC_DEBOUNCE_INTERVAL
    )
    
    # 4. Â¶ÇÊûúÊª°Ë∂≥Êù°‰ª∂ÔºåÂè™ÂØπ‰∏çÁ®≥ÂÆöÂå∫ÂüüÔºàÊñ∞ÊñáÊú¨ÔºâÊ∑ªÂä†Ê†áÁÇπ
    if should_punctuate:
        # ‰ΩøÁî®Â¢ûÈáèÊ†áÁÇπÂåñÔºå‰øùÁïô‰∏ä‰∏ãÊñá
        new_punctuated = apply_incremental_punctuation(
            state.stable_punctuated_text,
            state.unstable_raw_text,
            punc_model,
            context_sentences=PUNC_CONTEXT_SENTENCES
        )
        
        # Êõ¥Êñ∞ÂΩìÂâçÊòæÁ§∫ÊñáÊú¨
        state.current_sentence.text = f"{state.stable_punctuated_text}{new_punctuated}"
        state.last_punc_time = current_time
        
        sys.stderr.write(
            f"[FunASR Worker] üî§ Incremental punctuation: "
            f"stable={len(state.stable_punctuated_text)} chars, "
            f"new_raw={len(state.unstable_raw_text)} chars, "
            f"new_punc={len(new_punctuated)} chars\n"
        )
        sys.stderr.flush()
        
        # „Äê‰ºòÂåñ4„ÄëÊ†áÁÇπÂåñÂêéÂÜçÊ¨°ÂèëÈÄÅpartialÊõ¥Êñ∞Ôºå‰ºòÂåñÊòæÁ§∫ÊïàÊûú
        incremental_punc = extract_incremental_text(state.last_partial_text, state.current_sentence.text).strip()
        if incremental_punc:
            send_ipc_message({
                "request_id": request_id,
                "session_id": session_id,
                "type": "partial",
                "text": incremental_punc,
                "full_text": state.current_sentence.text,
                "timestamp": timestamp_ms,
                "is_final": is_final,
                "status": "success",
                "language": "zh",
            })
            sys.stderr.write(f"[FunASR Worker] üìù PARTIAL (punctuated): \"{incremental_punc[:30]}...\"\n")
            sys.stderr.flush()
            state.last_partial_text = state.current_sentence.text
    
    # 3. ÂØπÂΩìÂâçÊñáÊú¨ËøõË°åÂàÜÂè•Ê£ÄÊü•
    text_for_split = state.current_sentence.text
    
    # Â¶ÇÊûúÊñáÊú¨ËøòÊú™Ê†áÁÇπÂåñÔºå‰∏¥Êó∂Ê†áÁÇπÂåñÁî®‰∫éÂàÜÂè•Âà§Êñ≠
    if not should_punctuate and len(state.unstable_raw_text) >= MIN_CHARS_FOR_PUNC:
        temp_punctuated = apply_incremental_punctuation(
            state.stable_punctuated_text,
            state.unstable_raw_text,
            punc_model,
            context_sentences=PUNC_CONTEXT_SENTENCES
        )
        text_for_split = f"{state.stable_punctuated_text}{temp_punctuated}"
    
    # 4. ÂàÜÂè•Ôºö‰ªéÊ†áÁÇπÂåñÁöÑÊñáÊú¨‰∏≠ÊèêÂèñÂÆåÊï¥Âè•Â≠ê
    complete_sentences, remaining_text = split_by_sentence_end(text_for_split)
    sentences_to_commit = [s for s in complete_sentences if len(s.strip()) >= MIN_SENTENCE_CHARS]

    # Ë∂ÖËøáÊúÄÂ§ßÂè•Â≠êÊó∂ÈïøÊàñÁªìÊùüÂùóÊó∂Âº∫Âà∂Êèê‰∫§
    sentence_duration = 0.0
    if sentence_start_time_sec:
        sentence_duration = (chunk_end_time_ms / 1000) - sentence_start_time_sec
    should_force_commit = sentence_duration >= MAX_SENTENCE_SECONDS or is_final

    deferred_text = ""
    commit_ready = []
    for sentence in sentences_to_commit:
        sentence_text = sentence.strip()
        if not sentence_text:
            continue
        if (
            len(sentence_text) < MIN_AUTO_COMMIT_CHARS
            and not should_force_commit
            and not is_final
        ):
            deferred_text += sentence_text
            continue
        commit_ready.append(sentence_text)

    # 5. Êèê‰∫§ÂÆåÊï¥Âè•Â≠ê
    if commit_ready:
        commit_start_time_sec = sentence_start_time_sec or (chunk_start_time_ms / 1000)
        for sentence_text in commit_ready:
            # „Äê‰ºòÂåñ„ÄëÂØπÊúÄÁªàÊèê‰∫§ÁöÑÂè•Â≠êÈáçÊñ∞Ê†áÁÇπÂåñÔºåÁ°Æ‰øùÂáÜÁ°ÆÊÄß
            final_sentence = apply_punctuation(sentence_text, punc_model)
            
            start_ms = int(commit_start_time_sec * 1000)
            send_ipc_message({
                "request_id": request_id,
                "session_id": session_id,
                "type": "sentence_complete",
                "text": final_sentence,
                "timestamp": timestamp_ms,
                "is_final": is_final,
                "status": "success",
                "language": "zh",
                "audio_duration": audio_duration,
                "start_time": start_ms,
            })
            sys.stderr.write(f"[FunASR Worker] üéØ SENTENCE_COMPLETE: \"{final_sentence[:50]}...\"\n")
            sys.stderr.flush()
            state.completed_sentences.append(final_sentence)
            commit_start_time_sec = chunk_end_time_ms / 1000
        
        # „ÄêÂÖ≥ÈîÆ‰øÆÂ§ç„ÄëÊèê‰∫§ÂêéÊ∏ÖÁ©∫ÊâÄÊúâÁºìÂÜ≤Âå∫ÔºåÈáçÊñ∞ÂºÄÂßã
        # Áî±‰∫éÂàÜÂè•ÈÄªËæëÂü∫‰∫éÊ†áÁÇπÂåñÊñáÊú¨ÔºåÊó†Ê≥ïÂáÜÁ°ÆÊò†Â∞ÑÂõûÂéüÂßãÊñáÊú¨
        # Âõ†Ê≠§Êèê‰∫§ÂêéÊ∏ÖÁ©∫ÔºåÈÅøÂÖçÈáçÂ§çÂ§ÑÁêÜ
        state.unstable_raw_text = ""
        state.raw_text_buffer = ""
        state.stable_punctuated_text = ""
        state.current_sentence.text = ""
        state.last_partial_text = ""
        state.last_punc_time = 0.0
        state.current_sentence.start_time = 0.0
        
        sys.stderr.write(f"[FunASR Worker] ‚úÖ Buffers cleared after commit\n")
        sys.stderr.flush()
        return
    
    # 6. Êõ¥Êñ∞ÂΩìÂâçÂè•Â≠êÁºìÂÜ≤Âå∫
    state.current_sentence.text = f"{deferred_text}{remaining_text}".strip()
    state.current_sentence.last_update_time = time.time()

    if state.current_sentence.text:
        if deferred_text:
            state.current_sentence.start_time = sentence_start_time_sec or (chunk_start_time_ms / 1000)
        else:
            state.current_sentence.start_time = chunk_end_time_ms / 1000
    else:
        state.current_sentence.start_time = 0.0

    # 7. Âº∫Âà∂Êèê‰∫§ÔºàË∂ÖÊó∂ÊàñÊúÄÁªàÂùóÔºâ
    if should_force_commit and state.unstable_raw_text:
        # „Äê‰ºòÂåñ„ÄëÂØπ‰∏çÁ®≥ÂÆöÂå∫ÂüüÈáçÊñ∞Ê†áÁÇπÂåñÔºåÁ°Æ‰øùÊúÄÁªàÂáÜÁ°ÆÊÄß
        final_unstable = apply_incremental_punctuation(
            state.stable_punctuated_text,
            state.unstable_raw_text,
            punc_model,
            context_sentences=PUNC_CONTEXT_SENTENCES
        )
        final_text = f"{state.stable_punctuated_text}{final_unstable}".strip()
        
        start_ms = int(sentence_start_time_sec * 1000) if sentence_start_time_sec else int(chunk_start_time_ms)
        send_ipc_message({
            "request_id": request_id,
            "session_id": session_id,
            "type": "sentence_complete",
            "text": final_text,
            "timestamp": timestamp_ms,
            "is_final": is_final,
            "status": "success",
            "language": "zh",
            "audio_duration": audio_duration,
            "start_time": start_ms,
            "trigger": "timeout" if not is_final else "final_chunk",
        })
        sys.stderr.write(f"[FunASR Worker] üéØ FORCE_COMMIT: \"{final_text[:50]}...\"\n")
        sys.stderr.flush()
        state.completed_sentences.append(final_text)
        state.current_sentence = SentenceBuffer()
        state.last_partial_text = ""
        state.raw_text_buffer = ""
        state.stable_punctuated_text = ""
        state.unstable_raw_text = ""
        state.last_punc_time = 0.0
        return

    # Ê≥®ÊÑèÔºöpartialÊ∂àÊÅØÂ∑≤ÁªèÂú®ÂâçÈù¢ÂèëÈÄÅËøá‰∫ÜÔºàÁ¨¨545-587Ë°åÂå∫ÂüüÔºâÔºåËøôÈáå‰∏çÂÜçÈáçÂ§çÂèëÈÄÅ


def handle_batch_file(stream_model: AutoModel, punc_model: AutoModel, data: Dict):
    """Â§ÑÁêÜÊâπÈáèÊñá‰ª∂ËØÜÂà´"""
    request_id = data.get("request_id", "unknown")
    audio_path = data.get("audio_path")

    if not audio_path:
        send_ipc_message({"request_id": request_id, "error": "No audio_path provided"})
        return
    if not os.path.exists(audio_path):
        send_ipc_message({"request_id": request_id, "error": f"File not found: {audio_path}"})
        return

    try:
        import soundfile as sf
        audio_array, sample_rate = sf.read(audio_path)
        if audio_array.ndim > 1:
            audio_array = audio_array.mean(axis=1)

        # ÊâπÈáèËØÜÂà´
        full_text = funasr_streaming_recognition(audio_array, stream_model, {}, is_final=True)

        # Â∫îÁî®Ê†áÁÇπ
        punctuated_text = apply_punctuation(full_text, punc_model)

        send_ipc_message({
            "request_id": request_id,
            "text": punctuated_text,
            "language": "zh",
            "status": "success",
        })

    except Exception as exc:
        send_ipc_message({
            "request_id": request_id,
            "error": str(exc),
            "traceback": traceback.format_exc(),
        })


def handle_force_commit(data: Dict, sessions_cache: Dict[str, SessionState], punc_model: AutoModel):
    """Âº∫Âà∂Êèê‰∫§ÂΩìÂâçÂè•Â≠ê"""
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)

    sys.stderr.write(f"[FunASR Worker] force_commit received for session={session_id}\n")
    sys.stderr.flush()

    state = sessions_cache.get(session_id)
    if not state:
        sys.stderr.write(f"[FunASR Worker] No session state found for session={session_id}\n")
        sys.stderr.flush()
        return

    # „Äê‰ºòÂåñ„Äë‰ΩøÁî®‰∏çÁ®≥ÂÆöÂå∫ÂüüÔºåÂ¢ûÈáèÊ†áÁÇπÂåñÁ°Æ‰øùÂáÜÁ°ÆÊÄß
    if state.unstable_raw_text and len(state.unstable_raw_text) >= MIN_SENTENCE_CHARS:
        final_unstable = apply_incremental_punctuation(
            state.stable_punctuated_text,
            state.unstable_raw_text,
            punc_model,
            context_sentences=PUNC_CONTEXT_SENTENCES
        )
        final_text = f"{state.stable_punctuated_text}{final_unstable}".strip()
        
        timestamp_ms = int(time.time() * 1000)
        start_ms = int(state.current_sentence.start_time * 1000) if state.current_sentence.start_time else timestamp_ms
        sys.stderr.write(f"[FunASR Worker] üéØ FORCE_COMMIT (silence): \"{final_text[:50]}...\"\n")
        sys.stderr.flush()
        send_ipc_message({
            "request_id": request_id,
            "session_id": session_id,
            "type": "sentence_complete",
            "text": final_text,
            "timestamp": timestamp_ms,
            "is_final": True,
            "status": "success",
            "trigger": "silence_timeout",
            "language": "zh",
            "start_time": start_ms,
            "audio_duration": 0,
        })

        # ËÆ∞ÂΩïÂ∑≤Êèê‰∫§Âè•Â≠ê
        state.completed_sentences.append(final_text)

        # ÈáçÁΩÆÁä∂ÊÄÅ
        state.current_sentence = SentenceBuffer()
        state.last_partial_text = ""
        state.raw_text_buffer = ""
        state.stable_punctuated_text = ""
        state.unstable_raw_text = ""
        state.last_punc_time = 0.0
    else:
        sys.stderr.write(f"[FunASR Worker] force_commit: text too short or empty\n")
        sys.stderr.flush()


def main():
    try:
        sys.stderr.write("[FunASR Worker] Starting FunASR Worker...\n")
        sys.stderr.flush()

        # Âä†ËΩΩÊ®°Âûã
        stream_model, punc_model, ts_model = load_funasr_models()

        sessions_cache: Dict[str, SessionState] = {}
        send_ipc_message({"status": "ready"})

        sys.stderr.write("[FunASR Worker] Ready and waiting for input...\n")
        sys.stderr.flush()

        while True:
            line = sys.stdin.readline()
            if not line:
                break
            try:
                data = json.loads(line)
            except json.JSONDecodeError as exc:
                send_ipc_message({"request_id": "unknown", "error": f"Invalid JSON: {exc}"})
                continue

            request_type = data.get("type")
            request_id = data.get("request_id", "default")
            session_id = data.get("session_id", request_id)

            if request_type == "reset_session":
                sys.stderr.write(f"[FunASR Worker] Resetting session: {session_id}\n")
                sys.stderr.flush()
                sessions_cache.pop(session_id, None)
                continue

            if request_type == "force_commit":
                handle_force_commit(data, sessions_cache, punc_model)
                continue

            if request_type == "streaming_chunk":
                handle_streaming_chunk(stream_model, punc_model, data, sessions_cache)
                continue

            if request_type == "batch_file" or "audio_path" in data:
                handle_batch_file(stream_model, punc_model, data)
                continue

            send_ipc_message({
                "request_id": request_id,
                "error": f"Unknown request type: {request_type}",
            })

    except Exception as exc:
        sys.stderr.write(f"[FunASR Worker] Fatal error: {exc}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        send_ipc_message({"status": "fatal", "error": str(exc)})
        sys.exit(1)


if __name__ == "__main__":
    main()