/**
 * éŸ³é¢‘æ•è·æœåŠ¡ï¼ˆåœ¨æ¸²æŸ“è¿›ç¨‹ä¸­è¿è¡Œï¼‰
 * ä½¿ç”¨ electron-audio-loopback + getDisplayMedia æ•è·ç³»ç»ŸéŸ³é¢‘
 * ä½¿ç”¨ getUserMedia æ•è·éº¦å…‹é£éŸ³é¢‘
 */
class AudioCaptureService {
  constructor() {
    this.audioContext = null;
    this.sourceNodes = new Map(); // sourceId -> MediaStreamAudioSourceNode
    this.scriptProcessors = new Map(); // sourceId -> ScriptProcessorNode
    this.streams = new Map(); // sourceId -> MediaStream
    this.isCapturing = false;

    // éŸ³é¢‘å‚æ•°
    this.sampleRate = 16000; // Whisper è¦æ±‚çš„é‡‡æ ·ç‡
    this.bufferSize = 4096; // è„šæœ¬å¤„ç†å™¨ç¼“å†²åŒºå¤§å°

    // ã€ä¼˜åŒ–ã€‘ä¸FunASRçš„chunkStrideå¯¹é½ï¼š9600 samples = 600ms
    this.targetChunkSamples = 9600;
    this.sendInterval = 600; // å‘é€é—´éš”ï¼ˆmsï¼‰

    // ã€VADã€‘é™éŸ³æ£€æµ‹é…ç½® - è¿‡æ»¤é™éŸ³ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
    this.silenceThreshold = 0.008; // é™éŸ³é˜ˆå€¼ï¼ˆRMSèƒ½é‡ï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºé™éŸ³
    this.silenceSkipCount = new Map(); // sourceId -> è¿ç»­è·³è¿‡é™éŸ³çš„æ¬¡æ•°
    this.maxSilenceSkipLog = 5; // æœ€å¤šæ‰“å°å‡ æ¬¡é™éŸ³è·³è¿‡æ—¥å¿—

    // ã€æ–­å¥ã€‘åŸºäºé™éŸ³æ—¶é•¿çš„åˆ†å¥ï¼ˆç”¨äºç”Ÿæˆå¤šæ¡æ¶ˆæ¯ï¼‰
    // æ³¨æ„ï¼šè¿™æ˜¯â€œåœé¡¿æ—¶é•¿é˜ˆå€¼â€ï¼ˆç§’/æ¯«ç§’ï¼‰ï¼Œä¸åŒäºä¸Šé¢çš„èƒ½é‡é˜ˆå€¼ silenceThreshold
    this.sentencePauseThresholdMs = 600; // é»˜è®¤æ›´çµæ•ï¼ˆ0.6sï¼‰ï¼Œä¼šè‡ªåŠ¨ä» ASR é»˜è®¤é…ç½®åˆ·æ–°
    this._vadConfigLastRefreshAt = 0;
    this.enableSilenceSentenceCommit = false; // ä»…äº‘ç«¯ ASR å¯ç”¨ï¼ŒFunASR ä¸å—å½±å“
    this.shouldSkipSilence = true; // æ˜¯å¦åœ¨æœ¬åœ°è·³è¿‡é™éŸ³åŒ…ï¼ˆç™¾åº¦éœ€è¦è®¾ä¸º false ä»¥é˜² -3101ï¼‰
    this.silenceDurationMs = new Map(); // sourceId -> è¿ç»­é™éŸ³ç´¯è®¡æ—¶é•¿(ms)ï¼Œä»…åœ¨ inSpeech=true æ—¶ç´¯ç§¯
    this.inSpeech = new Map(); // sourceId -> æ˜¯å¦å¤„äºâ€œè¯´è¯æ®µâ€ä¸­ï¼ˆåªè¦å‘é€è¿‡éé™éŸ³éŸ³é¢‘å³è®¤ä¸ºè¿›å…¥ï¼‰
    this.lastSilenceCommitAt = new Map(); // sourceId -> ä¸Šæ¬¡è§¦å‘æ–­å¥çš„æ—¶é—´æˆ³(ms)
    this.silenceCommitCooldownMs = 500; // é˜²æŠ–ï¼Œé¿å…åŒä¸€æ®µé™éŸ³é‡å¤è§¦å‘

    // éŸ³é¢‘æ•°æ®ç´¯ç§¯
    this.audioAccumulators = new Map(); // sourceId -> Float32Array
    this.lastSendTime = new Map(); // sourceId -> timestamp

    // ã€å…±äº«æµã€‘å·²æˆæƒçš„ç³»ç»ŸéŸ³é¢‘æµï¼ˆè·¨çª—å£å…±äº«ï¼‰
    this.cachedSystemAudioStream = null;
    this.systemAudioStreamAuthorized = false;

    // äº‹ä»¶ç›‘å¬å™¨
    this.listeners = new Map();

    console.log('[AudioCaptureService] Created');
  }

  on(event, callback) {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, new Set());
    }
    this.listeners.get(event).add(callback);
  }

  off(event, callback) {
    if (this.listeners.has(event)) {
      this.listeners.get(event).delete(callback);
    }
  }

  emit(event, data) {
    if (this.listeners.has(event)) {
      this.listeners.get(event).forEach(callback => {
        try {
          callback(data);
        } catch (err) {
          console.error(`[AudioCaptureService] Error in listener for ${event}:`, err);
        }
      });
    }
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
   */
  async initialize() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: this.sampleRate
      });

      console.log('[AudioCaptureService] Initialized, sample rate:', this.sampleRate);
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error initializing:', error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·éº¦å…‹é£éŸ³é¢‘
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker1ï¼‰
   * @param {string} deviceId - éŸ³é¢‘è®¾å¤‡ ID
   */
  async startMicrophoneCapture(sourceId, deviceId = null) {
    try {
      if (!this.audioContext) {
        await this.initialize();
      }

      await this.refreshVadConfigFromASRDefault();

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting microphone capture for ${sourceId}, device: ${deviceId || 'default'}`);

      const constraints = {
        audio: {
          deviceId: deviceId ? { exact: deviceId } : undefined,
          sampleRate: this.sampleRate,
          channelCount: 1,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log(`[AudioCaptureService] âœ… Microphone stream obtained`);

      this.setupAudioProcessing(sourceId, stream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting microphone capture:`, error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·ç³»ç»ŸéŸ³é¢‘ï¼ˆä½¿ç”¨ electron-audio-loopbackï¼‰
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker2ï¼‰
   * @param {Object} options - é€‰é¡¹
   * @param {boolean} options.useCachedStream - æ˜¯å¦ä½¿ç”¨å·²ç¼“å­˜çš„æµï¼ˆé¿å…å¼¹å‡ºé€‰æ‹©çª—å£ï¼‰
   * @param {boolean} options.forceNewStream - å¼ºåˆ¶è·å–æ–°æµï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
   */
  async startSystemAudioCapture(sourceId, options = {}) {
    try {
      const { useCachedStream = true, forceNewStream = false } = options;

      if (!this.audioContext) {
        await this.initialize();
      }

      await this.refreshVadConfigFromASRDefault();

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting system audio capture for ${sourceId}, options:`, { useCachedStream, forceNewStream });

      // ã€ä¼˜åŒ–ã€‘ä¼˜å…ˆä½¿ç”¨å·²ç¼“å­˜çš„ç³»ç»ŸéŸ³é¢‘æµï¼ˆé¿å…æ¯æ¬¡éƒ½å¼¹å‡ºé€‰æ‹©çª—å£ï¼‰
      if (useCachedStream && !forceNewStream && this.cachedSystemAudioStream) {
        const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
        const hasActiveTrack = audioTracks.some(track => track.readyState === 'live' && track.enabled);

        if (hasActiveTrack) {
          console.log(`[AudioCaptureService] âœ… Using cached system audio stream with ${audioTracks.length} audio track(s)`);
          this.setupAudioProcessing(sourceId, this.cachedSystemAudioStream);
          return true;
        } else {
          console.log('[AudioCaptureService] Cached stream is no longer active, will request new stream');
          this.cachedSystemAudioStream = null;
          this.systemAudioStreamAuthorized = false;
        }
      }

      // ä½¿ç”¨ electron-audio-loopback æ–¹æ¡ˆ
      // 1. å¯ç”¨ loopback éŸ³é¢‘
      if (window.electronAPI?.enableLoopbackAudio) {
        await window.electronAPI.enableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio enabled');
      }

      let displayStream;

      // å°è¯•ä½¿ç”¨ getDesktopSourceId è·å–æº IDï¼Œä»¥é¿å¼€é€‰æ‹©å™¨å¼¹çª—
      if (window.electronAPI?.getDesktopSourceId) {
        try {
          const sourceId = await window.electronAPI.getDesktopSourceId();
          if (sourceId) {
            console.log(`[AudioCaptureService] Got desktop source ID: ${sourceId}, attempting getUserMedia`);
            displayStream = await navigator.mediaDevices.getUserMedia({
              audio: {
                mandatory: {
                  chromeMediaSource: 'desktop',
                  chromeMediaSourceId: sourceId
                }
              },
              video: {
                mandatory: {
                  chromeMediaSource: 'desktop',
                  chromeMediaSourceId: sourceId
                }
              }
            });
            console.log('[AudioCaptureService] âœ… System audio stream obtained via getUserMedia (no picker)');
          }
        } catch (err) {
          console.warn('[AudioCaptureService] Failed to get stream via getUserMedia, falling back to getDisplayMedia:', err);
        }
      }

      // å¦‚æœ getUserMedia å¤±è´¥æˆ–ä¸å¯ç”¨ï¼Œå›é€€åˆ° getDisplayMedia (ä¼šå¼¹å‡ºé€‰æ‹©å™¨)
      if (!displayStream) {
        console.log('[AudioCaptureService] Falling back to getDisplayMedia (picker will appear)');
        displayStream = await navigator.mediaDevices.getDisplayMedia({
          audio: true,
          video: true // éœ€è¦åŒæ—¶è¯·æ±‚è§†é¢‘æ‰èƒ½è·å–éŸ³é¢‘
        });
      }

      // 3. ç¦ç”¨ loopback éŸ³é¢‘ï¼ˆè·å–æµåå³å¯ç¦ç”¨ï¼‰
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio disabled');
      }

      // 4. åœæ­¢è§†é¢‘è½¨é“ï¼ˆæˆ‘ä»¬åªéœ€è¦éŸ³é¢‘ï¼‰
      const videoTracks = displayStream.getVideoTracks();
      videoTracks.forEach(track => {
        track.stop();
        displayStream.removeTrack(track);
        console.log(`[AudioCaptureService] Video track stopped: ${track.label}`);
      });

      // 5. æ£€æŸ¥éŸ³é¢‘è½¨é“
      const audioTracks = displayStream.getAudioTracks();
      if (audioTracks.length === 0) {
        throw new Error('No audio tracks in display stream');
      }

      console.log(`[AudioCaptureService] âœ… System audio stream obtained with ${audioTracks.length} audio track(s)`);
      audioTracks.forEach((track, index) => {
        console.log(`[AudioCaptureService] Audio track ${index + 1}: label=${track.label}, enabled=${track.enabled}`);
      });

      // ã€ç¼“å­˜ã€‘ä¿å­˜å·²æˆæƒçš„æµä¾›åç»­ä½¿ç”¨
      this.cachedSystemAudioStream = displayStream;
      this.systemAudioStreamAuthorized = true;
      console.log('[AudioCaptureService] System audio stream cached for reuse');

      this.setupAudioProcessing(sourceId, displayStream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting system audio capture:`, error);

      // ç¡®ä¿ç¦ç”¨ loopback
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio().catch(() => { });
      }

      throw error;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æœ‰å·²æˆæƒçš„ç³»ç»ŸéŸ³é¢‘æµå¯ç”¨
   * @returns {boolean} æ˜¯å¦æœ‰å¯ç”¨çš„ç¼“å­˜æµ
   */
  hasAuthorizedSystemAudioStream() {
    if (!this.cachedSystemAudioStream) {
      return false;
    }
    const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
    return audioTracks.some(track => track.readyState === 'live' && track.enabled);
  }

  /**
   * è·å–ç³»ç»ŸéŸ³é¢‘æµçŠ¶æ€
   * @returns {Object} çŠ¶æ€ä¿¡æ¯
   */
  getSystemAudioStreamStatus() {
    if (!this.cachedSystemAudioStream) {
      return {
        available: false,
        authorized: false,
        message: 'æœªæˆæƒç³»ç»ŸéŸ³é¢‘ï¼Œéœ€è¦åœ¨è®¾ç½®é¡µé¢æµ‹è¯•éŸ³é¢‘åæ‰èƒ½ä½¿ç”¨'
      };
    }

    const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
    const hasActiveTrack = audioTracks.some(track => track.readyState === 'live' && track.enabled);

    if (hasActiveTrack) {
      return {
        available: true,
        authorized: true,
        trackCount: audioTracks.length,
        message: 'ç³»ç»ŸéŸ³é¢‘å·²æˆæƒå¹¶å¯ç”¨'
      };
    } else {
      return {
        available: false,
        authorized: this.systemAudioStreamAuthorized,
        message: 'ç³»ç»ŸéŸ³é¢‘æµå·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°æˆæƒ'
      };
    }
  }

  /**
   * è®¾ç½®éŸ³é¢‘å¤„ç†ç®¡é“
   * @param {string} sourceId - éŸ³é¢‘æº ID
   * @param {MediaStream} stream - åª’ä½“æµ
   */
  setupAudioProcessing(sourceId, stream) {
    this.streams.set(sourceId, stream);

    // åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹
    const sourceNode = this.audioContext.createMediaStreamSource(stream);
    this.sourceNodes.set(sourceId, sourceNode);

    // åˆ›å»ºè„šæœ¬å¤„ç†å™¨
    const scriptProcessor = this.audioContext.createScriptProcessor(
      this.bufferSize,
      1, // è¾“å…¥å£°é“æ•°
      1  // è¾“å‡ºå£°é“æ•°
    );
    this.scriptProcessors.set(sourceId, scriptProcessor);

    // åˆå§‹åŒ–éŸ³é¢‘ç´¯ç§¯å™¨
    this.audioAccumulators.set(sourceId, new Float32Array());
    this.lastSendTime.set(sourceId, Date.now());
    this.silenceDurationMs.set(sourceId, 0);
    this.inSpeech.set(sourceId, false);

    // è®¾ç½®éŸ³é¢‘å¤„ç†å›è°ƒ
    scriptProcessor.onaudioprocess = (event) => {
      this.handleAudioProcess(sourceId, event);
    };

    // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
    sourceNode.connect(scriptProcessor);
    scriptProcessor.connect(this.audioContext.destination);

    console.log(`[AudioCaptureService] âœ… Audio processing setup complete for ${sourceId}`);
    this.isCapturing = true;
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®
   */
  handleAudioProcess(sourceId, event) {
    try {
      const inputData = event.inputBuffer.getChannelData(0);

      // è®¡ç®—å®æ—¶éŸ³é‡ (RMS)
      let sumSquared = 0;
      for (let i = 0; i < inputData.length; i++) {
        sumSquared += inputData[i] * inputData[i];
      }
      const rms = Math.sqrt(sumSquared / inputData.length);

      // ä½¿ç”¨ dB è®¡ç®—éŸ³é‡ï¼Œä½¿å…¶æ›´ç¬¦åˆäººè€³æ„ŸçŸ¥ (Logarithmic)
      // å‡è®¾æœ€å°å¯æ„ŸçŸ¥éŸ³é‡ä¸º -60dBï¼Œæœ€å¤§ä¸º 0dB
      let volume = 0;
      if (rms > 0) {
        const db = 20 * Math.log10(rms);
        // å°† -60dB ~ 0dB æ˜ å°„åˆ° 0 ~ 100
        volume = Math.max(0, Math.min(100, (db + 60) / 60 * 100));
      }

      // å‘é€éŸ³é‡æ›´æ–°äº‹ä»¶ (é™åˆ¶é¢‘ç‡)
      const now = Date.now();
      if (!this._lastVolumeEmit) this._lastVolumeEmit = {};
      if (!this._lastVolumeEmit[sourceId] || now - this._lastVolumeEmit[sourceId] > 50) {
        this.emit('volume-update', { sourceId, volume });
        this._lastVolumeEmit[sourceId] = now;
      }

      // ç´¯ç§¯éŸ³é¢‘æ•°æ®
      const accumulator = this.audioAccumulators.get(sourceId);
      const newAccumulator = new Float32Array(accumulator.length + inputData.length);
      newAccumulator.set(accumulator);
      newAccumulator.set(inputData, accumulator.length);
      this.audioAccumulators.set(sourceId, newAccumulator);

      const lastSend = this.lastSendTime.get(sourceId) || now;
      const timeSinceLastSend = now - lastSend;
      const accumulatedSamples = newAccumulator.length;

      // åŒé‡æ¡ä»¶è§¦å‘å‘é€
      const shouldSendByTime = timeSinceLastSend >= this.sendInterval;
      const shouldSendBySamples = accumulatedSamples >= this.targetChunkSamples;

      if (shouldSendByTime || shouldSendBySamples) {
        this.sendAudioData(sourceId, now);
      }
    } catch (error) {
      console.error(`[AudioCaptureService] Error processing audio for ${sourceId}:`, error);
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
   */
  sendAudioData(sourceId, timestamp) {
    try {
      const accumulator = this.audioAccumulators.get(sourceId);
      if (!accumulator || accumulator.length === 0) {
        return;
      }

      // ã€VADã€‘é™éŸ³æ£€æµ‹ - è·³è¿‡é™éŸ³æ•°æ®ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
      // æ³¨æ„ï¼šå¦‚æœ shouldSkipSilence ä¸º falseï¼ˆå¦‚ç™¾åº¦æ¨¡å¼ï¼‰ï¼Œåˆ™ä¸è·³è¿‡ï¼Œä»¥é˜²æœåŠ¡ç«¯è¶…æ—¶
      if (this.shouldSkipSilence && this.isSilence(accumulator)) {
        // ã€æ–­å¥ã€‘è‹¥ä¹‹å‰å¤„äºè¯´è¯çŠ¶æ€ï¼Œåˆ™ç´¯è®¡é™éŸ³æ—¶é•¿ï¼›è¶…è¿‡é˜ˆå€¼è§¦å‘â€œåˆ†å¥æäº¤â€
        const wasInSpeech = this.enableSilenceSentenceCommit && !!this.inSpeech.get(sourceId);
        if (wasInSpeech) {
          const chunkDurationMs = (accumulator.length / this.sampleRate) * 1000;
          const prev = this.silenceDurationMs.get(sourceId) || 0;
          const next = prev + chunkDurationMs;
          this.silenceDurationMs.set(sourceId, next);

          const pauseMs = this.sentencePauseThresholdMs || 600;
          const lastCommitAt = this.lastSilenceCommitAt.get(sourceId) || 0;
          const canCommit = timestamp - lastCommitAt >= this.silenceCommitCooldownMs;
          if (next >= pauseMs && canCommit) {
            this.lastSilenceCommitAt.set(sourceId, timestamp);
            // è§¦å‘ä¸»è¿›ç¨‹çš„â€œé™éŸ³æ–­å¥æäº¤â€ï¼ˆcommitCurrentSegment + force_commitï¼‰
            if (window.electronAPI && typeof window.electronAPI.send === 'function') {
              window.electronAPI.send('asr-silence-commit', { sourceId, timestamp, pauseMs });
              console.log(`[AudioCaptureService] ğŸ§© Silence commit triggered for ${sourceId} (silence=${Math.round(next)}ms >= ${pauseMs}ms)`);
            }
            // æ–­å¥åè®¤ä¸ºå½“å‰è¯´è¯æ®µç»“æŸï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡éé™éŸ³é‡æ–°è¿›å…¥è¯´è¯æ®µ
            this.inSpeech.set(sourceId, false);
            this.silenceDurationMs.set(sourceId, 0);
          }
        }

        // æ¸…ç©ºç´¯ç§¯å™¨ï¼Œé¿å…ç´¯ç§¯
        this.audioAccumulators.set(sourceId, new Float32Array());
        this.lastSendTime.set(sourceId, timestamp);

        // æ‰“å°æ—¥å¿—ï¼ˆé™åˆ¶é¢‘ç‡ï¼Œé¿å…åˆ·å±ï¼‰
        const skipCount = (this.silenceSkipCount.get(sourceId) || 0) + 1;
        this.silenceSkipCount.set(sourceId, skipCount);
        if (skipCount <= this.maxSilenceSkipLog || skipCount % 50 === 0) {
          console.log(`[AudioCaptureService] ğŸ”‡ Skipping silence for ${sourceId} (count: ${skipCount})`);
        }
        return;
      }

      // æœ‰å£°éŸ³æ—¶é‡ç½®é™éŸ³è®¡æ•°
      if (this.silenceSkipCount.get(sourceId) > 0) {
        console.log(`[AudioCaptureService] ğŸ¤ Voice detected for ${sourceId} after ${this.silenceSkipCount.get(sourceId)} silence frames`);
        this.silenceSkipCount.set(sourceId, 0);
      }

      // ã€æ–­å¥ã€‘è¿›å…¥è¯´è¯æ®µ/é‡ç½®é™éŸ³ç´¯è®¡
      if (this.enableSilenceSentenceCommit) {
        if (!this.inSpeech.get(sourceId)) {
          this.inSpeech.set(sourceId, true);
        }
        this.silenceDurationMs.set(sourceId, 0);
      }

      // éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
      const normalizedAudio = this.normalizeAudio(accumulator);

      // å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
      if (window.electronAPI && window.electronAPI.send) {
        window.electronAPI.send('asr-audio-data', {
          sourceId,
          audioBuffer: Array.from(normalizedAudio),
          timestamp,
          sampleRate: this.sampleRate
        });

        // æ¯10æ¬¡å‘é€ä¸€æ¬¡æ—¥å¿—
        if (!this._sendCount) this._sendCount = {};
        if (!this._sendCount[sourceId]) this._sendCount[sourceId] = 0;
        this._sendCount[sourceId]++;
        if (this._sendCount[sourceId] % 10 === 0) {
          const durationMs = (normalizedAudio.length / this.sampleRate * 1000).toFixed(0);
          console.log(`[AudioCaptureService] Sent audio #${this._sendCount[sourceId]} for ${sourceId}, samples: ${normalizedAudio.length}, duration: ${durationMs}ms`);
        }
      }

      // æ¸…ç©ºç´¯ç§¯å™¨
      this.audioAccumulators.set(sourceId, new Float32Array());
      this.lastSendTime.set(sourceId, timestamp);
    } catch (error) {
      console.error(`[AudioCaptureService] Error sending audio data for ${sourceId}:`, error);
    }
  }

  /**
   * ã€VADã€‘é™éŸ³æ£€æµ‹ - è®¡ç®—éŸ³é¢‘çš„ RMS èƒ½é‡
   * @param {Float32Array} audioData - éŸ³é¢‘æ•°æ®
   * @returns {boolean} æ˜¯å¦ä¸ºé™éŸ³
   */
  isSilence(audioData) {
    if (!audioData || audioData.length === 0) {
      return true;
    }

    // è®¡ç®— RMS (Root Mean Square) èƒ½é‡
    let sumSquared = 0;
    for (let i = 0; i < audioData.length; i++) {
      sumSquared += audioData[i] * audioData[i];
    }
    const rms = Math.sqrt(sumSquared / audioData.length);

    return rms < this.silenceThreshold;
  }

  /**
   * éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
   */
  normalizeAudio(audioData) {
    if (!audioData || audioData.length === 0) {
      return audioData;
    }

    let maxAbs = 0;
    for (let i = 0; i < audioData.length; i++) {
      const abs = Math.abs(audioData[i]);
      if (abs > maxAbs) {
        maxAbs = abs;
      }
    }

    if (maxAbs < 0.001) {
      return audioData;
    }

    const normalized = new Float32Array(audioData.length);
    if (maxAbs > 0.95) {
      normalized.set(audioData);
    } else {
      const scale = Math.min(0.95 / maxAbs, 1.5);
      for (let i = 0; i < audioData.length; i++) {
        normalized[i] = audioData[i] * scale;
      }
    }

    return normalized;
  }

  /**
   * åœæ­¢æ•è·éŸ³é¢‘
   */
  async stopCapture(sourceId) {
    try {
      console.log(`[AudioCaptureService] Stopping capture for ${sourceId}`);

      const scriptProcessor = this.scriptProcessors.get(sourceId);
      if (scriptProcessor) {
        scriptProcessor.disconnect();
        scriptProcessor.onaudioprocess = null;
        this.scriptProcessors.delete(sourceId);
      }

      const sourceNode = this.sourceNodes.get(sourceId);
      if (sourceNode) {
        sourceNode.disconnect();
        this.sourceNodes.delete(sourceId);
      }

      const stream = this.streams.get(sourceId);
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        this.streams.delete(sourceId);
      }

      this.audioAccumulators.delete(sourceId);
      this.lastSendTime.delete(sourceId);
      this.silenceDurationMs.delete(sourceId);
      this.inSpeech.delete(sourceId);
      this.lastSilenceCommitAt.delete(sourceId);

      console.log(`[AudioCaptureService] âœ… Capture stopped for ${sourceId}`);

      if (this.streams.size === 0) {
        this.isCapturing = false;
        console.log(`[AudioCaptureService] All captures stopped`);
      }

      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] Error stopping capture for ${sourceId}:`, error);
      throw error;
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘æ•è·
   */
  async stopAllCaptures() {
    try {
      console.log('[AudioCaptureService] Stopping all captures');

      const sourceIds = Array.from(this.streams.keys());
      for (const sourceId of sourceIds) {
        await this.stopCapture(sourceId);
      }

      if (this.audioContext) {
        await this.audioContext.close();
        this.audioContext = null;
      }

      console.log('[AudioCaptureService] All captures stopped');
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error stopping all captures:', error);
      throw error;
    }
  }

  /**
   * æšä¸¾éŸ³é¢‘è¾“å…¥è®¾å¤‡
   */
  async enumerateDevices() {
    try {
      await navigator.mediaDevices.getUserMedia({ audio: true });
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `éº¦å…‹é£ ${device.deviceId.substring(0, 8)}`,
          kind: device.kind
        }));

      console.log(`[AudioCaptureService] Found ${audioInputs.length} audio input devices`);
      return audioInputs;
    } catch (error) {
      console.error('[AudioCaptureService] Error enumerating devices:', error);
      throw error;
    }
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getState() {
    return {
      isCapturing: this.isCapturing,
      activeSources: Array.from(this.streams.keys()),
      sampleRate: this.sampleRate,
      audioContextState: this.audioContext ? this.audioContext.state : 'closed'
    };
  }

  /**
   * é”€æ¯æœåŠ¡
   */
  destroy() {
    this.stopAllCaptures();
    console.log('[AudioCaptureService] Destroyed');
  }

  /**
   * ä» ASR é»˜è®¤é…ç½®åˆ·æ–°â€œåœé¡¿é˜ˆå€¼â€ï¼ˆç”¨äºé™éŸ³æ–­å¥ï¼‰
   * - ä»…ç”¨äºæ¸²æŸ“è¿›ç¨‹ä¾§æ–­å¥ï¼ˆä¸å½±å“åç«¯æ¨¡å‹ VADï¼‰
   */
  async refreshVadConfigFromASRDefault(force = false) {
    try {
      const api = window.electronAPI;
      if (!api?.asrGetConfigs) {
        return;
      }

      const now = Date.now();
      if (!force && this._vadConfigLastRefreshAt && now - this._vadConfigLastRefreshAt < 5000) {
        return;
      }
      this._vadConfigLastRefreshAt = now;

      const configs = await api.asrGetConfigs();
      const defaultConfig = configs?.find((c) => c?.is_default === 1) || configs?.[0];
      const modelName = String(defaultConfig?.model_name || '');
      // ä»…äº‘ç«¯ ASR å¯ç”¨â€œé™éŸ³æ–­å¥ç”Ÿæˆå¤šæ¡æ¶ˆæ¯â€ï¼Œé¿å…å½±å“ FunASR
      // æ³¨æ„ï¼šç™¾åº¦ WebSocket è‡ªå¸¦æ–­å¥ï¼Œä¸å†ç”±å‰ç«¯å¹²é¢„ï¼Œé¿å… 1005 é”™è¯¯
      this.enableSilenceSentenceCommit = modelName.includes('cloud') && !modelName.includes('baidu');
      
      // å¯¹äºç™¾åº¦ï¼Œæˆ‘ä»¬ã€ä¸è¦ã€‘åœ¨æœ¬åœ°è·³è¿‡é™éŸ³åŒ…ã€‚
      // å› ä¸ºç™¾åº¦æœåŠ¡ç«¯å¦‚æœè¶…è¿‡ 10s-20s æ”¶ä¸åˆ°éŸ³é¢‘åŒ…ï¼Œä¼šæŠ¥ -3101 è¶…æ—¶é”™è¯¯ã€‚
      // æˆ‘ä»¬æŠŠæ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬é™éŸ³ï¼‰éƒ½å‘ç»™ç™¾åº¦ï¼Œè®©ç™¾åº¦å¼ºå¤§çš„æœåŠ¡ç«¯ VAD å»å¤„ç†ã€‚
      this.shouldSkipSilence = !modelName.includes('baidu');

      const pauseSecRaw = Number(defaultConfig?.sentence_pause_threshold);
      if (!Number.isFinite(pauseSecRaw) || pauseSecRaw <= 0) {
        return;
      }
      // å…è®¸æ›´ä½çš„é˜ˆå€¼ï¼Œä½†ç»™ä¸€ä¸ªå®‰å…¨ä¸‹é™ï¼Œé¿å… 0 å¯¼è‡´é¢‘ç¹æ–­å¥
      const pauseMs = Math.max(250, Math.round(pauseSecRaw * 1000));
      if (pauseMs !== this.sentencePauseThresholdMs) {
        this.sentencePauseThresholdMs = pauseMs;
        console.log(`[AudioCaptureService] Updated sentencePauseThresholdMs=${pauseMs}ms (enableSilenceSentenceCommit=${this.enableSilenceSentenceCommit}) from ASR config (model=${modelName}, sentence_pause_threshold=${pauseSecRaw}s)`);
      }
    } catch (err) {
      console.warn('[AudioCaptureService] Failed to refresh VAD config from ASR settings:', err);
    }
  }
}

// å¯¼å‡ºå•ä¾‹
const audioCaptureService = new AudioCaptureService();
export default audioCaptureService;
