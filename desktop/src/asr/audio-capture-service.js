/**
 * éŸ³é¢‘æ•è·æœåŠ¡ï¼ˆåœ¨æ¸²æŸ“è¿›ç¨‹ä¸­è¿è¡Œï¼‰
 * ä½¿ç”¨ electron-audio-loopback + getDisplayMedia æ•è·ç³»ç»ŸéŸ³é¢‘
 * ä½¿ç”¨ getUserMedia æ•è·éº¦å…‹é£éŸ³é¢‘
 */
class AudioCaptureService {
  constructor() {
    this.audioContext = null;
    this.sourceNodes = new Map(); // sourceId -> MediaStreamAudioSourceNode
    this.scriptProcessors = new Map(); // sourceId -> ScriptProcessorNode
    this.streams = new Map(); // sourceId -> MediaStream
    this.isCapturing = false;

    // éŸ³é¢‘å‚æ•°
    this.sampleRate = 16000; // Whisper è¦æ±‚çš„é‡‡æ ·ç‡
    this.bufferSize = 4096; // è„šæœ¬å¤„ç†å™¨ç¼“å†²åŒºå¤§å°

    // ã€ä¼˜åŒ–ã€‘ä¸FunASRçš„chunkStrideå¯¹é½ï¼š9600 samples = 600ms
    this.targetChunkSamples = 9600;
    this.sendInterval = 600; // å‘é€é—´éš”ï¼ˆmsï¼‰

    // ã€VADã€‘é™éŸ³æ£€æµ‹é…ç½® - è¿‡æ»¤é™éŸ³ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
    this.silenceThreshold = 0.008; // é™éŸ³é˜ˆå€¼ï¼ˆRMSèƒ½é‡ï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºé™éŸ³
    this.silenceSkipCount = new Map(); // sourceId -> è¿ç»­è·³è¿‡é™éŸ³çš„æ¬¡æ•°
    this.maxSilenceSkipLog = 5; // æœ€å¤šæ‰“å°å‡ æ¬¡é™éŸ³è·³è¿‡æ—¥å¿—

    // éŸ³é¢‘æ•°æ®ç´¯ç§¯
    this.audioAccumulators = new Map(); // sourceId -> Float32Array
    this.lastSendTime = new Map(); // sourceId -> timestamp

    // ã€å…±äº«æµã€‘å·²æˆæƒçš„ç³»ç»ŸéŸ³é¢‘æµï¼ˆè·¨çª—å£å…±äº«ï¼‰
    this.cachedSystemAudioStream = null;
    this.systemAudioStreamAuthorized = false;

    // äº‹ä»¶ç›‘å¬å™¨
    this.listeners = new Map();

    console.log('[AudioCaptureService] Created');
  }

  on(event, callback) {
    if (!this.listeners.has(event)) {
      this.listeners.set(event, new Set());
    }
    this.listeners.get(event).add(callback);
  }

  off(event, callback) {
    if (this.listeners.has(event)) {
      this.listeners.get(event).delete(callback);
    }
  }

  emit(event, data) {
    if (this.listeners.has(event)) {
      this.listeners.get(event).forEach(callback => {
        try {
          callback(data);
        } catch (err) {
          console.error(`[AudioCaptureService] Error in listener for ${event}:`, err);
        }
      });
    }
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
   */
  async initialize() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: this.sampleRate
      });

      console.log('[AudioCaptureService] Initialized, sample rate:', this.sampleRate);
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error initializing:', error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·éº¦å…‹é£éŸ³é¢‘
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker1ï¼‰
   * @param {string} deviceId - éŸ³é¢‘è®¾å¤‡ ID
   */
  async startMicrophoneCapture(sourceId, deviceId = null) {
    try {
      if (!this.audioContext) {
        await this.initialize();
      }

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting microphone capture for ${sourceId}, device: ${deviceId || 'default'}`);

      const constraints = {
        audio: {
          deviceId: deviceId ? { exact: deviceId } : undefined,
          sampleRate: this.sampleRate,
          channelCount: 1,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log(`[AudioCaptureService] âœ… Microphone stream obtained`);

      this.setupAudioProcessing(sourceId, stream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting microphone capture:`, error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·ç³»ç»ŸéŸ³é¢‘ï¼ˆä½¿ç”¨ electron-audio-loopbackï¼‰
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker2ï¼‰
   * @param {Object} options - é€‰é¡¹
   * @param {boolean} options.useCachedStream - æ˜¯å¦ä½¿ç”¨å·²ç¼“å­˜çš„æµï¼ˆé¿å…å¼¹å‡ºé€‰æ‹©çª—å£ï¼‰
   * @param {boolean} options.forceNewStream - å¼ºåˆ¶è·å–æ–°æµï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
   */
  async startSystemAudioCapture(sourceId, options = {}) {
    try {
      const { useCachedStream = true, forceNewStream = false } = options;

      if (!this.audioContext) {
        await this.initialize();
      }

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting system audio capture for ${sourceId}, options:`, { useCachedStream, forceNewStream });

      // ã€ä¼˜åŒ–ã€‘ä¼˜å…ˆä½¿ç”¨å·²ç¼“å­˜çš„ç³»ç»ŸéŸ³é¢‘æµï¼ˆé¿å…æ¯æ¬¡éƒ½å¼¹å‡ºé€‰æ‹©çª—å£ï¼‰
      if (useCachedStream && !forceNewStream && this.cachedSystemAudioStream) {
        const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
        const hasActiveTrack = audioTracks.some(track => track.readyState === 'live' && track.enabled);

        if (hasActiveTrack) {
          console.log(`[AudioCaptureService] âœ… Using cached system audio stream with ${audioTracks.length} audio track(s)`);
          this.setupAudioProcessing(sourceId, this.cachedSystemAudioStream);
          return true;
        } else {
          console.log('[AudioCaptureService] Cached stream is no longer active, will request new stream');
          this.cachedSystemAudioStream = null;
          this.systemAudioStreamAuthorized = false;
        }
      }

      // ä½¿ç”¨ electron-audio-loopback æ–¹æ¡ˆ
      // 1. å¯ç”¨ loopback éŸ³é¢‘
      if (window.electronAPI?.enableLoopbackAudio) {
        await window.electronAPI.enableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio enabled');
      }

      let displayStream;

      // å°è¯•ä½¿ç”¨ getDesktopSourceId è·å–æº IDï¼Œä»¥é¿å¼€é€‰æ‹©å™¨å¼¹çª—
      if (window.electronAPI?.getDesktopSourceId) {
        try {
          const sourceId = await window.electronAPI.getDesktopSourceId();
          if (sourceId) {
            console.log(`[AudioCaptureService] Got desktop source ID: ${sourceId}, attempting getUserMedia`);
            displayStream = await navigator.mediaDevices.getUserMedia({
              audio: {
                mandatory: {
                  chromeMediaSource: 'desktop',
                  chromeMediaSourceId: sourceId
                }
              },
              video: {
                mandatory: {
                  chromeMediaSource: 'desktop',
                  chromeMediaSourceId: sourceId
                }
              }
            });
            console.log('[AudioCaptureService] âœ… System audio stream obtained via getUserMedia (no picker)');
          }
        } catch (err) {
          console.warn('[AudioCaptureService] Failed to get stream via getUserMedia, falling back to getDisplayMedia:', err);
        }
      }

      // å¦‚æœ getUserMedia å¤±è´¥æˆ–ä¸å¯ç”¨ï¼Œå›é€€åˆ° getDisplayMedia (ä¼šå¼¹å‡ºé€‰æ‹©å™¨)
      if (!displayStream) {
        console.log('[AudioCaptureService] Falling back to getDisplayMedia (picker will appear)');
        displayStream = await navigator.mediaDevices.getDisplayMedia({
          audio: true,
          video: true // éœ€è¦åŒæ—¶è¯·æ±‚è§†é¢‘æ‰èƒ½è·å–éŸ³é¢‘
        });
      }

      // 3. ç¦ç”¨ loopback éŸ³é¢‘ï¼ˆè·å–æµåå³å¯ç¦ç”¨ï¼‰
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio disabled');
      }

      // 4. åœæ­¢è§†é¢‘è½¨é“ï¼ˆæˆ‘ä»¬åªéœ€è¦éŸ³é¢‘ï¼‰
      const videoTracks = displayStream.getVideoTracks();
      videoTracks.forEach(track => {
        track.stop();
        displayStream.removeTrack(track);
        console.log(`[AudioCaptureService] Video track stopped: ${track.label}`);
      });

      // 5. æ£€æŸ¥éŸ³é¢‘è½¨é“
      const audioTracks = displayStream.getAudioTracks();
      if (audioTracks.length === 0) {
        throw new Error('No audio tracks in display stream');
      }

      console.log(`[AudioCaptureService] âœ… System audio stream obtained with ${audioTracks.length} audio track(s)`);
      audioTracks.forEach((track, index) => {
        console.log(`[AudioCaptureService] Audio track ${index + 1}: label=${track.label}, enabled=${track.enabled}`);
      });

      // ã€ç¼“å­˜ã€‘ä¿å­˜å·²æˆæƒçš„æµä¾›åç»­ä½¿ç”¨
      this.cachedSystemAudioStream = displayStream;
      this.systemAudioStreamAuthorized = true;
      console.log('[AudioCaptureService] System audio stream cached for reuse');

      this.setupAudioProcessing(sourceId, displayStream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting system audio capture:`, error);

      // ç¡®ä¿ç¦ç”¨ loopback
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio().catch(() => { });
      }

      throw error;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦æœ‰å·²æˆæƒçš„ç³»ç»ŸéŸ³é¢‘æµå¯ç”¨
   * @returns {boolean} æ˜¯å¦æœ‰å¯ç”¨çš„ç¼“å­˜æµ
   */
  hasAuthorizedSystemAudioStream() {
    if (!this.cachedSystemAudioStream) {
      return false;
    }
    const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
    return audioTracks.some(track => track.readyState === 'live' && track.enabled);
  }

  /**
   * è·å–ç³»ç»ŸéŸ³é¢‘æµçŠ¶æ€
   * @returns {Object} çŠ¶æ€ä¿¡æ¯
   */
  getSystemAudioStreamStatus() {
    if (!this.cachedSystemAudioStream) {
      return {
        available: false,
        authorized: false,
        message: 'æœªæˆæƒç³»ç»ŸéŸ³é¢‘ï¼Œéœ€è¦åœ¨è®¾ç½®é¡µé¢æµ‹è¯•éŸ³é¢‘åæ‰èƒ½ä½¿ç”¨'
      };
    }

    const audioTracks = this.cachedSystemAudioStream.getAudioTracks();
    const hasActiveTrack = audioTracks.some(track => track.readyState === 'live' && track.enabled);

    if (hasActiveTrack) {
      return {
        available: true,
        authorized: true,
        trackCount: audioTracks.length,
        message: 'ç³»ç»ŸéŸ³é¢‘å·²æˆæƒå¹¶å¯ç”¨'
      };
    } else {
      return {
        available: false,
        authorized: this.systemAudioStreamAuthorized,
        message: 'ç³»ç»ŸéŸ³é¢‘æµå·²è¿‡æœŸï¼Œéœ€è¦é‡æ–°æˆæƒ'
      };
    }
  }

  /**
   * è®¾ç½®éŸ³é¢‘å¤„ç†ç®¡é“
   * @param {string} sourceId - éŸ³é¢‘æº ID
   * @param {MediaStream} stream - åª’ä½“æµ
   */
  setupAudioProcessing(sourceId, stream) {
    this.streams.set(sourceId, stream);

    // åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹
    const sourceNode = this.audioContext.createMediaStreamSource(stream);
    this.sourceNodes.set(sourceId, sourceNode);

    // åˆ›å»ºè„šæœ¬å¤„ç†å™¨
    const scriptProcessor = this.audioContext.createScriptProcessor(
      this.bufferSize,
      1, // è¾“å…¥å£°é“æ•°
      1  // è¾“å‡ºå£°é“æ•°
    );
    this.scriptProcessors.set(sourceId, scriptProcessor);

    // åˆå§‹åŒ–éŸ³é¢‘ç´¯ç§¯å™¨
    this.audioAccumulators.set(sourceId, new Float32Array());
    this.lastSendTime.set(sourceId, Date.now());

    // è®¾ç½®éŸ³é¢‘å¤„ç†å›è°ƒ
    scriptProcessor.onaudioprocess = (event) => {
      this.handleAudioProcess(sourceId, event);
    };

    // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
    sourceNode.connect(scriptProcessor);
    scriptProcessor.connect(this.audioContext.destination);

    console.log(`[AudioCaptureService] âœ… Audio processing setup complete for ${sourceId}`);
    this.isCapturing = true;
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®
   */
  handleAudioProcess(sourceId, event) {
    try {
      const inputData = event.inputBuffer.getChannelData(0);

      // è®¡ç®—å®æ—¶éŸ³é‡ (RMS)
      let sumSquared = 0;
      for (let i = 0; i < inputData.length; i++) {
        sumSquared += inputData[i] * inputData[i];
      }
      const rms = Math.sqrt(sumSquared / inputData.length);

      // ä½¿ç”¨ dB è®¡ç®—éŸ³é‡ï¼Œä½¿å…¶æ›´ç¬¦åˆäººè€³æ„ŸçŸ¥ (Logarithmic)
      // å‡è®¾æœ€å°å¯æ„ŸçŸ¥éŸ³é‡ä¸º -60dBï¼Œæœ€å¤§ä¸º 0dB
      let volume = 0;
      if (rms > 0) {
        const db = 20 * Math.log10(rms);
        // å°† -60dB ~ 0dB æ˜ å°„åˆ° 0 ~ 100
        volume = Math.max(0, Math.min(100, (db + 60) / 60 * 100));
      }

      // å‘é€éŸ³é‡æ›´æ–°äº‹ä»¶ (é™åˆ¶é¢‘ç‡)
      const now = Date.now();
      if (!this._lastVolumeEmit) this._lastVolumeEmit = {};
      if (!this._lastVolumeEmit[sourceId] || now - this._lastVolumeEmit[sourceId] > 50) {
        this.emit('volume-update', { sourceId, volume });
        this._lastVolumeEmit[sourceId] = now;
      }

      // ç´¯ç§¯éŸ³é¢‘æ•°æ®
      const accumulator = this.audioAccumulators.get(sourceId);
      const newAccumulator = new Float32Array(accumulator.length + inputData.length);
      newAccumulator.set(accumulator);
      newAccumulator.set(inputData, accumulator.length);
      this.audioAccumulators.set(sourceId, newAccumulator);

      const lastSend = this.lastSendTime.get(sourceId) || now;
      const timeSinceLastSend = now - lastSend;
      const accumulatedSamples = newAccumulator.length;

      // åŒé‡æ¡ä»¶è§¦å‘å‘é€
      const shouldSendByTime = timeSinceLastSend >= this.sendInterval;
      const shouldSendBySamples = accumulatedSamples >= this.targetChunkSamples;

      if (shouldSendByTime || shouldSendBySamples) {
        this.sendAudioData(sourceId, now);
      }
    } catch (error) {
      console.error(`[AudioCaptureService] Error processing audio for ${sourceId}:`, error);
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
   */
  sendAudioData(sourceId, timestamp) {
    try {
      const accumulator = this.audioAccumulators.get(sourceId);
      if (!accumulator || accumulator.length === 0) {
        return;
      }

      // ã€VADã€‘é™éŸ³æ£€æµ‹ - è·³è¿‡é™éŸ³æ•°æ®ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
      if (this.isSilence(accumulator)) {
        // æ¸…ç©ºç´¯ç§¯å™¨ï¼Œé¿å…ç´¯ç§¯
        this.audioAccumulators.set(sourceId, new Float32Array());
        this.lastSendTime.set(sourceId, timestamp);

        // æ‰“å°æ—¥å¿—ï¼ˆé™åˆ¶é¢‘ç‡ï¼Œé¿å…åˆ·å±ï¼‰
        const skipCount = (this.silenceSkipCount.get(sourceId) || 0) + 1;
        this.silenceSkipCount.set(sourceId, skipCount);
        if (skipCount <= this.maxSilenceSkipLog || skipCount % 50 === 0) {
          console.log(`[AudioCaptureService] ğŸ”‡ Skipping silence for ${sourceId} (count: ${skipCount})`);
        }
        return;
      }

      // æœ‰å£°éŸ³æ—¶é‡ç½®é™éŸ³è®¡æ•°
      if (this.silenceSkipCount.get(sourceId) > 0) {
        console.log(`[AudioCaptureService] ğŸ¤ Voice detected for ${sourceId} after ${this.silenceSkipCount.get(sourceId)} silence frames`);
        this.silenceSkipCount.set(sourceId, 0);
      }

      // éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
      const normalizedAudio = this.normalizeAudio(accumulator);

      // å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
      if (window.electronAPI && window.electronAPI.send) {
        window.electronAPI.send('asr-audio-data', {
          sourceId,
          audioBuffer: Array.from(normalizedAudio),
          timestamp,
          sampleRate: this.sampleRate
        });

        // æ¯10æ¬¡å‘é€ä¸€æ¬¡æ—¥å¿—
        if (!this._sendCount) this._sendCount = {};
        if (!this._sendCount[sourceId]) this._sendCount[sourceId] = 0;
        this._sendCount[sourceId]++;
        if (this._sendCount[sourceId] % 10 === 0) {
          const durationMs = (normalizedAudio.length / this.sampleRate * 1000).toFixed(0);
          console.log(`[AudioCaptureService] Sent audio #${this._sendCount[sourceId]} for ${sourceId}, samples: ${normalizedAudio.length}, duration: ${durationMs}ms`);
        }
      }

      // æ¸…ç©ºç´¯ç§¯å™¨
      this.audioAccumulators.set(sourceId, new Float32Array());
      this.lastSendTime.set(sourceId, timestamp);
    } catch (error) {
      console.error(`[AudioCaptureService] Error sending audio data for ${sourceId}:`, error);
    }
  }

  /**
   * ã€VADã€‘é™éŸ³æ£€æµ‹ - è®¡ç®—éŸ³é¢‘çš„ RMS èƒ½é‡
   * @param {Float32Array} audioData - éŸ³é¢‘æ•°æ®
   * @returns {boolean} æ˜¯å¦ä¸ºé™éŸ³
   */
  isSilence(audioData) {
    if (!audioData || audioData.length === 0) {
      return true;
    }

    // è®¡ç®— RMS (Root Mean Square) èƒ½é‡
    let sumSquared = 0;
    for (let i = 0; i < audioData.length; i++) {
      sumSquared += audioData[i] * audioData[i];
    }
    const rms = Math.sqrt(sumSquared / audioData.length);

    return rms < this.silenceThreshold;
  }

  /**
   * éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
   */
  normalizeAudio(audioData) {
    if (!audioData || audioData.length === 0) {
      return audioData;
    }

    let maxAbs = 0;
    for (let i = 0; i < audioData.length; i++) {
      const abs = Math.abs(audioData[i]);
      if (abs > maxAbs) {
        maxAbs = abs;
      }
    }

    if (maxAbs < 0.001) {
      return audioData;
    }

    const normalized = new Float32Array(audioData.length);
    if (maxAbs > 0.95) {
      normalized.set(audioData);
    } else {
      const scale = Math.min(0.95 / maxAbs, 1.5);
      for (let i = 0; i < audioData.length; i++) {
        normalized[i] = audioData[i] * scale;
      }
    }

    return normalized;
  }

  /**
   * åœæ­¢æ•è·éŸ³é¢‘
   */
  async stopCapture(sourceId) {
    try {
      console.log(`[AudioCaptureService] Stopping capture for ${sourceId}`);

      const scriptProcessor = this.scriptProcessors.get(sourceId);
      if (scriptProcessor) {
        scriptProcessor.disconnect();
        scriptProcessor.onaudioprocess = null;
        this.scriptProcessors.delete(sourceId);
      }

      const sourceNode = this.sourceNodes.get(sourceId);
      if (sourceNode) {
        sourceNode.disconnect();
        this.sourceNodes.delete(sourceId);
      }

      const stream = this.streams.get(sourceId);
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        this.streams.delete(sourceId);
      }

      this.audioAccumulators.delete(sourceId);
      this.lastSendTime.delete(sourceId);

      console.log(`[AudioCaptureService] âœ… Capture stopped for ${sourceId}`);

      if (this.streams.size === 0) {
        this.isCapturing = false;
        console.log(`[AudioCaptureService] All captures stopped`);
      }

      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] Error stopping capture for ${sourceId}:`, error);
      throw error;
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘æ•è·
   */
  async stopAllCaptures() {
    try {
      console.log('[AudioCaptureService] Stopping all captures');

      const sourceIds = Array.from(this.streams.keys());
      for (const sourceId of sourceIds) {
        await this.stopCapture(sourceId);
      }

      if (this.audioContext) {
        await this.audioContext.close();
        this.audioContext = null;
      }

      console.log('[AudioCaptureService] All captures stopped');
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error stopping all captures:', error);
      throw error;
    }
  }

  /**
   * æšä¸¾éŸ³é¢‘è¾“å…¥è®¾å¤‡
   */
  async enumerateDevices() {
    try {
      await navigator.mediaDevices.getUserMedia({ audio: true });
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `éº¦å…‹é£ ${device.deviceId.substring(0, 8)}`,
          kind: device.kind
        }));

      console.log(`[AudioCaptureService] Found ${audioInputs.length} audio input devices`);
      return audioInputs;
    } catch (error) {
      console.error('[AudioCaptureService] Error enumerating devices:', error);
      throw error;
    }
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getState() {
    return {
      isCapturing: this.isCapturing,
      activeSources: Array.from(this.streams.keys()),
      sampleRate: this.sampleRate,
      audioContextState: this.audioContext ? this.audioContext.state : 'closed'
    };
  }

  /**
   * é”€æ¯æœåŠ¡
   */
  destroy() {
    this.stopAllCaptures();
    console.log('[AudioCaptureService] Destroyed');
  }
}

// å¯¼å‡ºå•ä¾‹
const audioCaptureService = new AudioCaptureService();
export default audioCaptureService;
