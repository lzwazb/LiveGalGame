/**
 * éŸ³é¢‘æ•è·æœåŠ¡ï¼ˆåœ¨æ¸²æŸ“è¿›ç¨‹ä¸­è¿è¡Œï¼‰
 * ä½¿ç”¨ electron-audio-loopback + getDisplayMedia æ•è·ç³»ç»ŸéŸ³é¢‘
 * ä½¿ç”¨ getUserMedia æ•è·éº¦å…‹é£éŸ³é¢‘
 */
class AudioCaptureService {
  constructor() {
    this.audioContext = null;
    this.sourceNodes = new Map(); // sourceId -> MediaStreamAudioSourceNode
    this.scriptProcessors = new Map(); // sourceId -> ScriptProcessorNode
    this.streams = new Map(); // sourceId -> MediaStream
    this.isCapturing = false;

    // éŸ³é¢‘å‚æ•°
    this.sampleRate = 16000; // Whisper è¦æ±‚çš„é‡‡æ ·ç‡
    this.bufferSize = 4096; // è„šæœ¬å¤„ç†å™¨ç¼“å†²åŒºå¤§å°
    
    // ã€ä¼˜åŒ–ã€‘ä¸FunASRçš„chunkStrideå¯¹é½ï¼š9600 samples = 600ms
    this.targetChunkSamples = 9600;
    this.sendInterval = 600; // å‘é€é—´éš”ï¼ˆmsï¼‰

    // ã€VADã€‘é™éŸ³æ£€æµ‹é…ç½® - è¿‡æ»¤é™éŸ³ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
    this.silenceThreshold = 0.008; // é™éŸ³é˜ˆå€¼ï¼ˆRMSèƒ½é‡ï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºé™éŸ³
    this.silenceSkipCount = new Map(); // sourceId -> è¿ç»­è·³è¿‡é™éŸ³çš„æ¬¡æ•°
    this.maxSilenceSkipLog = 5; // æœ€å¤šæ‰“å°å‡ æ¬¡é™éŸ³è·³è¿‡æ—¥å¿—

    // éŸ³é¢‘æ•°æ®ç´¯ç§¯
    this.audioAccumulators = new Map(); // sourceId -> Float32Array
    this.lastSendTime = new Map(); // sourceId -> timestamp

    console.log('[AudioCaptureService] Created');
  }

  /**
   * åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
   */
  async initialize() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: this.sampleRate
      });

      console.log('[AudioCaptureService] Initialized, sample rate:', this.sampleRate);
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error initializing:', error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·éº¦å…‹é£éŸ³é¢‘
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker1ï¼‰
   * @param {string} deviceId - éŸ³é¢‘è®¾å¤‡ ID
   */
  async startMicrophoneCapture(sourceId, deviceId = null) {
    try {
      if (!this.audioContext) {
        await this.initialize();
      }

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting microphone capture for ${sourceId}, device: ${deviceId || 'default'}`);

      const constraints = {
        audio: {
          deviceId: deviceId ? { exact: deviceId } : undefined,
          sampleRate: this.sampleRate,
          channelCount: 1,
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      console.log(`[AudioCaptureService] âœ… Microphone stream obtained`);

      this.setupAudioProcessing(sourceId, stream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting microphone capture:`, error);
      throw error;
    }
  }

  /**
   * å¼€å§‹æ•è·ç³»ç»ŸéŸ³é¢‘ï¼ˆä½¿ç”¨ electron-audio-loopbackï¼‰
   * @param {string} sourceId - éŸ³é¢‘æº IDï¼ˆspeaker2ï¼‰
   */
  async startSystemAudioCapture(sourceId) {
    try {
      if (!this.audioContext) {
        await this.initialize();
      }

      // å¦‚æœå·²ç»åœ¨æ•è·ï¼Œå…ˆåœæ­¢
      if (this.streams.has(sourceId)) {
        await this.stopCapture(sourceId);
      }

      console.log(`[AudioCaptureService] Starting system audio capture for ${sourceId}`);

      // ä½¿ç”¨ electron-audio-loopback æ–¹æ¡ˆ
      // 1. å¯ç”¨ loopback éŸ³é¢‘
      if (window.electronAPI?.enableLoopbackAudio) {
        await window.electronAPI.enableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio enabled');
      }

      // 2. ä½¿ç”¨ getDisplayMedia è·å–ç³»ç»ŸéŸ³é¢‘
      const displayStream = await navigator.mediaDevices.getDisplayMedia({
        audio: true,
        video: true // éœ€è¦åŒæ—¶è¯·æ±‚è§†é¢‘æ‰èƒ½è·å–éŸ³é¢‘
      });

      // 3. ç¦ç”¨ loopback éŸ³é¢‘ï¼ˆè·å–æµåå³å¯ç¦ç”¨ï¼‰
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio();
        console.log('[AudioCaptureService] Loopback audio disabled');
      }

      // 4. åœæ­¢è§†é¢‘è½¨é“ï¼ˆæˆ‘ä»¬åªéœ€è¦éŸ³é¢‘ï¼‰
      const videoTracks = displayStream.getVideoTracks();
      videoTracks.forEach(track => {
        track.stop();
        displayStream.removeTrack(track);
        console.log(`[AudioCaptureService] Video track stopped: ${track.label}`);
      });

      // 5. æ£€æŸ¥éŸ³é¢‘è½¨é“
      const audioTracks = displayStream.getAudioTracks();
      if (audioTracks.length === 0) {
        throw new Error('No audio tracks in display stream');
      }

      console.log(`[AudioCaptureService] âœ… System audio stream obtained with ${audioTracks.length} audio track(s)`);
      audioTracks.forEach((track, index) => {
        console.log(`[AudioCaptureService] Audio track ${index + 1}: label=${track.label}, enabled=${track.enabled}`);
      });

      this.setupAudioProcessing(sourceId, displayStream);
      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] âŒ Error starting system audio capture:`, error);
      
      // ç¡®ä¿ç¦ç”¨ loopback
      if (window.electronAPI?.disableLoopbackAudio) {
        await window.electronAPI.disableLoopbackAudio().catch(() => {});
      }
      
      throw error;
    }
  }

  /**
   * è®¾ç½®éŸ³é¢‘å¤„ç†ç®¡é“
   * @param {string} sourceId - éŸ³é¢‘æº ID
   * @param {MediaStream} stream - åª’ä½“æµ
   */
  setupAudioProcessing(sourceId, stream) {
    this.streams.set(sourceId, stream);

    // åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹
    const sourceNode = this.audioContext.createMediaStreamSource(stream);
    this.sourceNodes.set(sourceId, sourceNode);

    // åˆ›å»ºè„šæœ¬å¤„ç†å™¨
    const scriptProcessor = this.audioContext.createScriptProcessor(
      this.bufferSize,
      1, // è¾“å…¥å£°é“æ•°
      1  // è¾“å‡ºå£°é“æ•°
    );
    this.scriptProcessors.set(sourceId, scriptProcessor);

    // åˆå§‹åŒ–éŸ³é¢‘ç´¯ç§¯å™¨
    this.audioAccumulators.set(sourceId, new Float32Array());
    this.lastSendTime.set(sourceId, Date.now());

    // è®¾ç½®éŸ³é¢‘å¤„ç†å›è°ƒ
    scriptProcessor.onaudioprocess = (event) => {
      this.handleAudioProcess(sourceId, event);
    };

    // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
    sourceNode.connect(scriptProcessor);
    scriptProcessor.connect(this.audioContext.destination);

    console.log(`[AudioCaptureService] âœ… Audio processing setup complete for ${sourceId}`);
    this.isCapturing = true;
  }

  /**
   * å¤„ç†éŸ³é¢‘æ•°æ®
   */
  handleAudioProcess(sourceId, event) {
    try {
      const inputData = event.inputBuffer.getChannelData(0);

      // ç´¯ç§¯éŸ³é¢‘æ•°æ®
      const accumulator = this.audioAccumulators.get(sourceId);
      const newAccumulator = new Float32Array(accumulator.length + inputData.length);
      newAccumulator.set(accumulator);
      newAccumulator.set(inputData, accumulator.length);
      this.audioAccumulators.set(sourceId, newAccumulator);

      const now = Date.now();
      const lastSend = this.lastSendTime.get(sourceId) || now;
      const timeSinceLastSend = now - lastSend;
      const accumulatedSamples = newAccumulator.length;

      // åŒé‡æ¡ä»¶è§¦å‘å‘é€
      const shouldSendByTime = timeSinceLastSend >= this.sendInterval;
      const shouldSendBySamples = accumulatedSamples >= this.targetChunkSamples;

      if (shouldSendByTime || shouldSendBySamples) {
        this.sendAudioData(sourceId, now);
      }
    } catch (error) {
      console.error(`[AudioCaptureService] Error processing audio for ${sourceId}:`, error);
    }
  }

  /**
   * å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
   */
  sendAudioData(sourceId, timestamp) {
    try {
      const accumulator = this.audioAccumulators.get(sourceId);
      if (!accumulator || accumulator.length === 0) {
        return;
      }

      // ã€VADã€‘é™éŸ³æ£€æµ‹ - è·³è¿‡é™éŸ³æ•°æ®ï¼Œé¿å… ASR æ¨¡å‹äº§ç”Ÿå¹»è§‰
      if (this.isSilence(accumulator)) {
        // æ¸…ç©ºç´¯ç§¯å™¨ï¼Œé¿å…ç´¯ç§¯
        this.audioAccumulators.set(sourceId, new Float32Array());
        this.lastSendTime.set(sourceId, timestamp);

        // æ‰“å°æ—¥å¿—ï¼ˆé™åˆ¶é¢‘ç‡ï¼Œé¿å…åˆ·å±ï¼‰
        const skipCount = (this.silenceSkipCount.get(sourceId) || 0) + 1;
        this.silenceSkipCount.set(sourceId, skipCount);
        if (skipCount <= this.maxSilenceSkipLog || skipCount % 50 === 0) {
          console.log(`[AudioCaptureService] ğŸ”‡ Skipping silence for ${sourceId} (count: ${skipCount})`);
        }
        return;
      }

      // æœ‰å£°éŸ³æ—¶é‡ç½®é™éŸ³è®¡æ•°
      if (this.silenceSkipCount.get(sourceId) > 0) {
        console.log(`[AudioCaptureService] ğŸ¤ Voice detected for ${sourceId} after ${this.silenceSkipCount.get(sourceId)} silence frames`);
        this.silenceSkipCount.set(sourceId, 0);
      }

      // éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
      const normalizedAudio = this.normalizeAudio(accumulator);

      // å‘é€éŸ³é¢‘æ•°æ®åˆ°ä¸»è¿›ç¨‹
      if (window.electronAPI && window.electronAPI.send) {
        window.electronAPI.send('asr-audio-data', {
          sourceId,
          audioBuffer: Array.from(normalizedAudio),
          timestamp,
          sampleRate: this.sampleRate
        });

        // æ¯10æ¬¡å‘é€ä¸€æ¬¡æ—¥å¿—
        if (!this._sendCount) this._sendCount = {};
        if (!this._sendCount[sourceId]) this._sendCount[sourceId] = 0;
        this._sendCount[sourceId]++;
        if (this._sendCount[sourceId] % 10 === 0) {
          const durationMs = (normalizedAudio.length / this.sampleRate * 1000).toFixed(0);
          console.log(`[AudioCaptureService] Sent audio #${this._sendCount[sourceId]} for ${sourceId}, samples: ${normalizedAudio.length}, duration: ${durationMs}ms`);
        }
      }

      // æ¸…ç©ºç´¯ç§¯å™¨
      this.audioAccumulators.set(sourceId, new Float32Array());
      this.lastSendTime.set(sourceId, timestamp);
    } catch (error) {
      console.error(`[AudioCaptureService] Error sending audio data for ${sourceId}:`, error);
    }
  }

  /**
   * ã€VADã€‘é™éŸ³æ£€æµ‹ - è®¡ç®—éŸ³é¢‘çš„ RMS èƒ½é‡
   * @param {Float32Array} audioData - éŸ³é¢‘æ•°æ®
   * @returns {boolean} æ˜¯å¦ä¸ºé™éŸ³
   */
  isSilence(audioData) {
    if (!audioData || audioData.length === 0) {
      return true;
    }

    // è®¡ç®— RMS (Root Mean Square) èƒ½é‡
    let sumSquared = 0;
    for (let i = 0; i < audioData.length; i++) {
      sumSquared += audioData[i] * audioData[i];
    }
    const rms = Math.sqrt(sumSquared / audioData.length);

    return rms < this.silenceThreshold;
  }

  /**
   * éŸ³é¢‘å½’ä¸€åŒ–å¤„ç†
   */
  normalizeAudio(audioData) {
    if (!audioData || audioData.length === 0) {
      return audioData;
    }

    let maxAbs = 0;
    for (let i = 0; i < audioData.length; i++) {
      const abs = Math.abs(audioData[i]);
      if (abs > maxAbs) {
        maxAbs = abs;
      }
    }

    if (maxAbs < 0.001) {
      return audioData;
    }

    const normalized = new Float32Array(audioData.length);
    if (maxAbs > 0.95) {
      normalized.set(audioData);
    } else {
      const scale = Math.min(0.95 / maxAbs, 1.5);
      for (let i = 0; i < audioData.length; i++) {
        normalized[i] = audioData[i] * scale;
      }
    }

    return normalized;
  }

  /**
   * åœæ­¢æ•è·éŸ³é¢‘
   */
  async stopCapture(sourceId) {
    try {
      console.log(`[AudioCaptureService] Stopping capture for ${sourceId}`);

      const scriptProcessor = this.scriptProcessors.get(sourceId);
      if (scriptProcessor) {
        scriptProcessor.disconnect();
        scriptProcessor.onaudioprocess = null;
        this.scriptProcessors.delete(sourceId);
      }

      const sourceNode = this.sourceNodes.get(sourceId);
      if (sourceNode) {
        sourceNode.disconnect();
        this.sourceNodes.delete(sourceId);
      }

      const stream = this.streams.get(sourceId);
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
        this.streams.delete(sourceId);
      }

      this.audioAccumulators.delete(sourceId);
      this.lastSendTime.delete(sourceId);

      console.log(`[AudioCaptureService] âœ… Capture stopped for ${sourceId}`);

      if (this.streams.size === 0) {
        this.isCapturing = false;
        console.log(`[AudioCaptureService] All captures stopped`);
      }

      return true;
    } catch (error) {
      console.error(`[AudioCaptureService] Error stopping capture for ${sourceId}:`, error);
      throw error;
    }
  }

  /**
   * åœæ­¢æ‰€æœ‰éŸ³é¢‘æ•è·
   */
  async stopAllCaptures() {
    try {
      console.log('[AudioCaptureService] Stopping all captures');

      const sourceIds = Array.from(this.streams.keys());
      for (const sourceId of sourceIds) {
        await this.stopCapture(sourceId);
      }

      if (this.audioContext) {
        await this.audioContext.close();
        this.audioContext = null;
      }

      console.log('[AudioCaptureService] All captures stopped');
      return true;
    } catch (error) {
      console.error('[AudioCaptureService] Error stopping all captures:', error);
      throw error;
    }
  }

  /**
   * æšä¸¾éŸ³é¢‘è¾“å…¥è®¾å¤‡
   */
  async enumerateDevices() {
    try {
      await navigator.mediaDevices.getUserMedia({ audio: true });
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices
        .filter(device => device.kind === 'audioinput')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || `éº¦å…‹é£ ${device.deviceId.substring(0, 8)}`,
          kind: device.kind
        }));

      console.log(`[AudioCaptureService] Found ${audioInputs.length} audio input devices`);
      return audioInputs;
    } catch (error) {
      console.error('[AudioCaptureService] Error enumerating devices:', error);
      throw error;
    }
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getState() {
    return {
      isCapturing: this.isCapturing,
      activeSources: Array.from(this.streams.keys()),
      sampleRate: this.sampleRate,
      audioContextState: this.audioContext ? this.audioContext.state : 'closed'
    };
  }

  /**
   * é”€æ¯æœåŠ¡
   */
  destroy() {
    this.stopAllCaptures();
    console.log('[AudioCaptureService] Destroyed');
  }
}

// å¯¼å‡ºå•ä¾‹
const audioCaptureService = new AudioCaptureService();
export default audioCaptureService;
