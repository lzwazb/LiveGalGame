#!/usr/bin/env python3
# coding: utf-8
"""
SiliconFlow ASR Worker - Parallel Redundant Architecture (å¹¶è¡Œå†—ä½™æ¶æ„)

ç­–ç•¥ï¼š
- VAD ç²¾å‡†æ–­å¥ï¼šä½¿ç”¨ FunASR è½»é‡çº§ FSMN-VAD æ¨¡å‹ï¼ˆæœ¬åœ°æ¨ç†ï¼Œå»¶è¿Ÿä½ï¼‰
- å¹¶è¡Œå†—ä½™è¯·æ±‚ï¼šæ¯æ®µéŸ³é¢‘åŒæ—¶å‘é€ N ä¸ªï¼ˆé»˜è®¤2ä¸ªï¼‰è¯·æ±‚åˆ°äº‘ç«¯ API
- Race æœºåˆ¶ï¼šåªæ¥å—æœ€å…ˆè¿”å›çš„ç»“æœï¼Œå…¶ä»–è‡ªåŠ¨å–æ¶ˆ
- æ®µè½ç‹¬ç«‹ï¼šæ¯æ®µéŸ³é¢‘ç‹¬ç«‹å¤„ç†ï¼Œä¸ç­‰å¾…å‰ä¸€æ®µå®Œæˆ

ä¼˜åŠ¿ï¼š
- é«˜å¯é æ€§ï¼šå•ä¸ªè¯·æ±‚å¤±è´¥ä¸å½±å“ç»“æœ
- ä½å»¶è¿Ÿï¼šæ€»æ˜¯å–æœ€å¿«è¿”å›çš„é‚£ä¸ª
- ç®€åŒ–é€»è¾‘ï¼šæ— éœ€å¤æ‚çš„é‡è¯•å’Œè¡¥å¿æœºåˆ¶
"""

import base64
import concurrent.futures
import io
import json
import os
import platform
import sys
import time
import traceback
import wave
from dataclasses import dataclass, field
from typing import Dict, List, Optional

import numpy as np

# ==============================================================================
# IPC é€šé“é‡å®šå‘
# ==============================================================================
ipc_fd = os.dup(sys.stdout.fileno())
ipc_channel = os.fdopen(ipc_fd, "w", buffering=1, encoding="utf-8")
os.dup2(sys.stderr.fileno(), sys.stdout.fileno())
sys.stdout = sys.stderr


def send_ipc_message(data: dict):
    try:
        ipc_channel.write(json.dumps(data, ensure_ascii=False) + "\n")
        ipc_channel.flush()
    except Exception as exc:
        sys.stderr.write(f"[IPC Error] {exc}\n")
        sys.stderr.flush()


# ==============================================================================
# é…ç½®
# ==============================================================================
API_URL = "https://api.siliconflow.cn/v1/audio/transcriptions"
_SF_API_KEY_OBFUSCATED = "c2staWJndG9zZmhuYmZxbmlueWVtYnRvY3B2eGJ2aG1qb3JuemJsZWZteWxlamd2a2xr"
API_KEY = os.environ.get("SILICONFLOW_API_KEY", base64.b64decode(_SF_API_KEY_OBFUSCATED).decode()).strip()
MODEL_NAME = os.environ.get("SILICONFLOW_MODEL", "TeleAI/TeleSpeechASR").strip()

SAMPLE_RATE = int(os.environ.get("ASR_SAMPLE_RATE", "16000"))
CHUNK_MS = 200  # VAD è¾“å…¥å—å¤§å°
MAX_BUFFER_SEC = float(os.environ.get("SF_MAX_BUFFER_SEC", "5.0"))  # é™ä½åˆ°5ç§’ï¼Œé¿å…å•å¥è¿‡é•¿
REQUEST_TIMEOUT = float(os.environ.get("SF_REQUEST_TIMEOUT", "25.0"))

# å¹¶è¡Œå†—ä½™é…ç½®
PARALLEL_REQUESTS = int(os.environ.get("SF_PARALLEL_REQUESTS", "2"))  # æ¯æ®µå‘é€çš„å¹¶è¡Œè¯·æ±‚æ•°

# VAD é…ç½®
SILENCE_THRESHOLD_CHUNKS = int(os.environ.get("SF_SILENCE_CHUNKS", "2"))  # é™ä½åˆ°2ï¼Œæ›´å¿«æ–­å¥ï¼ˆåŸ3ï¼‰
USE_FUNASR_VAD = os.environ.get("SF_USE_FUNASR_VAD", "1") in ("1", "true", "yes")

# VAD æ¨ç†è®¾å¤‡é€‰æ‹©ï¼ˆä»…å½±å“æœ¬åœ° VADï¼›äº‘ç«¯ SiliconFlow ASR ä¸å—å½±å“ï¼‰
# - auto: è‡ªåŠ¨é€‰æ‹©ï¼ˆä¼˜å…ˆ CUDAï¼Œå…¶æ¬¡ ROCmï¼Œå…¶æ¬¡ DirectMLï¼Œæœ€å CPUï¼‰
# - cpu/cuda/rocm/dml: å¼ºåˆ¶æŒ‡å®š
SF_VAD_DEVICE = os.environ.get("SF_VAD_DEVICE", "auto").strip().lower()
SF_VAD_DEVICE_ID = int(os.environ.get("SF_VAD_DEVICE_ID", "0"))

MIN_SENT_CHARS = 2
SENTENCE_END_PUNCT = set("ã€‚ï¼ï¼Ÿ!?.ï¼›;")


def decode_audio_chunk(audio_b64: str) -> np.ndarray:
    """Base64 -> float32 PCM"""
    audio_bytes = base64.b64decode(audio_b64)
    audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
    return audio_int16.astype(np.float32)


def pcm_to_wav_bytes(pcm: np.ndarray, sample_rate: int) -> bytes:
    """float32/int16 -> wav bytes"""
    if pcm.dtype != np.int16:
        if np.max(np.abs(pcm)) <= 1.0:
            pcm = (pcm * 32767).astype(np.int16)
        else:
            pcm = pcm.astype(np.int16)
    buf = io.BytesIO()
    with wave.open(buf, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(pcm.tobytes())
    return buf.getvalue()


def smart_concat(history: str, new_text: str) -> str:
    """æ™ºèƒ½æ‹¼æ¥æ–‡æœ¬"""
    if not new_text:
        return history
    if not history:
        return new_text
    if new_text.startswith(history):
        return new_text
    if history.endswith(new_text):
        return history
    # æ£€æŸ¥é‡å 
    overlap_len = min(len(history), len(new_text))
    for i in range(overlap_len, 0, -1):
        if history.endswith(new_text[:i]):
            return history + new_text[i:]
    # æ— é‡å ï¼Œæ·»åŠ ç©ºæ ¼
    if history and not history.endswith(tuple(SENTENCE_END_PUNCT)) and not history.endswith((" ", "\n")):
        return history + " " + new_text
    return history + new_text


@dataclass
class SessionState:
    audio_buffer: List[np.ndarray] = field(default_factory=list)
    silence_counter: int = 0
    is_speaking: bool = False
    start_time_ms: int = 0
    # ç§»é™¤ committed_textï¼Œæ¯æ®µç‹¬ç«‹è¿”å›
    # committed_text: str = ""
    segment_seq: int = 0

    def reset(self):
        self.audio_buffer.clear()
        self.silence_counter = 0
        self.is_speaking = False
        self.start_time_ms = 0

    def reset_all(self):
        self.reset()
        self.segment_seq = 0


class SiliconFlowWorker:
    def __init__(self):
        self.sessions: Dict[str, SessionState] = {}
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=8)
        self.vad_model = None
        self._vad_device_info = {"device": "cpu", "device_id": -1, "provider": "CPUExecutionProvider", "providers": []}

        # åŠ è½½è½»é‡çº§ VAD æ¨¡å‹
        if USE_FUNASR_VAD:
            self._load_vad_model()
        
        sys.stderr.write(f"[SF Worker] Parallel Redundant Mode\n")
        sys.stderr.write(f"[SF Worker] - Model: {MODEL_NAME}\n")
        sys.stderr.write(f"[SF Worker] - Parallel requests: {PARALLEL_REQUESTS}\n")
        if self.vad_model:
            sys.stderr.write(
                "[SF Worker] - VAD: FunASR FSMN-VAD"
                f" (device={self._vad_device_info.get('device')}, device_id={self._vad_device_info.get('device_id')}, "
                f"provider={self._vad_device_info.get('provider')})\n"
            )
        else:
            sys.stderr.write(f"[SF Worker] - VAD: Simple RMS\n")
        sys.stderr.write(f"[SF Worker] - Max buffer: {MAX_BUFFER_SEC}s\n")
        sys.stderr.flush()

    def _detect_onnx_vad_device(self) -> dict:
        """
        è‡ªåŠ¨æ£€æµ‹ onnxruntime å¯ç”¨çš„æ‰§è¡Œåç«¯ï¼Œå¹¶é€‰æ‹© VAD ä½¿ç”¨çš„è®¾å¤‡ã€‚

        æ³¨æ„ï¼š
        - è¿™é‡Œåªèƒ½æ§åˆ¶ã€Œæœ¬åœ° VADã€çš„æ¨ç†è®¾å¤‡ï¼›SiliconFlow äº‘ç«¯ ASR ä¸ä¼šä½¿ç”¨æœ¬æœº GPUã€‚
        - funasr_onnx çš„ Fsmn_vad æ¥å£é€šå¸¸é€šè¿‡ device_id æ§åˆ¶æ˜¯å¦èµ° GPUï¼ˆ>=0ï¼‰æˆ– CPUï¼ˆ-1ï¼‰ã€‚
        - Provider é€‰æ‹©å—å®‰è£…çš„ onnxruntime ç‰ˆæœ¬å½±å“ï¼š
          * NVIDIAï¼šonnxruntime-gpu -> CUDAExecutionProvider
          * AMD/Winï¼šonnxruntime-directml -> DmlExecutionProviderï¼ˆé€‚é… A/N/Intelï¼‰
          * AMD/Linuxï¼šonnxruntime-rocm -> ROCMExecutionProvider
        """
        forced = SF_VAD_DEVICE
        device_id = SF_VAD_DEVICE_ID

        try:
            import onnxruntime as ort  # type: ignore

            providers = ort.get_available_providers() or []
        except Exception:
            providers = []

        providers_set = {p.lower(): p for p in providers}
        has_cuda = "cudaexecutionprovider" in providers_set
        has_rocm = "rocmexecutionprovider" in providers_set
        has_dml = "dmlexecutionprovider" in providers_set

        def _cpu():
            return {
                "device": "cpu",
                "device_id": -1,
                "provider": "CPUExecutionProvider",
                "providers": providers,
            }

        def _gpu(provider_key: str, device: str):
            return {
                "device": device,
                "device_id": device_id,
                "provider": providers_set.get(provider_key, provider_key),
                "providers": providers,
            }

        # å¼ºåˆ¶æ¨¡å¼
        if forced in ("cpu", "none", "off", "-1"):
            return _cpu()
        if forced in ("cuda", "nvidia"):
            return _gpu("cudaexecutionprovider", "cuda") if has_cuda else _cpu()
        if forced in ("rocm", "amd"):
            return _gpu("rocmexecutionprovider", "rocm") if has_rocm else _cpu()
        if forced in ("dml", "directml"):
            return _gpu("dmlexecutionprovider", "dml") if has_dml else _cpu()

        # autoï¼šæŒ‰ä¼˜å…ˆçº§é€‰æ‹©ï¼ˆCUDA > ROCm > DirectML > CPUï¼‰
        if has_cuda:
            return _gpu("cudaexecutionprovider", "cuda")
        if has_rocm:
            return _gpu("rocmexecutionprovider", "rocm")
        # Windows ä¸‹ AMD/NVIDIA é€šå¸¸èµ° DirectML
        if has_dml:
            return _gpu("dmlexecutionprovider", "dml")
        return _cpu()

    def _load_vad_model(self):
        """åŠ è½½ FunASR è½»é‡çº§ VAD æ¨¡å‹ï¼ˆçº¦ 100MBï¼Œæ¯”å®Œæ•´ ASR æ¨¡å‹å°å¾—å¤šï¼‰"""
        try:
            from funasr_onnx.vad_bin import Fsmn_vad
            vad_model_id = "damo/speech_fsmn_vad_zh-cn-16k-common-onnx"

            self._vad_device_info = self._detect_onnx_vad_device()
            sys.stderr.write(f"[SF Worker] Host: {platform.system()} {platform.release()} ({platform.machine()})\n")
            sys.stderr.write(f"[SF Worker] SF_VAD_DEVICE={SF_VAD_DEVICE}, SF_VAD_DEVICE_ID={SF_VAD_DEVICE_ID}\n")
            sys.stderr.write(f"[SF Worker] ONNX Runtime providers: {self._vad_device_info.get('providers')}\n")
            sys.stderr.write(
                f"[SF Worker] Loading VAD model: {vad_model_id} "
                f"(device={self._vad_device_info.get('device')}, device_id={self._vad_device_info.get('device_id')}, "
                f"provider={self._vad_device_info.get('provider')})...\n"
            )
            sys.stderr.flush()

            # funasr_onnxï¼šdevice_id=-1 è¡¨ç¤º CPUï¼›>=0 å°è¯•ä½¿ç”¨ GPUï¼ˆç”±å®‰è£…çš„ onnxruntime provider å†³å®šï¼‰
            self.vad_model = Fsmn_vad(
                model_dir=vad_model_id,
                quantize=True,
                device_id=int(self._vad_device_info.get("device_id", -1)),
            )
            sys.stderr.write("[SF Worker] VAD model loaded successfully!\n")
            sys.stderr.flush()
        except Exception as e:
            sys.stderr.write(f"[SF Worker] VAD loading failed: {e}, fallback to RMS\n")
            sys.stderr.flush()
            self.vad_model = None

    def _is_speech(self, chunk_f32: np.ndarray) -> bool:
        """VAD æ£€æµ‹ï¼šä¼˜å…ˆç”¨ FunASR æ¨¡å‹ï¼Œå›é€€åˆ°ç®€å• RMS"""
        if chunk_f32.size == 0:
            return False
        
        if self.vad_model:
            try:
                # FunASR VAD å®é™…ä¸Šæ¥å— float32 æ ¼å¼ï¼ˆèŒƒå›´åœ¨ -32768 åˆ° 32768ï¼‰
                # è¾“å…¥çš„ chunk_f32 å·²ç»æ˜¯æ­£ç¡®æ ¼å¼äº†ï¼Œç›´æ¥ä¼ å…¥
                segments = self.vad_model(chunk_f32)
                return len(segments) > 0
            except Exception as e:
                sys.stderr.write(f"[SF Worker] VAD error: {e}, using RMS fallback\n")
                sys.stderr.flush()
        
        # RMS å›é€€æ–¹æ¡ˆ
        rms = float(np.sqrt(np.mean(chunk_f32 ** 2)))
        threshold = 300 / 32768.0
        return rms >= threshold

    def _get_state(self, session_id: str) -> SessionState:
        if session_id not in self.sessions:
            self.sessions[session_id] = SessionState()
        return self.sessions[session_id]

    def reset_session(self, session_id: str):
        self.sessions.pop(session_id, None)
        sys.stderr.write(f"[SF Worker] Session reset: {session_id}\n")
        sys.stderr.flush()

    def handle_force_commit(self, data: dict):
        session_id = data.get("session_id")
        if not session_id:
            return
        state = self.sessions.get(session_id)
        if not state or not state.audio_buffer:
            return
        self._commit_segment(state, data.get("request_id", "default"), session_id, "force_commit")

    def handle_streaming_chunk(self, data: dict):
        session_id = data.get("session_id") or data.get("request_id") or "default"
        request_id = data.get("request_id", "default")
        audio_b64 = data.get("audio_data")
        timestamp_ms = int(data.get("timestamp", int(time.time() * 1000)))
        is_final = bool(data.get("is_final", False))

        if not audio_b64:
            return

        state = self._get_state(session_id)
        if state.start_time_ms == 0:
            state.start_time_ms = timestamp_ms

        chunk = decode_audio_chunk(audio_b64)
        if chunk.size == 0:
            return

        # VAD æ£€æµ‹
        has_voice = self._is_speech(chunk)

        if has_voice:
            state.is_speaking = True
            state.silence_counter = 0
            state.audio_buffer.append(chunk)
        else:
            if state.is_speaking:
                state.silence_counter += 1
                # ä¿ç•™å°‘é‡å°¾éƒ¨é™éŸ³
                if state.silence_counter <= 2:
                    state.audio_buffer.append(chunk)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥æäº¤
        buffered_samples = sum(c.size for c in state.audio_buffer)
        buffered_sec = buffered_samples / float(SAMPLE_RATE)
        
        should_commit = state.is_speaking and (
            state.silence_counter >= SILENCE_THRESHOLD_CHUNKS or
            buffered_sec >= MAX_BUFFER_SEC or
            is_final
        )

        if should_commit and state.audio_buffer:
            trigger = "final" if is_final else ("max_buffer" if buffered_sec >= MAX_BUFFER_SEC else "silence")
            self._commit_segment(state, request_id, session_id, trigger)

    def handle_batch_file(self, data: dict):
        request_id = data.get("request_id", "unknown")
        audio_path = data.get("audio_path")
        
        if not audio_path or not os.path.exists(audio_path):
            send_ipc_message({"request_id": request_id, "status": "error", "error": f"File not found: {audio_path}"})
            return

        try:
            with wave.open(audio_path, "rb") as wf:
                if wf.getsampwidth() != 2:
                    raise ValueError("Only 16-bit PCM supported")
                ch = wf.getnchannels()
                sr = wf.getframerate()
                raw = wf.readframes(wf.getnframes())
            
            audio = np.frombuffer(raw, dtype=np.int16)
            if ch > 1:
                audio = audio.reshape(-1, ch)[:, 0]
            audio_f32 = audio.astype(np.float32)
            
            # æ‰¹é‡æ–‡ä»¶ä½¿ç”¨å•è¯·æ±‚å³å¯
            self._parallel_transcribe_and_send(audio_f32, sr, request_id, "batch_file", None, None)
        except Exception as exc:
            send_ipc_message({
                "request_id": request_id,
                "status": "error",
                "error": str(exc),
                "traceback": traceback.format_exc()
            })

    def _commit_segment(self, state: SessionState, request_id: str, session_id: str, trigger: str):
        """æäº¤éŸ³é¢‘æ®µ"""
        merged = np.concatenate(state.audio_buffer)
        sr = SAMPLE_RATE
        state.reset()
        state.segment_seq += 1
        seg_seq = state.segment_seq
        
        duration_sec = len(merged) / float(sr)
        sys.stderr.write(f"[SF Worker] ğŸ“¤ Committing segment #{seg_seq} ({duration_sec:.1f}s, trigger={trigger})\n")
        sys.stderr.flush()
        
        # å¹¶è¡Œå†—ä½™è¯·æ±‚
        self._parallel_transcribe_and_send(merged, sr, request_id, trigger, session_id, seg_seq)

    def _parallel_transcribe_and_send(
        self,
        audio_f32: np.ndarray,
        sample_rate: int,
        request_id: str,
        trigger: str,
        session_id: Optional[str],
        seg_seq: Optional[int],
    ):
        """å¹¶è¡Œå‘é€å¤šä¸ªå†—ä½™è¯·æ±‚ï¼Œå–æœ€å¿«è¿”å›çš„ç»“æœ"""
        import requests
        
        t0 = time.time()
        wav_bytes = pcm_to_wav_bytes(audio_f32, sample_rate)
        
        def single_request(replica_id: int):
            """å•ä¸ª API è¯·æ±‚"""
            try:
                files = {"file": ("chunk.wav", wav_bytes, "audio/wav")}
                data = {"model": MODEL_NAME}
                headers = {"Authorization": f"Bearer {API_KEY}"} if API_KEY else {}
                
                sys.stderr.write(f"[SF Worker]   - Request #{replica_id} started\n")
                sys.stderr.flush()
                
                resp = requests.post(
                    API_URL,
                    headers=headers,
                    data=data,
                    files=files,
                    timeout=(3, REQUEST_TIMEOUT),
                )
                resp.raise_for_status()
                
                j = resp.json()
                text = (j.get("text") or "").strip()
                latency = time.time() - t0
                
                sys.stderr.write(f"[SF Worker]   âœ“ Request #{replica_id} returned in {latency:.2f}s: \"{text[:30]}...\"\n")
                sys.stderr.flush()
                
                return {"text": text, "replica_id": replica_id, "latency": latency}
            except Exception as exc:
                sys.stderr.write(f"[SF Worker]   âœ— Request #{replica_id} failed: {exc}\n")
                sys.stderr.flush()
                raise

        # å¹¶è¡Œå‘é€ N ä¸ªè¯·æ±‚
        futures = []
        for i in range(PARALLEL_REQUESTS):
            future = self.executor.submit(single_request, i)
            futures.append(future)
        
        # ç­‰å¾…ç¬¬ä¸€ä¸ªå®Œæˆçš„è¯·æ±‚ï¼ˆRaceï¼‰
        result = None
        try:
            done, pending = concurrent.futures.wait(
                futures,
                timeout=REQUEST_TIMEOUT + 5,
                return_when=concurrent.futures.FIRST_COMPLETED
            )
            
            # å–ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
            for future in done:
                try:
                    result = future.result()
                    break
                except Exception:
                    continue
            
            # å–æ¶ˆå…¶ä»–æœªå®Œæˆçš„è¯·æ±‚
            for future in pending:
                future.cancel()
                
        except Exception as exc:
            sys.stderr.write(f"[SF Worker] Parallel request failed: {exc}\n")
            sys.stderr.flush()

        # å¦‚æœæ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥
        if result is None:
            send_ipc_message({
                "request_id": request_id,
                "session_id": session_id or request_id,
                "status": "error",
                "error": "All parallel requests failed",
                "trigger": trigger,
                "engine": "siliconflow",
            })
            return

        # å¤„ç†æˆåŠŸçš„ç»“æœ
        text = result["text"]
        latency_ms = int(result["latency"] * 1000)
        now_ms = int(time.time() * 1000)

        # batch_fileï¼šç›´æ¥è¿”å›
        if session_id is None:
            send_ipc_message({
                "request_id": request_id,
                "session_id": request_id,
                "type": "sentence_complete",
                "text": text,
                "timestamp": now_ms,
                "is_final": True,
                "status": "success",
                "language": "zh",
                "trigger": trigger,
                "latency_ms": latency_ms,
                "engine": "siliconflow",
                "replica_id": result["replica_id"],
            })
            return

        # streamingï¼šæ¯æ®µç‹¬ç«‹è¿”å›ï¼ˆä¸å†ç´¯ç§¯ï¼‰
        # è¿™æ ·é¿å…äº†é‡å¤ä¿å­˜é—®é¢˜ï¼Œç”±å‰ç«¯/Node.jsç«¯å†³å®šå¦‚ä½•å¤„ç†å¤šæ®µæ–‡æœ¬
        if not text:
            return

        send_ipc_message({
            "request_id": request_id,
            "session_id": session_id,
            "type": "sentence_complete",
            "text": text,  # ç›´æ¥è¿”å›æœ¬æ®µæ–‡æœ¬ï¼Œä¸ç´¯ç§¯
            "timestamp": now_ms,
            "is_final": True,
            "status": "success",
            "language": "zh",
            "trigger": trigger,
            "latency_ms": latency_ms,
            "engine": "siliconflow",
            "segment_seq": seg_seq,
            "replica_id": result["replica_id"],
        })


def main():
    try:
        worker = SiliconFlowWorker()
        send_ipc_message({"status": "ready"})
        sys.stderr.write("[SF Worker] READY - Parallel Redundant Mode Enabled\n")
        sys.stderr.flush()

        while True:
            line = sys.stdin.readline()
            if not line:
                break
            
            try:
                data = json.loads(line)
            except json.JSONDecodeError:
                continue

            req_type = data.get("type")
            if req_type == "reset_session":
                worker.reset_session(data.get("session_id", ""))
            elif req_type == "force_commit":
                worker.handle_force_commit(data)
            elif req_type == "streaming_chunk":
                worker.handle_streaming_chunk(data)
            elif req_type == "batch_file" or "audio_path" in data:
                worker.handle_batch_file(data)
            else:
                send_ipc_message({
                    "request_id": data.get("request_id", "unknown"),
                    "status": "error",
                    "error": f"Unknown request type: {req_type}"
                })
                
    except Exception as exc:
        sys.stderr.write(f"[SF Worker] Fatal: {exc}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        send_ipc_message({"status": "fatal", "error": str(exc)})
        sys.exit(1)


if __name__ == "__main__":
    main()

