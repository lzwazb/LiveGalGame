#!/usr/bin/env python3
"""
FunASR 2-Pass Worker: åŸºäº funasr_onnx çš„æµå¼/ç¦»çº¿æ··åˆè¯­éŸ³è¯†åˆ«

å‚ç…§ RealtimeMicPipeline demo è®¾è®¡ï¼š
- Pass 1 (æµå¼): ParaformerOnline å¿«é€Ÿå‡ºå­—ï¼Œç”¨äºå®æ—¶æ˜¾ç¤º
- Pass 2 (ç¦»çº¿): ParaformerOffline + æ ‡ç‚¹æ¨¡å‹ï¼Œç”¨äºæœ€ç»ˆä¿®æ­£

åˆ†å¥ç­–ç•¥ï¼š
- VAD æ£€æµ‹è¯­éŸ³è¾¹ç•Œ
- é™éŸ³ç´¯ç§¯è¾¾åˆ°é˜ˆå€¼è§¦å‘ Pass 2 ä¿®æ­£
- æ”¯æŒå¼ºåˆ¶æäº¤ (force_commit)
"""

import json
import os
import platform
import sys
import time
import traceback
import base64
from dataclasses import dataclass, field
from typing import Dict, List, Optional

import numpy as np

# ==============================================================================
# OS çº§åˆ«çš„æ–‡ä»¶æè¿°ç¬¦é‡å®šå‘
# ==============================================================================
ipc_fd = os.dup(sys.stdout.fileno())
ipc_channel = os.fdopen(ipc_fd, "w", buffering=1, encoding="utf-8")
os.dup2(sys.stderr.fileno(), sys.stdout.fileno())
sys.stdout = sys.stderr


def send_ipc_message(data):
    """å‘é€ JSON æ¶ˆæ¯åˆ° Node.js"""
    try:
        json_str = json.dumps(data, ensure_ascii=False)
        ipc_channel.write(json_str + "\n")
        ipc_channel.flush()
    except Exception as exc:
        sys.stderr.write(f"[IPC Error] Failed to send: {exc}\n")
        sys.stderr.flush()


# ==============================================================================
# ç¯å¢ƒå˜é‡é…ç½®
# ==============================================================================
os.environ.setdefault("TQDM_DISABLE", "1")

MODELSCOPE_CACHE = os.environ.get("MODELSCOPE_CACHE") or os.environ.get("ASR_CACHE_DIR")
if MODELSCOPE_CACHE:
    os.environ.setdefault("MODELSCOPE_CACHE", MODELSCOPE_CACHE)
    os.environ.setdefault("MODELSCOPE_CACHE_HOME", MODELSCOPE_CACHE)

# ç¦»çº¿æ¨¡å¼ï¼šå¦‚æœè®¾ç½®äº† MODELSCOPE_OFFLINE=1ï¼Œåˆ™è·³è¿‡ç½‘ç»œè¯·æ±‚ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°ç¼“å­˜
OFFLINE_MODE = os.environ.get("MODELSCOPE_OFFLINE", "").lower() in ("1", "true", "yes")
if OFFLINE_MODE:
    sys.stderr.write("[FunASR Worker] Offline mode enabled: using local cache only\n")
    sys.stderr.flush()
    # è®¾ç½® modelscope ç¦»çº¿æ¨¡å¼ç›¸å…³ç¯å¢ƒå˜é‡
    os.environ["MODELSCOPE_OFFLINE"] = "1"
    os.environ["HF_HUB_OFFLINE"] = "1"
    # å°è¯•é…ç½® modelscope åº“çš„ç¦»çº¿æ¨¡å¼
    try:
        from modelscope.hub.snapshot_download import snapshot_download
        from modelscope.hub.file_download import model_file_download
        # Monkey-patch: è®© modelscope è·³è¿‡ç‰ˆæœ¬æ£€æŸ¥
        import modelscope.hub.api as ms_api
        if hasattr(ms_api, 'HubApi'):
            _original_get_model_files = getattr(ms_api.HubApi, 'get_model_files', None)
            if _original_get_model_files:
                def _patched_get_model_files(self, model_id, revision=None, *args, **kwargs):
                    # ç¦»çº¿æ¨¡å¼ä¸‹ç›´æ¥è¿”å›ç©ºï¼Œè®©åº“ä½¿ç”¨æœ¬åœ°ç¼“å­˜
                    return []
                ms_api.HubApi.get_model_files = _patched_get_model_files
    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Warning: Could not configure modelscope offline mode: {e}\n")
        sys.stderr.flush()

# ==============================================================================
# FunASR é…ç½®
# ==============================================================================
SAMPLE_RATE = int(os.environ.get("ASR_SAMPLE_RATE", "16000"))
CHUNK_MS = int(os.environ.get("ASR_CHUNK_MS", "200"))  # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å—æ—¶é•¿ (æ¯«ç§’)
CHUNK_SAMPLES = int(SAMPLE_RATE * CHUNK_MS / 1000)

# é™éŸ³æ£€æµ‹é…ç½®
SILENCE_THRESHOLD_CHUNKS = int(os.environ.get("ASR_SILENCE_CHUNKS", "3"))  # è¿ç»­é™éŸ³å—æ•°è§¦å‘å¥å°¾
SILENCE_BUFFER_KEEP = 2  # ä¿ç•™å¤šå°‘ä¸ªé™éŸ³å—è®©éŸ³é¢‘æ›´è‡ªç„¶

# åˆ†å¥é…ç½®
SENTENCE_END_PUNCTUATION = set("ã€‚ï¼ï¼Ÿ!?.ï¼›;")
MIN_SENTENCE_CHARS = int(os.environ.get("MIN_SENTENCE_CHARS", "2"))

# æ¨ç†è®¾å¤‡é€‰æ‹©ï¼ˆå½±å“æœ¬åœ° FunASR ONNX æ¨¡å‹ï¼šVAD/Online/Offline/Puncï¼‰
# - auto: è‡ªåŠ¨é€‰æ‹©ï¼ˆä¼˜å…ˆ CUDAï¼Œå…¶æ¬¡ ROCmï¼Œå…¶æ¬¡ DirectMLï¼Œæœ€å CPUï¼‰
# - cpu/cuda/rocm/dml: å¼ºåˆ¶æŒ‡å®š
ASR_DEVICE = os.environ.get("ASR_DEVICE", "auto").strip().lower()
ASR_DEVICE_ID = int(os.environ.get("ASR_DEVICE_ID", "0"))


@dataclass
class GPUConfig:
    """
    å…¼å®¹å†å²æµ‹è¯•è„šæœ¬çš„ GPU é…ç½®å¯¹è±¡ã€‚

    - device_type: cpu/cuda/rocm/dml
    - provider_name: onnxruntime provider åç§°ï¼ˆå¦‚ DmlExecutionProviderï¼‰
    - available: æ˜¯å¦å¯ç”¨ GPU
    - device_id: GPU è®¾å¤‡ idï¼ˆCPU æ—¶ä¸º -1ï¼‰
    - providers: å¯ç”¨ providers åˆ—è¡¨ï¼ˆè°ƒè¯•ç”¨ï¼‰
    """

    device_type: str = "cpu"
    provider_name: str = "CPUExecutionProvider"
    available: bool = False
    device_id: int = -1
    providers: List[str] = field(default_factory=list)


def detect_onnx_device() -> dict:
    """
    æ£€æµ‹ onnxruntime å¯ç”¨ providerï¼Œå¹¶é€‰æ‹©æ¨ç†è®¾å¤‡ã€‚

    è¯´æ˜ï¼š
    - funasr_onnx çš„æ¨¡å‹æ„é€ å‡½æ•°ä¸€èˆ¬é€šè¿‡ device_id æ§åˆ¶ï¼š-1 ä¸º CPUï¼›>=0 å°è¯•ä½¿ç”¨ GPUã€‚
    - å®é™…èµ°å“ªç§ GPU å–å†³äºå®‰è£…çš„ onnxruntime ç‰ˆæœ¬æä¾›çš„ providerï¼š
      * CUDAExecutionProvider (onnxruntime-gpu) -> NVIDIA
      * ROCMExecutionProvider (onnxruntime-rocm) -> AMD/ROCm
      * DmlExecutionProvider (onnxruntime-directml) -> Windows ä¸Š AMD/NVIDIA/Intel
    """
    forced = ASR_DEVICE
    device_id = ASR_DEVICE_ID

    try:
        import onnxruntime as ort  # type: ignore

        providers = ort.get_available_providers() or []
    except Exception:
        providers = []

    providers_set = {p.lower(): p for p in providers}
    has_cuda = "cudaexecutionprovider" in providers_set
    has_rocm = "rocmexecutionprovider" in providers_set
    has_dml = "dmlexecutionprovider" in providers_set

    def _cpu():
        return {
            "device": "cpu",
            "device_id": -1,
            "provider": "CPUExecutionProvider",
            "providers": providers,
        }

    def _gpu(provider_key: str, device: str):
        return {
            "device": device,
            "device_id": device_id,
            "provider": providers_set.get(provider_key, provider_key),
            "providers": providers,
        }

    if forced in ("cpu", "none", "off", "-1"):
        return _cpu()
    if forced in ("cuda", "nvidia"):
        return _gpu("cudaexecutionprovider", "cuda") if has_cuda else _cpu()
    if forced in ("rocm", "amd"):
        return _gpu("rocmexecutionprovider", "rocm") if has_rocm else _cpu()
    if forced in ("dml", "directml"):
        return _gpu("dmlexecutionprovider", "dml") if has_dml else _cpu()

    # autoï¼šæŒ‰ä¼˜å…ˆçº§é€‰æ‹©ï¼ˆCUDA > ROCm > DirectML > CPUï¼‰
    if has_cuda:
        return _gpu("cudaexecutionprovider", "cuda")
    if has_rocm:
        return _gpu("rocmexecutionprovider", "rocm")
    if has_dml:
        return _gpu("dmlexecutionprovider", "dml")
    return _cpu()


def detect_gpu() -> GPUConfig:
    """
    å…¼å®¹æ¥å£ï¼šè¿”å› GPUConfigï¼Œä¾› test_funasr_gpu.py ç­‰è„šæœ¬è°ƒç”¨ã€‚
    """
    info = detect_onnx_device()
    device = str(info.get("device", "cpu"))
    device_id = int(info.get("device_id", -1))
    provider = str(info.get("provider", "CPUExecutionProvider"))
    providers = list(info.get("providers") or [])
    available = device_id >= 0 and provider != "CPUExecutionProvider"
    return GPUConfig(
        device_type=device,
        provider_name=provider,
        available=available,
        device_id=device_id,
        providers=providers,
    )


def smart_concat(history: str, new_text: str) -> str:
    """
    æ™ºèƒ½æ‹¼æ¥æµå¼æ–‡æœ¬ï¼šå¤„ç†å¢é‡ã€å…¨é‡ã€é‡å ç­‰æƒ…å†µã€‚
    """
    if not new_text:
        return history
    if not history:
        return new_text
    
    # 1. æ£€æŸ¥ new_text æ˜¯å¦å®Œå…¨åŒ…å« history (è¯´æ˜ new_text æ˜¯å…¨é‡æ›´æ–°)
    if new_text.startswith(history):
        return new_text
        
    # 2. æ£€æŸ¥ history æ˜¯å¦å®Œå…¨åŒ…å« new_text (è¯´æ˜ new_text æ˜¯æ—§çš„å…¨é‡æˆ–è€…æ˜¯é‡å¤è¾“å‡º)
    if history.endswith(new_text):
        return history
        
    # 3. æ£€æŸ¥é‡å  (historyåç¼€ ä¸ new_textå‰ç¼€)
    overlap_len = min(len(history), len(new_text))
    for i in range(overlap_len, 0, -1):
        if history.endswith(new_text[:i]):
            return history + new_text[i:]
            
    # 4. æ— é‡å ï¼Œç›´æ¥æ‹¼æ¥
    return history + new_text


def decode_audio_chunk(audio_b64: str) -> np.ndarray:
    """Base64 éŸ³é¢‘è½¬ float32 numpy arrayï¼ˆèŒƒå›´ -1~1ï¼‰ã€‚"""
    audio_bytes = base64.b64decode(audio_b64)
    audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
    return audio_int16.astype(np.float32)  # funasr_onnx æ¥å— float32ï¼Œä¸é™¤ä»¥ 32768


def smart_split_sentences(text: str) -> List[str]:
    """
    æ™ºèƒ½åˆ†å¥ï¼šåŸºäºæ ‡ç‚¹ç¬¦å·å°†é•¿æ–‡æœ¬åˆ‡åˆ†æˆè‡ªç„¶çš„å¥å­ã€‚
    
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæŒ‰å¥æœ«æ ‡ç‚¹ï¼ˆã€‚ï¼ï¼Ÿ!?.ï¼‰åˆ†å‰²
    2. å¦‚æœåˆ†éš”åçš„å¥å­å¤ªçŸ­ï¼Œè€ƒè™‘åˆå¹¶
    3. å¦‚æœæ²¡æœ‰å¥æœ«æ ‡ç‚¹ï¼Œè¿”å›åŸæ–‡
    """
    if not text or len(text) < MIN_SENTENCE_CHARS:
        return [text] if text else []
    
    # å®šä¹‰å¥æœ«æ ‡ç‚¹
    sentence_endings = "ã€‚ï¼ï¼Ÿ!?."
    
    sentences = []
    current_sentence = ""
    
    for char in text:
        current_sentence += char
        if char in sentence_endings:
            trimmed = current_sentence.strip()
            if trimmed and len(trimmed) >= MIN_SENTENCE_CHARS:
                sentences.append(trimmed)
            elif trimmed and sentences:
                # å¤ªçŸ­çš„å¥å­åˆå¹¶åˆ°ä¸Šä¸€å¥
                sentences[-1] += trimmed
            elif trimmed:
                sentences.append(trimmed)
            current_sentence = ""
    
    # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
    remaining = current_sentence.strip()
    if remaining:
        if len(remaining) < MIN_SENTENCE_CHARS and sentences:
            # å¤ªçŸ­å°±åˆå¹¶åˆ°ä¸Šä¸€å¥
            sentences[-1] += remaining
        else:
            sentences.append(remaining)
    
    return sentences if sentences else [text]



@dataclass
class SessionState:
    """
    FunASR 2-Pass ä¼šè¯çŠ¶æ€
    """
    # éŸ³é¢‘ç¼“å†²åŒº (ç»™ Pass 2 ç”¨)
    full_sentence_buffer: List[np.ndarray] = field(default_factory=list)
    
    # Pass 1 æµå¼æ¨¡å‹çš„ä¸Šä¸‹æ–‡ç¼“å­˜
    online_cache: Dict = field(default_factory=dict)
    
    # é™éŸ³æ£€æµ‹
    silence_counter: int = 0
    is_speaking: bool = False
    
    # ç´¯ç§¯çš„æµå¼æ–‡æœ¬
    streaming_text: str = ""
    last_sent_text: str = ""
    
    # æ—¶é—´æˆ³
    start_time: float = 0.0
    
    def reset(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        self.full_sentence_buffer.clear()
        self.online_cache.clear()
        self.silence_counter = 0
        self.is_speaking = False
        self.streaming_text = ""
        self.last_sent_text = ""
        self.start_time = 0.0


def resolve_local_model_path(model_id: str) -> Optional[str]:
    """
    åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ï¼Œè§£ææœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚
    æ£€æŸ¥ MODELSCOPE_CACHE å’Œé»˜è®¤ç¼“å­˜ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨æ¨¡å‹ã€‚
    """
    if not OFFLINE_MODE:
        return None
    
    import os.path
    cache_dirs = [
        os.environ.get("MODELSCOPE_CACHE"),
        os.environ.get("ASR_CACHE_DIR"),
        os.path.join(os.path.expanduser("~"), ".cache", "modelscope", "hub"),
    ]
    
    for cache_dir in cache_dirs:
        if not cache_dir:
            continue
        # ModelScope ç¼“å­˜ç»“æ„: hub/models/<model_id>/
        candidates = [
            os.path.join(cache_dir, model_id),
            os.path.join(cache_dir, "models", model_id),
        ]
        for candidate in candidates:
            if os.path.isdir(candidate):
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
                files = os.listdir(candidate)
                if any(f.endswith(('.onnx', '.bin', '.json')) for f in files):
                    sys.stderr.write(f"[FunASR Worker] Found local model: {candidate}\n")
                    sys.stderr.flush()
                    return candidate
    
    return None


def load_funasr_onnx_models(gpu_config: Optional[GPUConfig] = None):
    """
    åŠ è½½ funasr_onnx æ¨¡å‹ (VAD + æµå¼ASR + ç¦»çº¿ASR + æ ‡ç‚¹)
    
    æ”¯æŒçš„ç¯å¢ƒå˜é‡:
    - ASR_MODEL: æ¨¡å‹ ID (funasr-paraformer / funasr-paraformer-large)
        * funasr-paraformer: INT8 é‡åŒ–ç‰ˆï¼ŒåŒ…ä½“çº¦ 0.76GBï¼ˆonline/offline/punc/vadï¼‰ï¼Œé€Ÿåº¦æ›´å¿«
        * funasr-paraformer-large: FP32 æœªé‡åŒ–ï¼Œçº¦ 2.1GBï¼ˆæŒ‰ INT8â†’FP32 ä½“ç§¯ä¼°ç®—ï¼‰ï¼Œç²¾åº¦æ›´é«˜
    - ASR_QUANTIZE: æ˜¯å¦ä½¿ç”¨é‡åŒ– (true/false)ï¼Œé»˜è®¤æ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨é€‰æ‹©
    - MODELSCOPE_OFFLINE: ç¦»çº¿æ¨¡å¼ï¼Œè·³è¿‡ç½‘ç»œè¯·æ±‚ç›´æ¥ä½¿ç”¨æœ¬åœ°ç¼“å­˜
    """
    try:
        from funasr_onnx.vad_bin import Fsmn_vad
        from funasr_onnx.paraformer_online_bin import Paraformer as ParaformerOnline
        from funasr_onnx.paraformer_bin import Paraformer as ParaformerOffline
        from funasr_onnx.punc_bin import CT_Transformer
    except ImportError as e:
        sys.stderr.write(f"[FunASR Worker] Import error: {e}\n")
        sys.stderr.write("[FunASR Worker] Please install: pip install funasr_onnx\n")
        sys.stderr.flush()
        raise

    # è¯»å–æ¨¡å‹é…ç½®
    model_id = os.environ.get("ASR_MODEL", "funasr-paraformer")
    is_large = "large" in model_id.lower()

    device_info = detect_onnx_device()
    if gpu_config is not None:
        # å…¼å®¹ï¼šå…è®¸å¤–éƒ¨æ˜¾å¼ä¼ å…¥ device_idï¼ˆä¾‹å¦‚ test_funasr_gpu.pyï¼‰
        try:
            device_info = {
                "device": getattr(gpu_config, "device_type", "cpu"),
                "device_id": int(getattr(gpu_config, "device_id", -1)),
                "provider": getattr(gpu_config, "provider_name", "CPUExecutionProvider"),
                "providers": list(getattr(gpu_config, "providers", []) or []),
            }
        except Exception:
            device_info = detect_onnx_device()
    
    # Large ç‰ˆæœ¬é»˜è®¤ä¸ä½¿ç”¨é‡åŒ–ï¼Œç²¾åº¦æ›´é«˜
    quantize_env = os.environ.get("ASR_QUANTIZE", "").lower()
    if quantize_env in ("true", "1", "yes"):
        use_quantize = True
    elif quantize_env in ("false", "0", "no"):
        use_quantize = False
    else:
        # é»˜è®¤: æ™®é€šç‰ˆé‡åŒ–ï¼ŒLargeç‰ˆä¸é‡åŒ–
        use_quantize = not is_large
    
    sys.stderr.write(f"[FunASR Worker] Model ID: {model_id}\n")
    sys.stderr.write(f"[FunASR Worker] Is Large model: {is_large}\n")
    sys.stderr.write(f"[FunASR Worker] Use Quantize: {use_quantize}\n")
    sys.stderr.write(f"[FunASR Worker] Offline mode: {OFFLINE_MODE}\n")
    sys.stderr.write(f"[FunASR Worker] Host: {platform.system()} {platform.release()} ({platform.machine()})\n")
    sys.stderr.write(f"[FunASR Worker] ASR_DEVICE={ASR_DEVICE}, ASR_DEVICE_ID={ASR_DEVICE_ID}\n")
    sys.stderr.write(f"[FunASR Worker] ONNX Runtime providers: {device_info.get('providers')}\n")
    sys.stderr.write(
        "[FunASR Worker] Inference device selection: "
        f"device={device_info.get('device')}, device_id={device_info.get('device_id')}, provider={device_info.get('provider')}\n"
    )
    sys.stderr.write(f"[FunASR Worker] Preset size hint: {'~0.76GB INT8 (default)' if use_quantize else '~2.1GB FP32 (higher accuracy)'}\n")
    if OFFLINE_MODE:
        sys.stderr.write("[FunASR Worker] Loading ONNX models from local cache (offline mode)...\n")
    else:
        sys.stderr.write("[FunASR Worker] Loading ONNX models (first run will download)...\n")
    sys.stderr.flush()

    # ONNX æ¨¡å‹é…ç½®
    # å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤æ¨¡å‹
    vad_model_id = os.environ.get(
        "FUNASR_VAD_MODEL", 
        "damo/speech_fsmn_vad_zh-cn-16k-common-onnx"
    )
    online_model_id = os.environ.get(
        "FUNASR_ONLINE_MODEL",
        "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx"
    )
    offline_model_id = os.environ.get(
        "FUNASR_OFFLINE_MODEL",
        "damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx"
    )
    punc_model_id = os.environ.get(
        "FUNASR_PUNC_MODEL",
        "damo/punc_ct-transformer_zh-cn-common-vocab272727-onnx"
    )

    def _normalize_model_id(value: str, label: str) -> str:
        """
        å…¼å®¹å†å²/å¤–éƒ¨é…ç½®ï¼šæœ‰äº›ç¯å¢ƒå¯èƒ½ä¼šæŠŠ FUNASR_* å˜é‡è®¾ç½®ä¸ºæœ¬åœ°ç¼“å­˜ç›®å½•è·¯å¾„ï¼Œ
        ä½† funasr_onnx å†…éƒ¨ä¼šå°†è¯¥å€¼ä¼ ç»™ funasr.AutoModel(model=...)ã€‚
        AutoModel éœ€è¦ registry æ¨¡å‹ IDï¼ˆå¦‚ "damo/xxx"ï¼‰ï¼Œè€Œä¸æ˜¯ "C:\\...\\damo\\xxx"ã€‚
        """
        if not value:
            return value

        # å·²ç»æ˜¯ registry å½¢å¼
        if "/" in value and not (":" in value or value.startswith("\\") or value.startswith("/")):
            return value

        # å¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼ˆwin/mac/linuxï¼‰ï¼Œå°è¯•ä»è·¯å¾„ä¸­æå– "org/model"
        try:
            norm = os.path.normpath(value)
            parts = [p for p in norm.split(os.sep) if p]
            # å¸¸è§ç»“æ„: .../hub/models/damo/<model>  æˆ– .../hub/damo/<model>
            if "models" in parts:
                idx = parts.index("models")
                if idx + 2 < len(parts):
                    org = parts[idx + 1]
                    model = parts[idx + 2]
                    inferred = f"{org}/{model}"
                    sys.stderr.write(f"[FunASR Worker] Normalized {label} from local path to model id: {inferred}\n")
                    sys.stderr.flush()
                    return inferred
            # å…œåº•ï¼šç›´æ¥åœ¨è·¯å¾„ä¸­æ‰¾ "damo/<model>"
            if "damo" in parts:
                idx = parts.index("damo")
                if idx + 1 < len(parts):
                    inferred = f"damo/{parts[idx + 1]}"
                    sys.stderr.write(f"[FunASR Worker] Normalized {label} from local path to model id: {inferred}\n")
                    sys.stderr.flush()
                    return inferred
        except Exception:
            pass

        # æ— æ³•è¯†åˆ«æ—¶åŸæ ·è¿”å›ï¼ˆè®©åç»­æŠ¥é”™æ›´æ˜ç¡®ï¼‰
        return value

    vad_model_id = _normalize_model_id(vad_model_id, "VAD")
    online_model_id = _normalize_model_id(online_model_id, "Streaming ASR (Pass 1)")
    offline_model_id = _normalize_model_id(offline_model_id, "Offline ASR (Pass 2)")
    punc_model_id = _normalize_model_id(punc_model_id, "Punctuation")

    def _ensure_cached(model_id: str, label: str) -> Optional[str]:
        """
        ç¦»çº¿æ¨¡å¼ä¸‹ä»…ç”¨äºæ ¡éªŒæœ¬åœ°ç¼“å­˜æ˜¯å¦å­˜åœ¨ï¼Œå¹¶è¿”å›æ‰¾åˆ°çš„ç›®å½•è·¯å¾„ï¼ˆç”¨äºæ—¥å¿—/æç¤ºï¼‰ã€‚

        é‡è¦ï¼šfunasr_onnx å†…éƒ¨ä¼šå°† model_dir ä¼ ç»™ funasr.AutoModelï¼Œ
        è¿™é‡Œå¿…é¡»ä¼  registry æ¨¡å‹ IDï¼ˆå¦‚ "damo/xxx"ï¼‰ï¼Œä¸èƒ½ä¼ æœ¬åœ°ç›®å½•è·¯å¾„ï¼Œ
        å¦åˆ™ä¼šè§¦å‘ AutoModel çš„ "is not registered" æ–­è¨€é”™è¯¯ã€‚
        """
        if not OFFLINE_MODE:
            return None
        found = resolve_local_model_path(model_id)
        if not found:
            raise RuntimeError(
                f"Offline mode enabled (MODELSCOPE_OFFLINE=1) but required {label} model is not cached: {model_id}. "
                f"Please download the model first, or disable offline mode."
            )
        return found

    # ç¦»çº¿æ¨¡å¼ï¼šåªæ ¡éªŒç¼“å­˜æ˜¯å¦å­˜åœ¨ï¼ˆä¸æŠŠæœ¬åœ°è·¯å¾„ä¼ ç»™ funasr_onnxï¼‰
    vad_cached = _ensure_cached(vad_model_id, "VAD")
    online_cached = _ensure_cached(online_model_id, "Streaming ASR (Pass 1)")
    offline_cached = _ensure_cached(offline_model_id, "Offline ASR (Pass 2)")
    punc_cached = _ensure_cached(punc_model_id, "Punctuation")

    # 1. VAD æ¨¡å‹: æ£€æµ‹è¯­éŸ³æ´»åŠ¨
    sys.stderr.write(
        f"[FunASR Worker] Loading VAD model: {vad_model_id}"
        + (f" (cached at {vad_cached})" if vad_cached else "")
        + "...\n"
    )
    sys.stderr.flush()
    vad_model = Fsmn_vad(
        model_dir=vad_model_id,
        quantize=use_quantize,
        device_id=int(device_info.get("device_id", -1)),
    )

    # 2. Pass 1 æµå¼æ¨¡å‹: å¿«é€Ÿå‡ºå­—
    sys.stderr.write(
        f"[FunASR Worker] Loading streaming ASR model (Pass 1): {online_model_id}"
        + (f" (cached at {online_cached})" if online_cached else "")
        + "...\n"
    )
    sys.stderr.flush()
    asr_online_model = ParaformerOnline(
        model_dir=online_model_id,
        batch_size=1,
        device_id=int(device_info.get("device_id", -1)),
        quantize=use_quantize,
        intra_op_num_threads=4
    )

    # 3. Pass 2 éæµå¼æ¨¡å‹: é«˜ç²¾åº¦è¯†åˆ«
    sys.stderr.write(
        f"[FunASR Worker] Loading offline ASR model (Pass 2): {offline_model_id}"
        + (f" (cached at {offline_cached})" if offline_cached else "")
        + "...\n"
    )
    sys.stderr.flush()
    asr_offline_model = ParaformerOffline(
        model_dir=offline_model_id,
        batch_size=1,
        device_id=int(device_info.get("device_id", -1)),
        quantize=use_quantize,
        intra_op_num_threads=4
    )

    # 4. æ ‡ç‚¹æ¨¡å‹: ç»™ Pass 2 ç»“æœåŠ æ ‡ç‚¹
    sys.stderr.write(
        f"[FunASR Worker] Loading punctuation model: {punc_model_id}"
        + (f" (cached at {punc_cached})" if punc_cached else "")
        + "...\n"
    )
    sys.stderr.flush()
    punc_model = CT_Transformer(
        model_dir=punc_model_id,
        quantize=use_quantize,
        device_id=int(device_info.get("device_id", -1)),
        intra_op_num_threads=2
    )

    sys.stderr.write("[FunASR Worker] All models loaded successfully!\n")
    sys.stderr.write(f"[FunASR Worker] Configuration: model={model_id}, quantize={use_quantize}\n")
    sys.stderr.flush()

    return vad_model, asr_online_model, asr_offline_model, punc_model


def handle_streaming_chunk(
    vad_model,
    asr_online_model,
    asr_offline_model,
    punc_model,
    data: dict,
    sessions_cache: Dict[str, SessionState],
):
    """
    å¤„ç†æµå¼éŸ³é¢‘å— - 2-Pass æ¶æ„
    
    Pass 1: å®æ—¶æµå¼è¯†åˆ«ï¼Œå¿«é€Ÿè¿”å› partial ç»“æœ
    Pass 2: æ£€æµ‹åˆ°å¥å°¾åï¼Œä½¿ç”¨ç¦»çº¿æ¨¡å‹ + æ ‡ç‚¹è¿›è¡Œé«˜ç²¾åº¦ä¿®æ­£
    """
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)
    audio_data_b64 = data.get("audio_data")
    is_final = bool(data.get("is_final", False))
    timestamp_ms = data.get("timestamp", int(time.time() * 1000))

    if not audio_data_b64:
        send_ipc_message({"request_id": request_id, "error": "No audio_data provided"})
        return

    state = sessions_cache.setdefault(session_id, SessionState())
    audio_chunk = decode_audio_chunk(audio_data_b64)

    if audio_chunk.size == 0:
        return

    # è®°å½•å¼€å§‹æ—¶é—´
    if not state.is_speaking and state.start_time == 0:
        state.start_time = time.time()

    # ==== VAD æ£€æµ‹ ====
    try:
        vad_segments = vad_model(audio_chunk)
        current_chunk_has_speech = len(vad_segments) > 0
    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] VAD error: {e}\n")
        sys.stderr.flush()
        current_chunk_has_speech = True  # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†

    # ==== çŠ¶æ€ç®¡ç† ====
    if current_chunk_has_speech:
        state.silence_counter = 0
        state.is_speaking = True
        state.full_sentence_buffer.append(audio_chunk)
    else:
        if state.is_speaking:
            state.silence_counter += 1
            # ä¿ç•™ä¸€ç‚¹é™éŸ³æ®µè®©éŸ³é¢‘æ›´è‡ªç„¶
            if state.silence_counter < SILENCE_BUFFER_KEEP:
                state.full_sentence_buffer.append(audio_chunk)

    # ==== Pass 1: å®æ—¶æµå¼è¯†åˆ« ====
    if state.is_speaking:
        try:
            partial_res = asr_online_model(
                audio_chunk,
                param_dict={"cache": state.online_cache, "is_final": False},
            )

            if partial_res:
                # è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹å®é™…è¿”å›çš„æ ¼å¼
                sys.stderr.write(f"[FunASR Worker] DEBUG partial_res type={type(partial_res).__name__}, value={str(partial_res)[:100]}\n")
                sys.stderr.flush()
                
                # funasr_onnx è¿”å›æ ¼å¼å¯èƒ½æ˜¯:
                # 1. [('text', ['chars'])] - åˆ—è¡¨åŒ…å« tuple
                # 2. [{'preds': 'text'}] - åˆ—è¡¨åŒ…å«å­—å…¸
                # 3. ('text', ['chars']) - ç›´æ¥æ˜¯ tuple
                text = ""
                
                # å…ˆè§£åŒ…åˆ—è¡¨
                item = partial_res
                while isinstance(item, list) and len(item) > 0:
                    item = item[0]
                
                # ç°åœ¨ item åº”è¯¥æ˜¯ tuple æˆ– dict æˆ– str
                if isinstance(item, dict):
                    preds_value = item.get("preds") or item.get("text") or ""
                    # å¦‚æœ preds æ˜¯ tupleï¼Œéœ€è¦æå–å­—ç¬¦ä¸²
                    if isinstance(preds_value, tuple) and len(preds_value) > 0:
                        text = preds_value[0] if isinstance(preds_value[0], str) else str(preds_value[0])
                    elif isinstance(preds_value, str):
                        text = preds_value
                    else:
                        text = str(preds_value) if preds_value else ""
                elif isinstance(item, tuple) and len(item) > 0:
                    # Tuple æ ¼å¼: ('text', ['chars']) - å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    first_elem = item[0]
                    text = first_elem if isinstance(first_elem, str) else str(first_elem)
                elif isinstance(item, str):
                    text = item
                else:
                    text = str(item) if item else ""
                
                sys.stderr.write(f"[FunASR Worker] DEBUG extracted text=\"{text[:50]}...\"\n")
                sys.stderr.flush()
                
                if text:
                    # ä½¿ç”¨æ™ºèƒ½æ‹¼æ¥æ›´æ–° streaming_textï¼Œè§£å†³æµå¼è¾“å‡ºä¸è¿ç»­é—®é¢˜
                    new_streaming = smart_concat(state.streaming_text, text)
                    
                    if new_streaming != state.streaming_text:
                        state.streaming_text = new_streaming
                        send_ipc_message({
                            "request_id": request_id,
                            "session_id": session_id,
                            "type": "partial",
                            "text": state.streaming_text,
                            "full_text": state.streaming_text,
                            "timestamp": timestamp_ms,
                            "is_final": False,
                            "status": "success",
                            "language": "zh",
                        })
                        state.last_sent_text = text
                        sys.stderr.write(f"[FunASR Worker] ğŸ“ PARTIAL: \"{state.streaming_text[-50:]}...\"\n")
                        sys.stderr.flush()
        except Exception as e:
            sys.stderr.write(f"[FunASR Worker] Pass 1 error: {e}\n")
            sys.stderr.flush()

    # ==== Pass 2: æ£€æµ‹åˆ°å¥å°¾ï¼Œè§¦å‘é«˜ç²¾åº¦ä¿®æ­£ ====
    if state.is_speaking and state.silence_counter >= SILENCE_THRESHOLD_CHUNKS:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="silence",
        )

    # ==== å¤„ç† is_final æ ‡è®° ====
    if is_final and state.full_sentence_buffer:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="final",
        )


def _trigger_pass2(
    asr_offline_model,
    punc_model,
    state: SessionState,
    request_id: str,
    session_id: str,
    timestamp_ms: int,
    trigger: str,
):
    """
    è§¦å‘ Pass 2: ç¦»çº¿é«˜ç²¾åº¦è¯†åˆ« + æ ‡ç‚¹ + æ™ºèƒ½åˆ†å¥
    
    æ”¹è¿›ï¼šä½¿ç”¨æ ‡ç‚¹æ¨¡å‹ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†å¥ï¼Œå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªè‡ªç„¶å¥å­åˆ†åˆ«å‘é€ã€‚
    """
    if not state.full_sentence_buffer:
        return

    sys.stderr.write(f"[FunASR Worker] Triggering Pass 2 ({trigger})...\n")
    sys.stderr.flush()

    try:
        # åˆå¹¶éŸ³é¢‘ç‰‡æ®µ
        complete_audio = np.concatenate(state.full_sentence_buffer)
        audio_duration = len(complete_audio) / SAMPLE_RATE

        # A. éæµå¼é«˜ç²¾åº¦è¯†åˆ«
        offline_res = asr_offline_model(complete_audio)
        raw_text = ""
        if offline_res:
            # è§£æè¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯ tuple æˆ– dictï¼‰
            item = offline_res[0] if isinstance(offline_res, list) else offline_res
            if isinstance(item, dict):
                raw_text = item.get("preds") or item.get("text") or ""
            elif isinstance(item, (tuple, list)) and len(item) > 0:
                raw_text = item[0] if isinstance(item[0], str) else str(item[0])
            elif isinstance(item, str):
                raw_text = item
            else:
                raw_text = str(item) if item else ""

        if raw_text and len(raw_text) >= MIN_SENTENCE_CHARS:
            # B. æ ‡ç‚¹é¢„æµ‹
            try:
                punc_res = punc_model(raw_text)
                # è§£ææ ‡ç‚¹æ¨¡å‹è¿”å›å€¼
                if punc_res:
                    punc_item = punc_res[0] if isinstance(punc_res, list) else punc_res
                    if isinstance(punc_item, str):
                        punctuated_text = punc_item
                    elif isinstance(punc_item, (tuple, list)) and len(punc_item) > 0:
                        punctuated_text = punc_item[0] if isinstance(punc_item[0], str) else str(punc_item[0])
                    else:
                        punctuated_text = str(punc_item) if punc_item else raw_text
                else:
                    punctuated_text = raw_text
            except Exception as e:
                sys.stderr.write(f"[FunASR Worker] Punctuation error: {e}\n")
                sys.stderr.flush()
                punctuated_text = raw_text

            sys.stderr.write(f"[FunASR Worker]    Raw: \"{raw_text}\"\n")
            sys.stderr.write(f"[FunASR Worker]    With punc: \"{punctuated_text}\"\n")
            sys.stderr.flush()

            # C. æ™ºèƒ½åˆ†å¥ï¼šå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªè‡ªç„¶å¥å­
            sentences = smart_split_sentences(punctuated_text)
            
            # è®¡ç®—æ¯ä¸ªå¥å­çš„å¤§è‡´æ—¶é—´åˆ†å¸ƒ
            total_chars = sum(len(s) for s in sentences)
            current_time = state.start_time * 1000 if state.start_time else timestamp_ms - (audio_duration * 1000)
            
            for i, sentence in enumerate(sentences):
                # ä¼°ç®—è¿™ä¸ªå¥å­çš„æ—¶é—´èŒƒå›´
                sentence_ratio = len(sentence) / max(total_chars, 1)
                sentence_duration = audio_duration * sentence_ratio
                sentence_end_time = current_time + (sentence_duration * 1000)
                
                is_last = (i == len(sentences) - 1)
                
                sys.stderr.write(f"[FunASR Worker] ğŸ¯ SENTENCE [{i+1}/{len(sentences)}]: \"{sentence[:50]}...\"\n")
                sys.stderr.flush()

                send_ipc_message({
                    "request_id": request_id,
                    "session_id": session_id,
                    "type": "sentence_complete",
                    "text": sentence,
                    "raw_text": raw_text if i == 0 else "",  # åªåœ¨ç¬¬ä¸€å¥é™„å¸¦åŸå§‹æ–‡æœ¬
                    "timestamp": int(sentence_end_time),
                    "is_final": is_last,
                    "status": "success",
                    "language": "zh",
                    "audio_duration": sentence_duration,
                    "trigger": trigger,
                    "start_time": int(current_time),
                    "end_time": int(sentence_end_time),
                    "sentence_index": i,
                    "total_sentences": len(sentences),
                })
                
                current_time = sentence_end_time

    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Pass 2 error: {e}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()

    # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€å¥
    state.reset()


def handle_force_commit(
    asr_offline_model,
    punc_model,
    data: dict,
    sessions_cache: Dict[str, SessionState],
):
    """å¼ºåˆ¶æäº¤å½“å‰å¥å­"""
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)
    timestamp_ms = int(time.time() * 1000)

    sys.stderr.write(f"[FunASR Worker] force_commit received for session={session_id}\n")
    sys.stderr.flush()

    state = sessions_cache.get(session_id)
    if not state:
        sys.stderr.write(f"[FunASR Worker] No session state found for session={session_id}\n")
        sys.stderr.flush()
        return

    # å¦‚æœæœ‰ç¼“å†²çš„éŸ³é¢‘ï¼Œè§¦å‘ Pass 2
    if state.full_sentence_buffer:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="force_commit",
        )
    elif state.streaming_text and len(state.streaming_text) >= MIN_SENTENCE_CHARS:
        # æ²¡æœ‰ç¼“å†²çš„éŸ³é¢‘ï¼Œä½†æœ‰æµå¼æ–‡æœ¬ï¼Œç›´æ¥æäº¤æµå¼æ–‡æœ¬
        send_ipc_message({
            "request_id": request_id,
            "session_id": session_id,
            "type": "sentence_complete",
            "text": state.streaming_text,
            "timestamp": timestamp_ms,
            "is_final": True,
            "status": "success",
            "trigger": "force_commit_text_only",
            "language": "zh",
            "audio_duration": 0,
        })
        state.reset()
    else:
        sys.stderr.write(f"[FunASR Worker] force_commit: no content to commit\n")
        sys.stderr.flush()


def handle_batch_file(asr_offline_model, punc_model, data: dict):
    """å¤„ç†æ‰¹é‡æ–‡ä»¶è¯†åˆ«"""
    request_id = data.get("request_id", "unknown")
    audio_path = data.get("audio_path")

    if not audio_path:
        send_ipc_message({"request_id": request_id, "error": "No audio_path provided"})
        return
    if not os.path.exists(audio_path):
        send_ipc_message({"request_id": request_id, "error": f"File not found: {audio_path}"})
        return

    try:
        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        import wave
        with wave.open(audio_path, 'rb') as wf:
            audio_data = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
            audio_float = audio_data.astype(np.float32)

        # ç¦»çº¿è¯†åˆ«
        offline_res = asr_offline_model(audio_float)
        raw_text = ""
        if offline_res:
            # è§£æè¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯ tuple æˆ– dictï¼‰
            item = offline_res[0] if isinstance(offline_res, list) else offline_res
            if isinstance(item, dict):
                raw_text = item.get("preds") or item.get("text") or ""
            elif isinstance(item, (tuple, list)) and len(item) > 0:
                raw_text = item[0] if isinstance(item[0], str) else str(item[0])
            elif isinstance(item, str):
                raw_text = item
            else:
                raw_text = str(item) if item else ""

        # æ ‡ç‚¹
        if raw_text:
            try:
                punc_res = punc_model(raw_text)
                # è§£ææ ‡ç‚¹æ¨¡å‹è¿”å›å€¼
                if punc_res:
                    punc_item = punc_res[0] if isinstance(punc_res, list) else punc_res
                    if isinstance(punc_item, str):
                        final_text = punc_item
                    elif isinstance(punc_item, (tuple, list)) and len(punc_item) > 0:
                        final_text = punc_item[0] if isinstance(punc_item[0], str) else str(punc_item[0])
                    else:
                        final_text = str(punc_item) if punc_item else raw_text
                else:
                    final_text = raw_text
            except Exception:
                final_text = raw_text
        else:
            final_text = ""

        send_ipc_message({
            "request_id": request_id,
            "text": final_text,
            "raw_text": raw_text,
            "language": "zh",
            "status": "success",
        })

    except Exception as exc:
        send_ipc_message({
            "request_id": request_id,
            "error": str(exc),
            "traceback": traceback.format_exc(),
        })


def main():
    try:
        sys.stderr.write("[FunASR Worker] Starting FunASR 2-Pass Worker...\n")
        sys.stderr.flush()

        # åŠ è½½æ¨¡å‹
        vad_model, asr_online_model, asr_offline_model, punc_model = load_funasr_onnx_models()

        sessions_cache: Dict[str, SessionState] = {}
        send_ipc_message({"status": "ready"})

        sys.stderr.write("[FunASR Worker] Ready! 2-Pass mode enabled.\n")
        sys.stderr.flush()

        while True:
            line = sys.stdin.readline()
            if not line:
                break

            try:
                data = json.loads(line)
            except json.JSONDecodeError as exc:
                send_ipc_message({"request_id": "unknown", "error": f"Invalid JSON: {exc}"})
                continue

            request_type = data.get("type")
            request_id = data.get("request_id", "default")
            session_id = data.get("session_id", request_id)

            if request_type == "reset_session":
                sys.stderr.write(f"[FunASR Worker] Resetting session: {session_id}\n")
                sys.stderr.flush()
                sessions_cache.pop(session_id, None)
                continue

            if request_type == "force_commit":
                handle_force_commit(asr_offline_model, punc_model, data, sessions_cache)
                continue

            if request_type == "streaming_chunk":
                handle_streaming_chunk(
                    vad_model,
                    asr_online_model,
                    asr_offline_model,
                    punc_model,
                    data,
                    sessions_cache,
                )
                continue

            if request_type == "batch_file" or "audio_path" in data:
                handle_batch_file(asr_offline_model, punc_model, data)
                continue

            send_ipc_message({
                "request_id": request_id,
                "error": f"Unknown request type: {request_type}",
            })

    except Exception as exc:
        sys.stderr.write(f"[FunASR Worker] Fatal error: {exc}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        send_ipc_message({"status": "fatal", "error": str(exc)})
        sys.exit(1)


if __name__ == "__main__":
    main()
