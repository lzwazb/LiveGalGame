#!/usr/bin/env python3
"""
FunASR 2-Pass Worker: åŸºäº funasr_onnx çš„æµå¼/ç¦»çº¿æ··åˆè¯­éŸ³è¯†åˆ«

å‚ç…§ RealtimeMicPipeline demo è®¾è®¡ï¼š
- Pass 1 (æµå¼): ParaformerOnline å¿«é€Ÿå‡ºå­—ï¼Œç”¨äºå®æ—¶æ˜¾ç¤º
- Pass 2 (ç¦»çº¿): ParaformerOffline + æ ‡ç‚¹æ¨¡å‹ï¼Œç”¨äºæœ€ç»ˆä¿®æ­£

åˆ†å¥ç­–ç•¥ï¼š
- VAD æ£€æµ‹è¯­éŸ³è¾¹ç•Œ
- é™éŸ³ç´¯ç§¯è¾¾åˆ°é˜ˆå€¼è§¦å‘ Pass 2 ä¿®æ­£
- æ”¯æŒå¼ºåˆ¶æäº¤ (force_commit)
"""

import json
import os
import sys
import time
import traceback
import base64
from dataclasses import dataclass, field
from typing import Dict, List, Optional

import numpy as np

# ==============================================================================
# OS çº§åˆ«çš„æ–‡ä»¶æè¿°ç¬¦é‡å®šå‘
# ==============================================================================
ipc_fd = os.dup(sys.stdout.fileno())
ipc_channel = os.fdopen(ipc_fd, "w", buffering=1, encoding="utf-8")
os.dup2(sys.stderr.fileno(), sys.stdout.fileno())
sys.stdout = sys.stderr


def send_ipc_message(data):
    """å‘é€ JSON æ¶ˆæ¯åˆ° Node.js"""
    try:
        json_str = json.dumps(data, ensure_ascii=False)
        ipc_channel.write(json_str + "\n")
        ipc_channel.flush()
    except Exception as exc:
        sys.stderr.write(f"[IPC Error] Failed to send: {exc}\n")
        sys.stderr.flush()


# ==============================================================================
# ç¯å¢ƒå˜é‡é…ç½®
# ==============================================================================
os.environ.setdefault("TQDM_DISABLE", "1")

MODELSCOPE_CACHE = os.environ.get("MODELSCOPE_CACHE") or os.environ.get("ASR_CACHE_DIR")
if MODELSCOPE_CACHE:
    os.environ.setdefault("MODELSCOPE_CACHE", MODELSCOPE_CACHE)
    os.environ.setdefault("MODELSCOPE_CACHE_HOME", MODELSCOPE_CACHE)

# ==============================================================================
# FunASR é…ç½®
# ==============================================================================
SAMPLE_RATE = int(os.environ.get("ASR_SAMPLE_RATE", "16000"))
CHUNK_MS = int(os.environ.get("ASR_CHUNK_MS", "200"))  # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å—æ—¶é•¿ (æ¯«ç§’)
CHUNK_SAMPLES = int(SAMPLE_RATE * CHUNK_MS / 1000)

# é™éŸ³æ£€æµ‹é…ç½®
SILENCE_THRESHOLD_CHUNKS = int(os.environ.get("ASR_SILENCE_CHUNKS", "3"))  # è¿ç»­é™éŸ³å—æ•°è§¦å‘å¥å°¾
SILENCE_BUFFER_KEEP = 2  # ä¿ç•™å¤šå°‘ä¸ªé™éŸ³å—è®©éŸ³é¢‘æ›´è‡ªç„¶

# åˆ†å¥é…ç½®
SENTENCE_END_PUNCTUATION = set("ã€‚ï¼ï¼Ÿ!?.ï¼›;")
MIN_SENTENCE_CHARS = int(os.environ.get("MIN_SENTENCE_CHARS", "2"))


def decode_audio_chunk(audio_b64: str) -> np.ndarray:
    """Base64 éŸ³é¢‘è½¬ float32 numpy arrayï¼ˆèŒƒå›´ -1~1ï¼‰ã€‚"""
    audio_bytes = base64.b64decode(audio_b64)
    audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
    return audio_int16.astype(np.float32)  # funasr_onnx æ¥å— float32ï¼Œä¸é™¤ä»¥ 32768


def smart_split_sentences(text: str) -> List[str]:
    """
    æ™ºèƒ½åˆ†å¥ï¼šåŸºäºæ ‡ç‚¹ç¬¦å·å°†é•¿æ–‡æœ¬åˆ‡åˆ†æˆè‡ªç„¶çš„å¥å­ã€‚
    
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæŒ‰å¥æœ«æ ‡ç‚¹ï¼ˆã€‚ï¼ï¼Ÿ!?.ï¼‰åˆ†å‰²
    2. å¦‚æœåˆ†éš”åçš„å¥å­å¤ªçŸ­ï¼Œè€ƒè™‘åˆå¹¶
    3. å¦‚æœæ²¡æœ‰å¥æœ«æ ‡ç‚¹ï¼Œè¿”å›åŸæ–‡
    """
    if not text or len(text) < MIN_SENTENCE_CHARS:
        return [text] if text else []
    
    # å®šä¹‰å¥æœ«æ ‡ç‚¹
    sentence_endings = "ã€‚ï¼ï¼Ÿ!?."
    
    sentences = []
    current_sentence = ""
    
    for char in text:
        current_sentence += char
        if char in sentence_endings:
            trimmed = current_sentence.strip()
            if trimmed and len(trimmed) >= MIN_SENTENCE_CHARS:
                sentences.append(trimmed)
            elif trimmed and sentences:
                # å¤ªçŸ­çš„å¥å­åˆå¹¶åˆ°ä¸Šä¸€å¥
                sentences[-1] += trimmed
            elif trimmed:
                sentences.append(trimmed)
            current_sentence = ""
    
    # å¤„ç†å‰©ä½™çš„æ–‡æœ¬
    remaining = current_sentence.strip()
    if remaining:
        if len(remaining) < MIN_SENTENCE_CHARS and sentences:
            # å¤ªçŸ­å°±åˆå¹¶åˆ°ä¸Šä¸€å¥
            sentences[-1] += remaining
        else:
            sentences.append(remaining)
    
    return sentences if sentences else [text]



@dataclass
class SessionState:
    """
    FunASR 2-Pass ä¼šè¯çŠ¶æ€
    """
    # éŸ³é¢‘ç¼“å†²åŒº (ç»™ Pass 2 ç”¨)
    full_sentence_buffer: List[np.ndarray] = field(default_factory=list)
    
    # Pass 1 æµå¼æ¨¡å‹çš„ä¸Šä¸‹æ–‡ç¼“å­˜
    online_cache: Dict = field(default_factory=dict)
    
    # é™éŸ³æ£€æµ‹
    silence_counter: int = 0
    is_speaking: bool = False
    
    # ç´¯ç§¯çš„æµå¼æ–‡æœ¬
    streaming_text: str = ""
    last_sent_text: str = ""
    
    # æ—¶é—´æˆ³
    start_time: float = 0.0
    
    def reset(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        self.full_sentence_buffer.clear()
        self.online_cache.clear()
        self.silence_counter = 0
        self.is_speaking = False
        self.streaming_text = ""
        self.last_sent_text = ""
        self.start_time = 0.0


def load_funasr_onnx_models():
    """
    åŠ è½½ funasr_onnx æ¨¡å‹ (VAD + æµå¼ASR + ç¦»çº¿ASR + æ ‡ç‚¹)
    
    æ”¯æŒçš„ç¯å¢ƒå˜é‡:
    - ASR_MODEL: æ¨¡å‹ ID (funasr-paraformer / funasr-paraformer-large)
    - ASR_QUANTIZE: æ˜¯å¦ä½¿ç”¨é‡åŒ– (true/false)ï¼Œé»˜è®¤æ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨é€‰æ‹©
    """
    try:
        from funasr_onnx.vad_bin import Fsmn_vad
        from funasr_onnx.paraformer_online_bin import Paraformer as ParaformerOnline
        from funasr_onnx.paraformer_bin import Paraformer as ParaformerOffline
        from funasr_onnx.punc_bin import CT_Transformer
    except ImportError as e:
        sys.stderr.write(f"[FunASR Worker] Import error: {e}\n")
        sys.stderr.write("[FunASR Worker] Please install: pip install funasr_onnx\n")
        sys.stderr.flush()
        raise

    # è¯»å–æ¨¡å‹é…ç½®
    model_id = os.environ.get("ASR_MODEL", "funasr-paraformer")
    is_large = "large" in model_id.lower()
    
    # Large ç‰ˆæœ¬é»˜è®¤ä¸ä½¿ç”¨é‡åŒ–ï¼Œç²¾åº¦æ›´é«˜
    quantize_env = os.environ.get("ASR_QUANTIZE", "").lower()
    if quantize_env in ("true", "1", "yes"):
        use_quantize = True
    elif quantize_env in ("false", "0", "no"):
        use_quantize = False
    else:
        # é»˜è®¤: æ™®é€šç‰ˆé‡åŒ–ï¼ŒLargeç‰ˆä¸é‡åŒ–
        use_quantize = not is_large
    
    sys.stderr.write(f"[FunASR Worker] Model ID: {model_id}\n")
    sys.stderr.write(f"[FunASR Worker] Is Large model: {is_large}\n")
    sys.stderr.write(f"[FunASR Worker] Use Quantize: {use_quantize}\n")
    sys.stderr.write("[FunASR Worker] Loading ONNX models (first run will download)...\n")
    sys.stderr.flush()

    # ONNX æ¨¡å‹é…ç½®
    # å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é»˜è®¤æ¨¡å‹
    vad_model_dir = os.environ.get(
        "FUNASR_VAD_MODEL", 
        "damo/speech_fsmn_vad_zh-cn-16k-common-onnx"
    )
    online_model_dir = os.environ.get(
        "FUNASR_ONLINE_MODEL",
        "damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx"
    )
    offline_model_dir = os.environ.get(
        "FUNASR_OFFLINE_MODEL",
        "damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx"
    )
    punc_model_dir = os.environ.get(
        "FUNASR_PUNC_MODEL",
        "damo/punc_ct-transformer_zh-cn-common-vocab272727-onnx"
    )

    # 1. VAD æ¨¡å‹: æ£€æµ‹è¯­éŸ³æ´»åŠ¨
    sys.stderr.write(f"[FunASR Worker] Loading VAD model: {vad_model_dir}...\n")
    sys.stderr.flush()
    vad_model = Fsmn_vad(
        model_dir=vad_model_dir,
        quantize=use_quantize
    )

    # 2. Pass 1 æµå¼æ¨¡å‹: å¿«é€Ÿå‡ºå­—
    sys.stderr.write(f"[FunASR Worker] Loading streaming ASR model (Pass 1): {online_model_dir}...\n")
    sys.stderr.flush()
    asr_online_model = ParaformerOnline(
        model_dir=online_model_dir,
        batch_size=1,
        quantize=use_quantize,
        intra_op_num_threads=4
    )

    # 3. Pass 2 éæµå¼æ¨¡å‹: é«˜ç²¾åº¦è¯†åˆ«
    sys.stderr.write(f"[FunASR Worker] Loading offline ASR model (Pass 2): {offline_model_dir}...\n")
    sys.stderr.flush()
    asr_offline_model = ParaformerOffline(
        model_dir=offline_model_dir,
        batch_size=1,
        quantize=use_quantize,
        intra_op_num_threads=4
    )

    # 4. æ ‡ç‚¹æ¨¡å‹: ç»™ Pass 2 ç»“æœåŠ æ ‡ç‚¹
    sys.stderr.write(f"[FunASR Worker] Loading punctuation model: {punc_model_dir}...\n")
    sys.stderr.flush()
    punc_model = CT_Transformer(
        model_dir=punc_model_dir,
        quantize=use_quantize,
        intra_op_num_threads=2
    )

    sys.stderr.write("[FunASR Worker] All models loaded successfully!\n")
    sys.stderr.write(f"[FunASR Worker] Configuration: model={model_id}, quantize={use_quantize}\n")
    sys.stderr.flush()

    return vad_model, asr_online_model, asr_offline_model, punc_model


def handle_streaming_chunk(
    vad_model,
    asr_online_model,
    asr_offline_model,
    punc_model,
    data: dict,
    sessions_cache: Dict[str, SessionState],
):
    """
    å¤„ç†æµå¼éŸ³é¢‘å— - 2-Pass æ¶æ„
    
    Pass 1: å®æ—¶æµå¼è¯†åˆ«ï¼Œå¿«é€Ÿè¿”å› partial ç»“æœ
    Pass 2: æ£€æµ‹åˆ°å¥å°¾åï¼Œä½¿ç”¨ç¦»çº¿æ¨¡å‹ + æ ‡ç‚¹è¿›è¡Œé«˜ç²¾åº¦ä¿®æ­£
    """
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)
    audio_data_b64 = data.get("audio_data")
    is_final = bool(data.get("is_final", False))
    timestamp_ms = data.get("timestamp", int(time.time() * 1000))

    if not audio_data_b64:
        send_ipc_message({"request_id": request_id, "error": "No audio_data provided"})
        return

    state = sessions_cache.setdefault(session_id, SessionState())
    audio_chunk = decode_audio_chunk(audio_data_b64)

    if audio_chunk.size == 0:
        return

    # è®°å½•å¼€å§‹æ—¶é—´
    if not state.is_speaking and state.start_time == 0:
        state.start_time = time.time()

    # ==== VAD æ£€æµ‹ ====
    try:
        vad_segments = vad_model(audio_chunk)
        current_chunk_has_speech = len(vad_segments) > 0
    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] VAD error: {e}\n")
        sys.stderr.flush()
        current_chunk_has_speech = True  # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†

    # ==== çŠ¶æ€ç®¡ç† ====
    if current_chunk_has_speech:
        state.silence_counter = 0
        state.is_speaking = True
        state.full_sentence_buffer.append(audio_chunk)
    else:
        if state.is_speaking:
            state.silence_counter += 1
            # ä¿ç•™ä¸€ç‚¹é™éŸ³æ®µè®©éŸ³é¢‘æ›´è‡ªç„¶
            if state.silence_counter < SILENCE_BUFFER_KEEP:
                state.full_sentence_buffer.append(audio_chunk)

    # ==== Pass 1: å®æ—¶æµå¼è¯†åˆ« ====
    if state.is_speaking:
        try:
            partial_res = asr_online_model(
                audio_chunk,
                param_dict={"cache": state.online_cache, "is_final": False},
            )

            if partial_res:
                # è°ƒè¯•æ—¥å¿—ï¼šæŸ¥çœ‹å®é™…è¿”å›çš„æ ¼å¼
                sys.stderr.write(f"[FunASR Worker] DEBUG partial_res type={type(partial_res).__name__}, value={str(partial_res)[:100]}\n")
                sys.stderr.flush()
                
                # funasr_onnx è¿”å›æ ¼å¼å¯èƒ½æ˜¯:
                # 1. [('text', ['chars'])] - åˆ—è¡¨åŒ…å« tuple
                # 2. [{'preds': 'text'}] - åˆ—è¡¨åŒ…å«å­—å…¸
                # 3. ('text', ['chars']) - ç›´æ¥æ˜¯ tuple
                text = ""
                
                # å…ˆè§£åŒ…åˆ—è¡¨
                item = partial_res
                while isinstance(item, list) and len(item) > 0:
                    item = item[0]
                
                # ç°åœ¨ item åº”è¯¥æ˜¯ tuple æˆ– dict æˆ– str
                if isinstance(item, dict):
                    preds_value = item.get("preds") or item.get("text") or ""
                    # å¦‚æœ preds æ˜¯ tupleï¼Œéœ€è¦æå–å­—ç¬¦ä¸²
                    if isinstance(preds_value, tuple) and len(preds_value) > 0:
                        text = preds_value[0] if isinstance(preds_value[0], str) else str(preds_value[0])
                    elif isinstance(preds_value, str):
                        text = preds_value
                    else:
                        text = str(preds_value) if preds_value else ""
                elif isinstance(item, tuple) and len(item) > 0:
                    # Tuple æ ¼å¼: ('text', ['chars']) - å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    first_elem = item[0]
                    text = first_elem if isinstance(first_elem, str) else str(first_elem)
                elif isinstance(item, str):
                    text = item
                else:
                    text = str(item) if item else ""
                
                sys.stderr.write(f"[FunASR Worker] DEBUG extracted text=\"{text[:50]}...\"\n")
                sys.stderr.flush()
                
                if text and text != state.last_sent_text:
                    state.streaming_text = text
                    send_ipc_message({
                        "request_id": request_id,
                        "session_id": session_id,
                        "type": "partial",
                        "text": text,
                        "full_text": text,
                        "timestamp": timestamp_ms,
                        "is_final": False,
                        "status": "success",
                        "language": "zh",
                    })
                    state.last_sent_text = text
                    sys.stderr.write(f"[FunASR Worker] ğŸ“ PARTIAL: \"{text[:50]}...\"\n")
                    sys.stderr.flush()
        except Exception as e:
            sys.stderr.write(f"[FunASR Worker] Pass 1 error: {e}\n")
            sys.stderr.flush()

    # ==== Pass 2: æ£€æµ‹åˆ°å¥å°¾ï¼Œè§¦å‘é«˜ç²¾åº¦ä¿®æ­£ ====
    if state.is_speaking and state.silence_counter >= SILENCE_THRESHOLD_CHUNKS:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="silence",
        )

    # ==== å¤„ç† is_final æ ‡è®° ====
    if is_final and state.full_sentence_buffer:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="final",
        )


def _trigger_pass2(
    asr_offline_model,
    punc_model,
    state: SessionState,
    request_id: str,
    session_id: str,
    timestamp_ms: int,
    trigger: str,
):
    """
    è§¦å‘ Pass 2: ç¦»çº¿é«˜ç²¾åº¦è¯†åˆ« + æ ‡ç‚¹ + æ™ºèƒ½åˆ†å¥
    
    æ”¹è¿›ï¼šä½¿ç”¨æ ‡ç‚¹æ¨¡å‹ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†å¥ï¼Œå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªè‡ªç„¶å¥å­åˆ†åˆ«å‘é€ã€‚
    """
    if not state.full_sentence_buffer:
        return

    sys.stderr.write(f"[FunASR Worker] Triggering Pass 2 ({trigger})...\n")
    sys.stderr.flush()

    try:
        # åˆå¹¶éŸ³é¢‘ç‰‡æ®µ
        complete_audio = np.concatenate(state.full_sentence_buffer)
        audio_duration = len(complete_audio) / SAMPLE_RATE

        # A. éæµå¼é«˜ç²¾åº¦è¯†åˆ«
        offline_res = asr_offline_model(complete_audio)
        raw_text = ""
        if offline_res:
            # è§£æè¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯ tuple æˆ– dictï¼‰
            item = offline_res[0] if isinstance(offline_res, list) else offline_res
            if isinstance(item, dict):
                raw_text = item.get("preds") or item.get("text") or ""
            elif isinstance(item, (tuple, list)) and len(item) > 0:
                raw_text = item[0] if isinstance(item[0], str) else str(item[0])
            elif isinstance(item, str):
                raw_text = item
            else:
                raw_text = str(item) if item else ""

        if raw_text and len(raw_text) >= MIN_SENTENCE_CHARS:
            # B. æ ‡ç‚¹é¢„æµ‹
            try:
                punc_res = punc_model(raw_text)
                # è§£ææ ‡ç‚¹æ¨¡å‹è¿”å›å€¼
                if punc_res:
                    punc_item = punc_res[0] if isinstance(punc_res, list) else punc_res
                    if isinstance(punc_item, str):
                        punctuated_text = punc_item
                    elif isinstance(punc_item, (tuple, list)) and len(punc_item) > 0:
                        punctuated_text = punc_item[0] if isinstance(punc_item[0], str) else str(punc_item[0])
                    else:
                        punctuated_text = str(punc_item) if punc_item else raw_text
                else:
                    punctuated_text = raw_text
            except Exception as e:
                sys.stderr.write(f"[FunASR Worker] Punctuation error: {e}\n")
                sys.stderr.flush()
                punctuated_text = raw_text

            sys.stderr.write(f"[FunASR Worker]    Raw: \"{raw_text}\"\n")
            sys.stderr.write(f"[FunASR Worker]    With punc: \"{punctuated_text}\"\n")
            sys.stderr.flush()

            # C. æ™ºèƒ½åˆ†å¥ï¼šå°†é•¿æ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªè‡ªç„¶å¥å­
            sentences = smart_split_sentences(punctuated_text)
            
            # è®¡ç®—æ¯ä¸ªå¥å­çš„å¤§è‡´æ—¶é—´åˆ†å¸ƒ
            total_chars = sum(len(s) for s in sentences)
            current_time = state.start_time * 1000 if state.start_time else timestamp_ms - (audio_duration * 1000)
            
            for i, sentence in enumerate(sentences):
                # ä¼°ç®—è¿™ä¸ªå¥å­çš„æ—¶é—´èŒƒå›´
                sentence_ratio = len(sentence) / max(total_chars, 1)
                sentence_duration = audio_duration * sentence_ratio
                sentence_end_time = current_time + (sentence_duration * 1000)
                
                is_last = (i == len(sentences) - 1)
                
                sys.stderr.write(f"[FunASR Worker] ğŸ¯ SENTENCE [{i+1}/{len(sentences)}]: \"{sentence[:50]}...\"\n")
                sys.stderr.flush()

                send_ipc_message({
                    "request_id": request_id,
                    "session_id": session_id,
                    "type": "sentence_complete",
                    "text": sentence,
                    "raw_text": raw_text if i == 0 else "",  # åªåœ¨ç¬¬ä¸€å¥é™„å¸¦åŸå§‹æ–‡æœ¬
                    "timestamp": int(sentence_end_time),
                    "is_final": is_last,
                    "status": "success",
                    "language": "zh",
                    "audio_duration": sentence_duration,
                    "trigger": trigger,
                    "start_time": int(current_time),
                    "end_time": int(sentence_end_time),
                    "sentence_index": i,
                    "total_sentences": len(sentences),
                })
                
                current_time = sentence_end_time

    except Exception as e:
        sys.stderr.write(f"[FunASR Worker] Pass 2 error: {e}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()

    # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€å¥
    state.reset()


def handle_force_commit(
    asr_offline_model,
    punc_model,
    data: dict,
    sessions_cache: Dict[str, SessionState],
):
    """å¼ºåˆ¶æäº¤å½“å‰å¥å­"""
    request_id = data.get("request_id", "default")
    session_id = data.get("session_id", request_id)
    timestamp_ms = int(time.time() * 1000)

    sys.stderr.write(f"[FunASR Worker] force_commit received for session={session_id}\n")
    sys.stderr.flush()

    state = sessions_cache.get(session_id)
    if not state:
        sys.stderr.write(f"[FunASR Worker] No session state found for session={session_id}\n")
        sys.stderr.flush()
        return

    # å¦‚æœæœ‰ç¼“å†²çš„éŸ³é¢‘ï¼Œè§¦å‘ Pass 2
    if state.full_sentence_buffer:
        _trigger_pass2(
            asr_offline_model,
            punc_model,
            state,
            request_id,
            session_id,
            timestamp_ms,
            trigger="force_commit",
        )
    elif state.streaming_text and len(state.streaming_text) >= MIN_SENTENCE_CHARS:
        # æ²¡æœ‰ç¼“å†²çš„éŸ³é¢‘ï¼Œä½†æœ‰æµå¼æ–‡æœ¬ï¼Œç›´æ¥æäº¤æµå¼æ–‡æœ¬
        send_ipc_message({
            "request_id": request_id,
            "session_id": session_id,
            "type": "sentence_complete",
            "text": state.streaming_text,
            "timestamp": timestamp_ms,
            "is_final": True,
            "status": "success",
            "trigger": "force_commit_text_only",
            "language": "zh",
            "audio_duration": 0,
        })
        state.reset()
    else:
        sys.stderr.write(f"[FunASR Worker] force_commit: no content to commit\n")
        sys.stderr.flush()


def handle_batch_file(asr_offline_model, punc_model, data: dict):
    """å¤„ç†æ‰¹é‡æ–‡ä»¶è¯†åˆ«"""
    request_id = data.get("request_id", "unknown")
    audio_path = data.get("audio_path")

    if not audio_path:
        send_ipc_message({"request_id": request_id, "error": "No audio_path provided"})
        return
    if not os.path.exists(audio_path):
        send_ipc_message({"request_id": request_id, "error": f"File not found: {audio_path}"})
        return

    try:
        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        import wave
        with wave.open(audio_path, 'rb') as wf:
            audio_data = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
            audio_float = audio_data.astype(np.float32)

        # ç¦»çº¿è¯†åˆ«
        offline_res = asr_offline_model(audio_float)
        raw_text = ""
        if offline_res:
            # è§£æè¿”å›å€¼ï¼ˆå¯èƒ½æ˜¯ tuple æˆ– dictï¼‰
            item = offline_res[0] if isinstance(offline_res, list) else offline_res
            if isinstance(item, dict):
                raw_text = item.get("preds") or item.get("text") or ""
            elif isinstance(item, (tuple, list)) and len(item) > 0:
                raw_text = item[0] if isinstance(item[0], str) else str(item[0])
            elif isinstance(item, str):
                raw_text = item
            else:
                raw_text = str(item) if item else ""

        # æ ‡ç‚¹
        if raw_text:
            try:
                punc_res = punc_model(raw_text)
                # è§£ææ ‡ç‚¹æ¨¡å‹è¿”å›å€¼
                if punc_res:
                    punc_item = punc_res[0] if isinstance(punc_res, list) else punc_res
                    if isinstance(punc_item, str):
                        final_text = punc_item
                    elif isinstance(punc_item, (tuple, list)) and len(punc_item) > 0:
                        final_text = punc_item[0] if isinstance(punc_item[0], str) else str(punc_item[0])
                    else:
                        final_text = str(punc_item) if punc_item else raw_text
                else:
                    final_text = raw_text
            except Exception:
                final_text = raw_text
        else:
            final_text = ""

        send_ipc_message({
            "request_id": request_id,
            "text": final_text,
            "raw_text": raw_text,
            "language": "zh",
            "status": "success",
        })

    except Exception as exc:
        send_ipc_message({
            "request_id": request_id,
            "error": str(exc),
            "traceback": traceback.format_exc(),
        })


def main():
    try:
        sys.stderr.write("[FunASR Worker] Starting FunASR 2-Pass Worker...\n")
        sys.stderr.flush()

        # åŠ è½½æ¨¡å‹
        vad_model, asr_online_model, asr_offline_model, punc_model = load_funasr_onnx_models()

        sessions_cache: Dict[str, SessionState] = {}
        send_ipc_message({"status": "ready"})

        sys.stderr.write("[FunASR Worker] Ready! 2-Pass mode enabled.\n")
        sys.stderr.flush()

        while True:
            line = sys.stdin.readline()
            if not line:
                break

            try:
                data = json.loads(line)
            except json.JSONDecodeError as exc:
                send_ipc_message({"request_id": "unknown", "error": f"Invalid JSON: {exc}"})
                continue

            request_type = data.get("type")
            request_id = data.get("request_id", "default")
            session_id = data.get("session_id", request_id)

            if request_type == "reset_session":
                sys.stderr.write(f"[FunASR Worker] Resetting session: {session_id}\n")
                sys.stderr.flush()
                sessions_cache.pop(session_id, None)
                continue

            if request_type == "force_commit":
                handle_force_commit(asr_offline_model, punc_model, data, sessions_cache)
                continue

            if request_type == "streaming_chunk":
                handle_streaming_chunk(
                    vad_model,
                    asr_online_model,
                    asr_offline_model,
                    punc_model,
                    data,
                    sessions_cache,
                )
                continue

            if request_type == "batch_file" or "audio_path" in data:
                handle_batch_file(asr_offline_model, punc_model, data)
                continue

            send_ipc_message({
                "request_id": request_id,
                "error": f"Unknown request type: {request_type}",
            })

    except Exception as exc:
        sys.stderr.write(f"[FunASR Worker] Fatal error: {exc}\n")
        sys.stderr.write(traceback.format_exc())
        sys.stderr.flush()
        send_ipc_message({"status": "fatal", "error": str(exc)})
        sys.exit(1)


if __name__ == "__main__":
    main()
